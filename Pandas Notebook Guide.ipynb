{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêº Guide to Using Pandas Methods and Functions\n",
    "This guide provides a practical overview of the main Pandas methods and functions for data analysis. From DataFrame management to cleaning and transformation, you will find useful examples to manipulate and analyze data in Python efficiently.\n",
    "\n",
    "By [Enzo Schitini]('https://www.linkedin.com/in/enzoschitini/')\n",
    "\n",
    "Data Scientist & Data Analyst ‚Ä¢ SQL ‚Ä¢ Expert Bubble.io ‚Ä¢ UX & UI @ Scituffy creator\n",
    "\n",
    "Pandas is one of the most powerful and widely used libraries for manipulating and analyzing data in Python. Whether you are an aspiring data scientist, an experienced analyst, or simply someone who works with data, mastering Pandas can greatly improve your productivity and data processing skills. This guide aims to provide a comprehensive overview of Pandas' essential methods and functions, enabling you to tackle complex data operations with ease and efficiency.\n",
    "\n",
    "In this guide, you will explore fundamental concepts such as data cleansing, transformation, aggregation, and visualization techniques using Pandas. Through practical examples and step-by-step instructions, you will gain a deeper understanding of how to leverage Pandas' full potential to simplify and enhance your data workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dataset:` For this guide, we will use data from an online store, although with fewer rows and columns than the original. We have 2022 rows and 10 columns.\n",
    "Link Dataset: https://github.com/enzoschitini/Guide-to-Using-Pandas/blob/main/pandas_csv_guide.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| order_id                            | customer_state | product_category_name | product_weight_g | review_score | price | freight_value | payment_value | order_approved_at     | order_purchase_timestamp |\n",
    "|-------------------------------------|----------------|-----------------------|------------------|--------------|-------|---------------|---------------|-----------------------|-------------------------|\n",
    "| 00010242fe8c5a6d1ba2dd792cb16214    | RJ             | cool_stuff            | 650.0            | 5            | 58.9  | 13.29         | 72.19         | 2017-09-13 09:45:35   | 2017-09-13 08:59:02     |\n",
    "| 130898c0987d1801452a8ed92a670612    | GO             | cool_stuff            | 650.0            | 5            | 55.9  | 17.96         | 73.86         | 2017-06-29 02:44:11   | 2017-06-28 11:52:20     |\n",
    "| 532ed5e14e24ae1f0d735b91524b98b9    | MG             | cool_stuff            | 650.0            | 4            | 64.9  | 18.33         | 83.23         | 2018-05-18 12:31:43   | 2018-05-18 10:25:53     |\n",
    "| 6f8c31653edb8c83e1a739408b5ff750    | PR             | cool_stuff            | 650.0            | 5            | 58.9  | 16.17         | 75.07         | 2017-08-01 18:55:08   | 2017-08-01 18:38:42     |\n",
    "| 7d19f4ef4d04461989632411b7e588b9    | MG             | cool_stuff            | 650.0            | 5            | 58.9  | 13.29         | 72.19         | 2017-08-10 22:05:11   | 2017-08-10 21:48:40     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of columns:\n",
    "\n",
    "- **order_id**: Unique identifier for the order. Each row represents a specific order made by the customer.\n",
    "\n",
    "- **customer_state**: Brazilian state where the customer resides. It is represented by a two-letter code (e.g., RJ for Rio de Janeiro).\n",
    "\n",
    "- **product_category_name**: Category of the purchased product. For example, \"cool_stuff\" indicates a specific product category.\n",
    "\n",
    "- **product_weight_g**: Weight of the product in grams. This provides information about the weight of the ordered product.\n",
    "\n",
    "- **review_score**: Review score given by the customer for the order, typically on a scale from 1 to 5.\n",
    "\n",
    "- **price**: Price of the product in the local currency (Brazilian reais). This indicates the cost of the purchased product.\n",
    "\n",
    "- **freight_value**: Shipping cost in the local currency. This represents the shipping charge for the order.\n",
    "\n",
    "- **payment_value**: Total amount paid for the order, including the product price and the shipping cost.\n",
    "\n",
    "- **order_approved_at**: Date and time when the order was approved for shipping.\n",
    "\n",
    "- **order_purchase_timestamp**: Date and time when the order was placed by the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/pandas_csv_guide.csv').drop(columns='Unnamed: 0')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argomenti da trattare in questa guida:  \n",
    "Ho scelto i 10 argomenti che, secondo me, sono pi√π utilizzati in Pandas per analizzare i dati.  \n",
    "\n",
    "### 1. **Caricamento dei Dati**  \n",
    "\n",
    "- `pd.read_csv()` ‚Äì Carica dati da un file CSV.  \n",
    "- `pd.read_excel()` ‚Äì Carica dati da un file Excel.  \n",
    "- `pd.read_sql()` ‚Äì Carica dati da un database SQL.  \n",
    "- `pd.read_json()` ‚Äì Carica dati da un file JSON.  \n",
    "- `pd.read_parquet()` ‚Äì Carica dati da un file Parquet, utile per dataset di grandi dimensioni.  \n",
    "- `pd.read_html()` ‚Äì Analizza tabelle HTML da una pagina web.  \n",
    "- `pd.read_pickle()` ‚Äì Carica dati salvati in formato pickle di Python.  \n",
    "- `pd.read_feather()` ‚Äì Carica dati da un file in formato Feather, adatto per input/output veloci.  \n",
    "- `pd.read_sas()` ‚Äì Carica dati da file SAS.  \n",
    "- `pd.read_hdf()` ‚Äì Carica dati da file in formato HDF5.  \n",
    "\n",
    "### 2. **Ispezione dei Dati**  \n",
    "\n",
    "- `.head(n)` ‚Äì Mostra le prime `n` righe del DataFrame (predefinito: 5).  \n",
    "- `.tail(n)` ‚Äì Mostra le ultime `n` righe del DataFrame.  \n",
    "- `.shape` ‚Äì Restituisce le dimensioni (righe, colonne) del DataFrame.  \n",
    "- `.columns` ‚Äì Elenca i nomi delle colonne.  \n",
    "- `.info()` ‚Äì Mostra informazioni sul DataFrame (tipi di colonna, conteggi non nulli).  \n",
    "- `.describe()` ‚Äì Fornisce statistiche descrittive per le colonne numeriche.  \n",
    "- `.dtypes` ‚Äì Restituisce i tipi di dati di tutte le colonne.  \n",
    "- `.index` ‚Äì Restituisce l'indice (etichette delle righe) del DataFrame.  \n",
    "- `.value_counts()` ‚Äì Conta i valori univoci in una colonna.  \n",
    "- `.isnull()` / `.notnull()` ‚Äì Controlla i valori mancanti.  \n",
    "- `.duplicated()` ‚Äì Controlla righe duplicate.  \n",
    "- `.nunique()` ‚Äì Conta il numero di valori univoci per colonna.  \n",
    "- `.sample(n)` ‚Äì Seleziona casualmente `n` righe dal DataFrame.  \n",
    "\n",
    "### 3. **Selezione e Indicizzazione dei Dati**  \n",
    "\n",
    "- `.loc[]` ‚Äì Accede a gruppi di righe e colonne tramite etichette.  \n",
    "- `.iloc[]` ‚Äì Accede a gruppi di righe e colonne tramite posizioni (basate su interi).  \n",
    "- `.at[]` ‚Äì Accede a un singolo valore tramite una coppia etichetta riga/colonna.  \n",
    "- `.iat[]` ‚Äì Accede a un singolo valore tramite una coppia posizione riga/colonna.  \n",
    "- `.filter()` ‚Äì Sottoseleziona il DataFrame in base alle etichette di riga/colonna.  \n",
    "- `.xs()` ‚Äì Estrae sezioni trasversali da un MultiIndex.  \n",
    "- `.query()` ‚Äì Filtra il DataFrame usando un'espressione in formato stringa.  \n",
    "- `.get()` ‚Äì Recupera elementi da una Serie tramite chiave.  \n",
    "- `.isin()` ‚Äì Filtra righe in base alla presenza di valori in una lista.  \n",
    "- `.where()` ‚Äì Imposta valori in base a una condizione.  \n",
    "- `.mask()` ‚Äì Sostituisce valori dove una condizione √® `True`.  \n",
    "- `.squeeze()` ‚Äì Converte un DataFrame con una sola colonna in una Serie.  \n",
    "\n",
    "### 4. **Pulizia dei Dati**  \n",
    "\n",
    "- `.drop()` ‚Äì Rimuove etichette specificate da righe o colonne.  \n",
    "- `.dropna()` ‚Äì Elimina righe/colonne con valori mancanti.  \n",
    "- `.fillna()` ‚Äì Sostituisce i valori mancanti con un valore specificato.  \n",
    "- `.replace()` ‚Äì Sostituisce valori all'interno del DataFrame.  \n",
    "- `.rename()` ‚Äì Rinomina colonne o indici.  \n",
    "- `.interpolate()` ‚Äì Riempie valori NaN con valori interpolati.  \n",
    "- `.bfill()` / `.ffill()` ‚Äì Riempimento a ritroso o in avanti di valori NaN.  \n",
    "- `.convert_dtypes()` ‚Äì Converte colonne nei tipi di dati ottimali.  \n",
    "- `.clip()` ‚Äì Limita i valori al di sotto o al di sopra di una soglia.  \n",
    "- `.abs()` ‚Äì Calcola il valore assoluto delle colonne numeriche.  \n",
    "- `.round(decimals)` ‚Äì Arrotonda i valori a un numero specificato di decimali.  \n",
    "\n",
    "### 5. **Trasformazione dei Dati**  \n",
    "\n",
    "- `.astype()` ‚Äì Cambia il tipo di dato delle colonne.  \n",
    "- `.apply()` ‚Äì Applica una funzione lungo un asse (righe/colonne).  \n",
    "- `.applymap()` ‚Äì Applica una funzione elemento per elemento.  \n",
    "- `.map()` ‚Äì Mappa valori da una colonna a un'altra.  \n",
    "- `.sort_values()` ‚Äì Ordina il DataFrame per colonne.  \n",
    "- `.sort_index()` ‚Äì Ordina il DataFrame per il suo indice.  \n",
    "- `.reset_index()` ‚Äì Reimposta l'indice del DataFrame.  \n",
    "- `.pivot()` ‚Äì Rimodella i dati in base ai valori delle colonne.  \n",
    "- `.rank()` ‚Äì Classifica i valori all'interno di ciascuna colonna.  \n",
    "- `.cumsum()` / `.cumprod()` ‚Äì Calcola somme/prodotti cumulativi.  \n",
    "- `.diff()` ‚Äì Calcola la differenza tra righe successive.  \n",
    "- `.expanding()` ‚Äì Applica trasformazioni progressive (es. somma cumulativa).  \n",
    "- `.pipe()` ‚Äì Applica funzioni personalizzate al DataFrame.  \n",
    "- `.eval()` ‚Äì Valuta un'espressione Python come colonna nel DataFrame.  \n",
    "\n",
    "### 6. **Aggregazione e Raggruppamento**  \n",
    "\n",
    "- `.groupby()` ‚Äì Raggruppa il DataFrame in base a una o pi√π colonne.  \n",
    "- `.agg()` ‚Äì Applica funzioni di aggregazione come somma, media, min, max sui dati raggruppati.  \n",
    "- `.sum()`, `.mean()`, `.min()`, `.max()`, `.count()` ‚Äì Calcola direttamente queste statistiche.  \n",
    "- `.pivot_table()` ‚Äì Crea una tabella pivot con righe, colonne e valori specificati.  \n",
    "- `.transform()` ‚Äì Applica funzioni a colonne raggruppate usando `groupby()`.  \n",
    "- `.size()` ‚Äì Restituisce la dimensione di ogni gruppo.  \n",
    "- `.cumcount()` ‚Äì Conta le occorrenze cumulative di valori univoci.  \n",
    "- `.nsmallest(n, columns)` ‚Äì Trova i `n` valori pi√π piccoli in una colonna.  \n",
    "- `.nlargest(n, columns)` ‚Äì Trova i `n` valori pi√π grandi in una colonna.  \n",
    "- `.mad()` ‚Äì Deviazione assoluta media per dati raggruppati.  \n",
    "- `.rolling(window).apply()` ‚Äì Applica una funzione su una finestra mobile.  \n",
    "\n",
    "### 7. **Unione e Combinazione dei Dati**  \n",
    "\n",
    "- `pd.merge()` ‚Äì Unisce DataFrame su colonne specificate.  \n",
    "- `.join()` ‚Äì Unisce DataFrame sugli indici.  \n",
    "- `pd.concat()` ‚Äì Concatena DataFrame lungo righe o colonne.  \n",
    "\n",
    "### 8. **Esplorazione dei Dati Temporali**  \n",
    "\n",
    "- `.resample()` ‚Äì Raggruppa e riassume i dati in base a una frequenza temporale.  \n",
    "- `.to_datetime()` ‚Äì Converte stringhe in oggetti datetime.  \n",
    "- `.dt` accessor ‚Äì Accede a componenti di data come anno, mese, giorno.  \n",
    "- `.rolling()` ‚Äì Applica operazioni su una finestra temporale mobile.  \n",
    "- `.shift()` ‚Äì Sposta i dati nel tempo (es. periodi).  \n",
    "- `.diff()` ‚Äì Calcola la differenza di valori successivi in una serie temporale.  \n",
    "- `.asfreq()` ‚Äì Cambia la frequenza di un indice temporale.  \n",
    "- `.between_time()` ‚Äì Estrae righe in base a un intervallo di tempo specifico.  \n",
    "- `.at_time()` ‚Äì Estrae righe per un'ora specifica.  \n",
    "- `.truncate()` ‚Äì Riduce righe prima o dopo una data specifica.  \n",
    "\n",
    "### 9. **Esportazione dei Dati**  \n",
    "\n",
    "- `.to_csv()` ‚Äì Esporta i dati in un file CSV.  \n",
    "- `.to_excel()` ‚Äì Esporta i dati in un file Excel.  \n",
    "- `.to_sql()` ‚Äì Esporta i dati in un database SQL.  \n",
    "- `.to_json()` ‚Äì Esporta i dati in formato JSON.  \n",
    "- `.to_parquet()` ‚Äì Esporta i dati in formato Parquet.  \n",
    "- `.to_pickle()` ‚Äì Esporta i dati in un file pickle di Python.  \n",
    "- `.to_html()` ‚Äì Esporta i dati in una tabella HTML.  \n",
    "- `.to_latex()` ‚Äì Esporta i dati in formato LaTeX.  \n",
    "- `.to_dict()` ‚Äì Converte i dati in un dizionario Python.  \n",
    "- `.to_markdown()` ‚Äì Esporta i dati in formato Markdown.  \n",
    "- `.to_clipboard()` ‚Äì Copia i dati negli appunti.  \n",
    "- `.to_string()` ‚Äì Converte il DataFrame in una stringa.  \n",
    "- `.to_records()` ‚Äì Converte il DataFrame in un array di\n",
    "\n",
    "### 9. **Esportazione dei Dati**  \n",
    "\n",
    "- `.to_csv()` ‚Äì Esporta i dati in un file CSV.  \n",
    "- `.to_excel()` ‚Äì Esporta i dati in un file Excel.  \n",
    "- `.to_sql()` ‚Äì Esporta i dati in un database SQL.  \n",
    "- `.to_json()` ‚Äì Esporta i dati in formato JSON.  \n",
    "- `.to_parquet()` ‚Äì Esporta i dati in formato Parquet.  \n",
    "- `.to_pickle()` ‚Äì Esporta i dati in un file pickle di Python.  \n",
    "- `.to_html()` ‚Äì Esporta i dati in una tabella HTML.  \n",
    "- `.to_latex()` ‚Äì Esporta i dati in formato LaTeX.  \n",
    "- `.to_dict()` ‚Äì Converte i dati in un dizionario Python.  \n",
    "- `.to_markdown()` ‚Äì Esporta i dati in formato Markdown.  \n",
    "- `.to_clipboard()` ‚Äì Copia i dati negli appunti.  \n",
    "- `.to_string()` ‚Äì Converte il DataFrame in una stringa.  \n",
    "- `.to_records()` ‚Äì Converte il DataFrame in un array di record.  \n",
    "- `.to_feather()` ‚Äì Esporta i dati in formato Feather.  \n",
    "\n",
    "### 10. **Gestione degli Indici Multi-Livello (MultiIndex)**  \n",
    "\n",
    "- `.set_index()` ‚Äì Imposta una o pi√π colonne come indice del DataFrame.  \n",
    "- `.reset_index()` ‚Äì Reimposta l'indice del DataFrame, spostando gli attuali indici nelle colonne.  \n",
    "- `.sort_index()` ‚Äì Ordina il DataFrame in base ai valori dell'indice.  \n",
    "- `.swaplevel()` ‚Äì Scambia i livelli di un MultiIndex.  \n",
    "- `.stack()` ‚Äì Comprime i livelli delle colonne in righe.  \n",
    "- `.unstack()` ‚Äì Espande i livelli delle righe in colonne.  \n",
    "- `.reorder_levels()` ‚Äì Riordina i livelli di un MultiIndex.  \n",
    "- `.index.get_level_values()` ‚Äì Estrae i valori di un livello specifico da un MultiIndex.  \n",
    "- `.droplevel()` ‚Äì Rimuove un livello da un MultiIndex.  \n",
    "- `.groupby(level=...)` ‚Äì Raggruppa i dati in base ai livelli del MultiIndex.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî•Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_github(type):\n",
    "    url_data = f'https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/pandas_{type}_guide.{type}'\n",
    "    return url_data\n",
    "\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV, Execel, parquet, feather, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(url_github('csv')).drop(columns='Unnamed: 0')\n",
    "excel = pd.read_excel(url_github('xlsx')).drop(columns='Unnamed: 0')\n",
    "parquet = pd.read_parquet(url_github('parquet'))\n",
    "feather = pd.read_feather(url_github('feather'))\n",
    "json = pd.read_json(url_github('json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>RJ</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>72.19</td>\n",
       "      <td>2017-09-13 09:45:35</td>\n",
       "      <td>2017-09-13 08:59:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130898c0987d1801452a8ed92a670612</td>\n",
       "      <td>GO</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>55.9</td>\n",
       "      <td>17.96</td>\n",
       "      <td>73.86</td>\n",
       "      <td>2017-06-29 02:44:11</td>\n",
       "      <td>2017-06-28 11:52:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532ed5e14e24ae1f0d735b91524b98b9</td>\n",
       "      <td>MG</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>18.33</td>\n",
       "      <td>83.23</td>\n",
       "      <td>2018-05-18 12:31:43</td>\n",
       "      <td>2018-05-18 10:25:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6f8c31653edb8c83e1a739408b5ff750</td>\n",
       "      <td>PR</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>16.17</td>\n",
       "      <td>75.07</td>\n",
       "      <td>2017-08-01 18:55:08</td>\n",
       "      <td>2017-08-01 18:38:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7d19f4ef4d04461989632411b7e588b9</td>\n",
       "      <td>MG</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>72.19</td>\n",
       "      <td>2017-08-10 22:05:11</td>\n",
       "      <td>2017-08-10 21:48:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id customer_state product_category_name  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214             RJ            cool_stuff   \n",
       "1  130898c0987d1801452a8ed92a670612             GO            cool_stuff   \n",
       "2  532ed5e14e24ae1f0d735b91524b98b9             MG            cool_stuff   \n",
       "3  6f8c31653edb8c83e1a739408b5ff750             PR            cool_stuff   \n",
       "4  7d19f4ef4d04461989632411b7e588b9             MG            cool_stuff   \n",
       "\n",
       "   product_weight_g  review_score  price  freight_value  payment_value  \\\n",
       "0             650.0             5   58.9          13.29          72.19   \n",
       "1             650.0             5   55.9          17.96          73.86   \n",
       "2             650.0             4   64.9          18.33          83.23   \n",
       "3             650.0             5   58.9          16.17          75.07   \n",
       "4             650.0             5   58.9          13.29          72.19   \n",
       "\n",
       "     order_approved_at order_purchase_timestamp  \n",
       "0  2017-09-13 09:45:35      2017-09-13 08:59:02  \n",
       "1  2017-06-29 02:44:11      2017-06-28 11:52:20  \n",
       "2  2018-05-18 12:31:43      2018-05-18 10:25:53  \n",
       "3  2017-08-01 18:55:08      2017-08-01 18:38:42  \n",
       "4  2017-08-10 22:05:11      2017-08-10 21:48:40  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "\n",
    "# Scarica il file dal link\n",
    "url = 'https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/pandas_sql_guide.db'\n",
    "response = requests.get(url)\n",
    "with open('pandas_sql_guide.db', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Crea una connessione al database SQLite locale\n",
    "conn = sqlite3.connect('pandas_sql_guide.db')\n",
    "\n",
    "# Leggi la tabella SQL in un DataFrame pandas\n",
    "df_importato = pd.read_sql('SELECT * FROM pandas_sql_guide', conn).drop(columns='Unnamed: 0')\n",
    "\n",
    "# Chiudi la connessione\n",
    "conn.close()\n",
    "\n",
    "df_importato.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import sqlite3  # or use other database connectors like SQLAlchemy for different databases\\n\\n# Load your CSV file into a DataFrame\\ndf = pd.read_csv('https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/pandas_csv_guide.csv')\\n\\n# Create a connection to a SQLite database (or another database)\\nconn = sqlite3.connect('pandas_sql_guide.db')  # Creates a database file if it doesn't exist\\n\\n# Save the DataFrame to the SQL database\\ndf.to_sql('pandas_sql_guide', conn, if_exists='replace', index=False)\\n\\n# Close the connection\\nconn.close()\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import sqlite3  # or use other database connectors like SQLAlchemy for different databases\n",
    "\n",
    "# Load your CSV file into a DataFrame\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/pandas_csv_guide.csv')\n",
    "\n",
    "# Create a connection to a SQLite database (or another database)\n",
    "conn = sqlite3.connect('pandas_sql_guide.db')  # Creates a database file if it doesn't exist\n",
    "\n",
    "# Save the DataFrame to the SQL database\n",
    "df.to_sql('pandas_sql_guide', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "pip install lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country/Territory</th>\n",
       "      <th colspan=\"2\" halign=\"left\">IMF[4][5]</th>\n",
       "      <th colspan=\"2\" halign=\"left\">World Bank[6]</th>\n",
       "      <th colspan=\"2\" halign=\"left\">United Nations[7]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country/Territory</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>240862</td>\n",
       "      <td>2022</td>\n",
       "      <td>240535</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>187267</td>\n",
       "      <td>2022</td>\n",
       "      <td>197268</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>135321</td>\n",
       "      <td>2024</td>\n",
       "      <td>128259</td>\n",
       "      <td>2023</td>\n",
       "      <td>125897</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bermuda</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>123091</td>\n",
       "      <td>2022</td>\n",
       "      <td>117568</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>106098</td>\n",
       "      <td>2024</td>\n",
       "      <td>99995</td>\n",
       "      <td>2023</td>\n",
       "      <td>93636</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Malawi</td>\n",
       "      <td>464</td>\n",
       "      <td>2024</td>\n",
       "      <td>673</td>\n",
       "      <td>2023</td>\n",
       "      <td>615</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Syria</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>‚Äî</td>\n",
       "      <td>421</td>\n",
       "      <td>2021</td>\n",
       "      <td>840</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>411</td>\n",
       "      <td>2023</td>\n",
       "      <td>353</td>\n",
       "      <td>2022</td>\n",
       "      <td>345</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>South Sudan</td>\n",
       "      <td>341</td>\n",
       "      <td>2024</td>\n",
       "      <td>1072</td>\n",
       "      <td>2015</td>\n",
       "      <td>423</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>321</td>\n",
       "      <td>2024</td>\n",
       "      <td>200</td>\n",
       "      <td>2023</td>\n",
       "      <td>313</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country/Territory IMF[4][5]       World Bank[6]       United Nations[7]  \\\n",
       "    Country/Territory  Estimate  Year      Estimate  Year          Estimate   \n",
       "0              Monaco         ‚Äî     ‚Äî        240862  2022            240535   \n",
       "1       Liechtenstein         ‚Äî     ‚Äî        187267  2022            197268   \n",
       "2          Luxembourg    135321  2024        128259  2023            125897   \n",
       "3             Bermuda         ‚Äî     ‚Äî        123091  2022            117568   \n",
       "4         Switzerland    106098  2024         99995  2023             93636   \n",
       "..                ...       ...   ...           ...   ...               ...   \n",
       "218            Malawi       464  2024           673  2023               615   \n",
       "219             Syria         ‚Äî     ‚Äî           421  2021               840   \n",
       "220       Afghanistan       411  2023           353  2022               345   \n",
       "221       South Sudan       341  2024          1072  2015               423   \n",
       "222           Burundi       321  2024           200  2023               313   \n",
       "\n",
       "           \n",
       "     Year  \n",
       "0    2022  \n",
       "1    2022  \n",
       "2    2022  \n",
       "3    2022  \n",
       "4    2022  \n",
       "..    ...  \n",
       "218  2022  \n",
       "219  2022  \n",
       "220  2022  \n",
       "221  2022  \n",
       "222  2022  \n",
       "\n",
       "[223 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dfs = pd.read_html('https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita')\n",
    "list_of_dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_features = \"https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/UCI%20HAR%20Dataset/features.txt\"\n",
    "filename_labels = \"https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/UCI%20HAR%20Dataset/activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = \"https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/UCI%20HAR%20Dataset/train/subject_train.txt\"\n",
    "filename_xtrain = \"https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/UCI%20HAR%20Dataset/train/X_train.txt\"\n",
    "filename_ytrain = \"https://raw.githubusercontent.com/enzoschitini/Guide-to-Using-Pandas/refs/heads/main/Data/UCI%20HAR%20Dataset/train/y_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(filename_features, header=None, sep=\"#\")\n",
    "features.columns = ['nome_var']\n",
    "labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id'])\\nX_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features['nome_var'].tolist())\\ny_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id'])\n",
    "X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features['nome_var'].tolist())\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.head(n)`` ‚Äì Shows the first n rows of the DataFrame (default: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>RJ</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>72.19</td>\n",
       "      <td>2017-09-13 09:45:35</td>\n",
       "      <td>2017-09-13 08:59:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130898c0987d1801452a8ed92a670612</td>\n",
       "      <td>GO</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>55.9</td>\n",
       "      <td>17.96</td>\n",
       "      <td>73.86</td>\n",
       "      <td>2017-06-29 02:44:11</td>\n",
       "      <td>2017-06-28 11:52:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532ed5e14e24ae1f0d735b91524b98b9</td>\n",
       "      <td>MG</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>18.33</td>\n",
       "      <td>83.23</td>\n",
       "      <td>2018-05-18 12:31:43</td>\n",
       "      <td>2018-05-18 10:25:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6f8c31653edb8c83e1a739408b5ff750</td>\n",
       "      <td>PR</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>16.17</td>\n",
       "      <td>75.07</td>\n",
       "      <td>2017-08-01 18:55:08</td>\n",
       "      <td>2017-08-01 18:38:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7d19f4ef4d04461989632411b7e588b9</td>\n",
       "      <td>MG</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>72.19</td>\n",
       "      <td>2017-08-10 22:05:11</td>\n",
       "      <td>2017-08-10 21:48:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id customer_state product_category_name  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214             RJ            cool_stuff   \n",
       "1  130898c0987d1801452a8ed92a670612             GO            cool_stuff   \n",
       "2  532ed5e14e24ae1f0d735b91524b98b9             MG            cool_stuff   \n",
       "3  6f8c31653edb8c83e1a739408b5ff750             PR            cool_stuff   \n",
       "4  7d19f4ef4d04461989632411b7e588b9             MG            cool_stuff   \n",
       "\n",
       "   product_weight_g  review_score  price  freight_value  payment_value  \\\n",
       "0             650.0             5   58.9          13.29          72.19   \n",
       "1             650.0             5   55.9          17.96          73.86   \n",
       "2             650.0             4   64.9          18.33          83.23   \n",
       "3             650.0             5   58.9          16.17          75.07   \n",
       "4             650.0             5   58.9          13.29          72.19   \n",
       "\n",
       "     order_approved_at order_purchase_timestamp  \n",
       "0  2017-09-13 09:45:35      2017-09-13 08:59:02  \n",
       "1  2017-06-29 02:44:11      2017-06-28 11:52:20  \n",
       "2  2018-05-18 12:31:43      2018-05-18 10:25:53  \n",
       "3  2017-08-01 18:55:08      2017-08-01 18:38:42  \n",
       "4  2017-08-10 22:05:11      2017-08-10 21:48:40  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.tail(n)`` ‚Äì Shows the last n rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>bb0c66e312ff8cb97698f012cd92553c</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>350.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56.99</td>\n",
       "      <td>8.72</td>\n",
       "      <td>65.71</td>\n",
       "      <td>2017-11-22 02:56:28</td>\n",
       "      <td>2017-11-19 17:05:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>c0db7d31ace61fc360a3eaa34dd3457c</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>350.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56.99</td>\n",
       "      <td>8.72</td>\n",
       "      <td>65.71</td>\n",
       "      <td>2018-02-13 16:50:30</td>\n",
       "      <td>2018-02-13 16:36:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>c0db7d31ace61fc360a3eaa34dd3457c</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>350.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56.99</td>\n",
       "      <td>8.72</td>\n",
       "      <td>65.71</td>\n",
       "      <td>2018-02-13 16:50:30</td>\n",
       "      <td>2018-02-13 16:36:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>c90025afa3c59ad0768b713161777935</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>350.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56.99</td>\n",
       "      <td>8.72</td>\n",
       "      <td>65.71</td>\n",
       "      <td>2018-03-01 02:50:46</td>\n",
       "      <td>2018-02-28 12:59:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>cc3336764b2bc18f4eaa8f17f86bfd53</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>350.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56.99</td>\n",
       "      <td>7.78</td>\n",
       "      <td>64.77</td>\n",
       "      <td>2017-06-11 17:55:17</td>\n",
       "      <td>2017-06-11 17:43:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              order_id customer_state product_category_name  \\\n",
       "2017  bb0c66e312ff8cb97698f012cd92553c             SP            perfumaria   \n",
       "2018  c0db7d31ace61fc360a3eaa34dd3457c             SP            perfumaria   \n",
       "2019  c0db7d31ace61fc360a3eaa34dd3457c             SP            perfumaria   \n",
       "2020  c90025afa3c59ad0768b713161777935             SP            perfumaria   \n",
       "2021  cc3336764b2bc18f4eaa8f17f86bfd53             SP            perfumaria   \n",
       "\n",
       "      product_weight_g  review_score  price  freight_value  payment_value  \\\n",
       "2017             350.0             5  56.99           8.72          65.71   \n",
       "2018             350.0             5  56.99           8.72          65.71   \n",
       "2019             350.0             5  56.99           8.72          65.71   \n",
       "2020             350.0             5  56.99           8.72          65.71   \n",
       "2021             350.0             5  56.99           7.78          64.77   \n",
       "\n",
       "        order_approved_at order_purchase_timestamp  \n",
       "2017  2017-11-22 02:56:28      2017-11-19 17:05:09  \n",
       "2018  2018-02-13 16:50:30      2018-02-13 16:36:56  \n",
       "2019  2018-02-13 16:50:30      2018-02-13 16:36:56  \n",
       "2020  2018-03-01 02:50:46      2018-02-28 12:59:08  \n",
       "2021  2017-06-11 17:55:17      2017-06-11 17:43:18  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.tail(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.shape`` ‚Äì Returns the dimensions (rows, columns) of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2022, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.columns`` ‚Äì Lists the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id', 'customer_state', 'product_category_name',\n",
       "       'product_weight_g', 'review_score', 'price', 'freight_value',\n",
       "       'payment_value', 'order_approved_at', 'order_purchase_timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('Country/Territory', 'Country/Territory'),\n",
       "            (        'IMF[4][5]',          'Estimate'),\n",
       "            (        'IMF[4][5]',              'Year'),\n",
       "            (    'World Bank[6]',          'Estimate'),\n",
       "            (    'World Bank[6]',              'Year'),\n",
       "            ('United Nations[7]',          'Estimate'),\n",
       "            ('United Nations[7]',              'Year')],\n",
       "           )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dfs[1].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.info()`` ‚Äì Displays information about the DataFrame (column types, non-null counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2022 entries, 0 to 2021\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   order_id                  2022 non-null   object \n",
      " 1   customer_state            2022 non-null   object \n",
      " 2   product_category_name     2022 non-null   object \n",
      " 3   product_weight_g          2022 non-null   float64\n",
      " 4   review_score              2022 non-null   int64  \n",
      " 5   price                     2022 non-null   float64\n",
      " 6   freight_value             2022 non-null   float64\n",
      " 7   payment_value             2022 non-null   float64\n",
      " 8   order_approved_at         2022 non-null   object \n",
      " 9   order_purchase_timestamp  2022 non-null   object \n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 158.1+ KB\n"
     ]
    }
   ],
   "source": [
    "csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo `info()` di un oggetto DataFrame di Pandas fornisce un riepilogo conciso del contenuto del DataFrame, mostrando dettagli utili per l'analisi preliminare del dataset. I parametri principali di `info()` sono:\n",
    "\n",
    "- `verbose`: (default `None`) Se impostato su `True`, mostrer√† tutte le colonne, altrimenti una vista abbreviata (utile per dataset di grandi dimensioni).\n",
    "- `buf`: (default `None`) Specifica l'output su un oggetto come un file. Se impostato su `None`, l'output viene stampato sulla console.\n",
    "- `max_cols`: (default `None`) Limita il numero di colonne da visualizzare nel riepilogo.\n",
    "- `memory_usage`: (default `True`) Mostra l'uso della memoria del DataFrame. Pu√≤ essere impostato su `'deep'` per avere una stima pi√π precisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2022 entries, 0 to 2021\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   order_id                  2022 non-null   object \n",
      " 1   customer_state            2022 non-null   object \n",
      " 2   product_category_name     2022 non-null   object \n",
      " 3   product_weight_g          2022 non-null   float64\n",
      " 4   review_score              2022 non-null   int64  \n",
      " 5   price                     2022 non-null   float64\n",
      " 6   freight_value             2022 non-null   float64\n",
      " 7   payment_value             2022 non-null   float64\n",
      " 8   order_approved_at         2022 non-null   object \n",
      " 9   order_purchase_timestamp  2022 non-null   object \n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 727.2 KB\n"
     ]
    }
   ],
   "source": [
    "csv.info(verbose=True, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.describe()`` ‚Äì Provides descriptive statistics for numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1154.325915</td>\n",
       "      <td>4.017310</td>\n",
       "      <td>73.512992</td>\n",
       "      <td>15.884327</td>\n",
       "      <td>100.126632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2643.718753</td>\n",
       "      <td>1.381362</td>\n",
       "      <td>63.045769</td>\n",
       "      <td>9.318311</td>\n",
       "      <td>111.499859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>203.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>51.900000</td>\n",
       "      <td>11.680000</td>\n",
       "      <td>65.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.990000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>76.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>950.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>84.990000</td>\n",
       "      <td>17.680000</td>\n",
       "      <td>106.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>185.730000</td>\n",
       "      <td>1525.780000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_weight_g  review_score        price  freight_value  \\\n",
       "count       2022.000000   2022.000000  2022.000000    2022.000000   \n",
       "mean        1154.325915      4.017310    73.512992      15.884327   \n",
       "std         2643.718753      1.381362    63.045769       9.318311   \n",
       "min           50.000000      1.000000     2.990000       0.000000   \n",
       "25%          203.750000      3.000000    51.900000      11.680000   \n",
       "50%          350.000000      5.000000    58.990000      15.150000   \n",
       "75%          950.000000      5.000000    84.990000      17.680000   \n",
       "max        30000.000000      5.000000  1050.000000     185.730000   \n",
       "\n",
       "       payment_value  \n",
       "count    2022.000000  \n",
       "mean      100.126632  \n",
       "std       111.499859  \n",
       "min         0.220000  \n",
       "25%        65.710000  \n",
       "50%        76.650000  \n",
       "75%       106.380000  \n",
       "max      1525.780000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo `describe()` √® utilizzato in Pandas per generare statistiche descrittive di un DataFrame o di una Serie. Per impostazione predefinita, restituisce le statistiche per le colonne numeriche, ma pu√≤ essere utilizzato anche per dati categorici. Ecco una panoramica dei principali parametri:\n",
    "\n",
    "#### Principali Parametri di `describe()`\n",
    "\n",
    "1. **`percentiles`**: Specifica i percentili che vuoi calcolare. Per impostazione predefinita, include il 25¬∞, 50¬∞ (mediana) e il 75¬∞ percentile. Puoi specificare una lista di percentuali per ottenere valori personalizzati.\n",
    "    - *Tipo*: array-like di numeri tra 0 e 1.\n",
    "    - *Valore predefinito*: `[0.25, 0.5, 0.75]`.\n",
    "2. **`include`**: Specifica quali tipi di dati includere nella descrizione. Pu√≤ essere impostato su `None` (comportamento predefinito, solo colonne numeriche), `all` (tutti i tipi di dati) oppure su un elenco di tipi di dati come `['object']` o `['number']`.\n",
    "    - *Valore predefinito*: `None`.\n",
    "3. **`exclude`**: Specifica quali tipi di dati escludere dall'analisi. Funziona in modo complementare a `include`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1154.325915</td>\n",
       "      <td>4.017310</td>\n",
       "      <td>73.512992</td>\n",
       "      <td>15.884327</td>\n",
       "      <td>100.126632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2643.718753</td>\n",
       "      <td>1.381362</td>\n",
       "      <td>63.045769</td>\n",
       "      <td>9.318311</td>\n",
       "      <td>111.499859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.720000</td>\n",
       "      <td>29.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.990000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>76.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>2245.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>118.900000</td>\n",
       "      <td>23.161000</td>\n",
       "      <td>162.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>185.730000</td>\n",
       "      <td>1525.780000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_weight_g  review_score        price  freight_value  \\\n",
       "count       2022.000000   2022.000000  2022.000000    2022.000000   \n",
       "mean        1154.325915      4.017310    73.512992      15.884327   \n",
       "std         2643.718753      1.381362    63.045769       9.318311   \n",
       "min           50.000000      1.000000     2.990000       0.000000   \n",
       "10%          200.000000      1.000000    21.000000       8.720000   \n",
       "50%          350.000000      5.000000    58.990000      15.150000   \n",
       "90%         2245.000000      5.000000   118.900000      23.161000   \n",
       "max        30000.000000      5.000000  1050.000000     185.730000   \n",
       "\n",
       "       payment_value  \n",
       "count    2022.000000  \n",
       "mean      100.126632  \n",
       "std       111.499859  \n",
       "min         0.220000  \n",
       "10%        29.560000  \n",
       "50%        76.650000  \n",
       "90%       162.070000  \n",
       "max      1525.780000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.describe(percentiles=[0.1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1735</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1734</td>\n",
       "      <td>1735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>370e2e6c1a9fd451eb7f0852daa3b006</td>\n",
       "      <td>SP</td>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-11 18:34:44</td>\n",
       "      <td>2017-03-11 18:34:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11</td>\n",
       "      <td>849</td>\n",
       "      <td>766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1154.325915</td>\n",
       "      <td>4.017310</td>\n",
       "      <td>73.512992</td>\n",
       "      <td>15.884327</td>\n",
       "      <td>100.126632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2643.718753</td>\n",
       "      <td>1.381362</td>\n",
       "      <td>63.045769</td>\n",
       "      <td>9.318311</td>\n",
       "      <td>111.499859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>51.900000</td>\n",
       "      <td>11.680000</td>\n",
       "      <td>65.710000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.990000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>76.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>84.990000</td>\n",
       "      <td>17.680000</td>\n",
       "      <td>106.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>185.730000</td>\n",
       "      <td>1525.780000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                order_id customer_state product_category_name  \\\n",
       "count                               2022           2022                  2022   \n",
       "unique                              1735             27                    21   \n",
       "top     370e2e6c1a9fd451eb7f0852daa3b006             SP          beleza_saude   \n",
       "freq                                  11            849                   766   \n",
       "mean                                 NaN            NaN                   NaN   \n",
       "std                                  NaN            NaN                   NaN   \n",
       "min                                  NaN            NaN                   NaN   \n",
       "25%                                  NaN            NaN                   NaN   \n",
       "50%                                  NaN            NaN                   NaN   \n",
       "75%                                  NaN            NaN                   NaN   \n",
       "max                                  NaN            NaN                   NaN   \n",
       "\n",
       "        product_weight_g  review_score        price  freight_value  \\\n",
       "count        2022.000000   2022.000000  2022.000000    2022.000000   \n",
       "unique               NaN           NaN          NaN            NaN   \n",
       "top                  NaN           NaN          NaN            NaN   \n",
       "freq                 NaN           NaN          NaN            NaN   \n",
       "mean         1154.325915      4.017310    73.512992      15.884327   \n",
       "std          2643.718753      1.381362    63.045769       9.318311   \n",
       "min            50.000000      1.000000     2.990000       0.000000   \n",
       "25%           203.750000      3.000000    51.900000      11.680000   \n",
       "50%           350.000000      5.000000    58.990000      15.150000   \n",
       "75%           950.000000      5.000000    84.990000      17.680000   \n",
       "max         30000.000000      5.000000  1050.000000     185.730000   \n",
       "\n",
       "        payment_value    order_approved_at order_purchase_timestamp  \n",
       "count     2022.000000                 2022                     2022  \n",
       "unique            NaN                 1734                     1735  \n",
       "top               NaN  2017-03-11 18:34:44      2017-03-11 18:34:44  \n",
       "freq              NaN                   11                       11  \n",
       "mean       100.126632                  NaN                      NaN  \n",
       "std        111.499859                  NaN                      NaN  \n",
       "min          0.220000                  NaN                      NaN  \n",
       "25%         65.710000                  NaN                      NaN  \n",
       "50%         76.650000                  NaN                      NaN  \n",
       "75%        106.380000                  NaN                      NaN  \n",
       "max       1525.780000                  NaN                      NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.dtypes`` ‚Äì Returns data types of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                     object\n",
       "customer_state               object\n",
       "product_category_name        object\n",
       "product_weight_g            float64\n",
       "review_score                  int64\n",
       "price                       float64\n",
       "freight_value               float64\n",
       "payment_value               float64\n",
       "order_approved_at            object\n",
       "order_purchase_timestamp     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.index`` ‚Äì Returns the index (row labels) of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2022, step=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.value_counts()`` ‚Äì Counts unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                          customer_state  product_category_name   product_weight_g  review_score  price  freight_value  payment_value  order_approved_at    order_purchase_timestamp\n",
       "2f839b79d9954ebfedeeba654f0f3de8  SP              telefonia               150.0             5             7.00   7.39           71.95          2018-03-26 14:50:21  2018-03-26 14:40:10         5\n",
       "8a8bd4a338e17ace44431e99a2add1d2  DF              dvds_blu_ray            2150.0            5             83.99  18.17          20.00          2018-05-15 21:54:02  2018-05-15 21:31:55         5\n",
       "58346246ea802a21cb34124ed2326770  SP              perfumaria              200.0             5             44.99  7.58           210.28         2018-07-11 17:25:53  2018-07-11 17:17:37         4\n",
       "05fcd933547be81890bc4d62357fdf3f  SP              informatica_acessorios  300.0             1             89.90  12.13          408.12         2017-07-19 10:30:13  2017-07-19 10:17:34         4\n",
       "84ddfd4c559558c53b5a4c6765e49be8  SP              utilidades_domesticas   250.0             1             5.90   7.39           53.16          2018-08-09 21:44:52  2018-08-09 21:31:52         4\n",
       "                                                                                                                                                                                               ..\n",
       "55ff9b1565b988a5125bc8f70a9df367  SP              perfumaria              350.0             4             56.99  8.72           65.71          2017-10-20 13:28:06  2017-10-20 13:10:04         1\n",
       "55f8a030ae34836632355176608c7314  SP              telefonia               150.0             1             19.90  7.11           125.44         2018-01-22 15:13:00  2018-01-22 14:55:18         1\n",
       "55f2d8cb4b644ca9cc2da77732fd1117  RJ              cool_stuff              650.0             4             49.40  9.94           59.34          2017-10-15 14:14:18  2017-10-15 13:56:49         1\n",
       "55d18e6e778d8bbc28aff36ab14104ba  SP              perfumaria              200.0             5             53.99  7.78           61.77          2017-11-28 22:31:34  2017-11-28 21:58:05         1\n",
       "ff92fd3088a85112214acbc08d72afbf  SP              livros_tecnicos         950.0             5             57.89  11.15          69.04          2018-05-22 20:37:13  2018-05-22 20:17:56         1\n",
       "Name: count, Length: 1885, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo `.value_counts()` in Pandas √® utilizzato per ottenere una distribuzione delle occorrenze uniche dei valori in una Serie (o in una colonna di un DataFrame). √à molto utile per esplorare i dati categorici o per comprendere la distribuzione dei valori in una colonna.\n",
    "\n",
    "#### Principali Parametri di `.value_counts()`\n",
    "\n",
    "1. **`normalize`**: Se impostato a `True`, restituisce le frequenze relative dei valori invece dei conteggi assoluti.\n",
    "    - *Tipo*: booleano (`True` o `False`).\n",
    "    - *Valore predefinito*: `False`.\n",
    "2. **`sort`**: Specifica se ordinare i risultati in base ai conteggi (in ordine decrescente). Se impostato a `False`, non ordina i valori.\n",
    "    - *Tipo*: booleano (`True` o `False`).\n",
    "    - *Valore predefinito*: `True`.\n",
    "3. **`ascending`**: Se impostato a `True`, ordina i risultati in ordine crescente.\n",
    "    - *Tipo*: booleano (`True` o `False`).\n",
    "    - *Valore predefinito*: `False`.\n",
    "4. **`bins`**: Consente di suddividere i dati numerici in intervalli (binning).\n",
    "    - *Tipo*: intero.\n",
    "    - *Valore predefinito*: `None`.\n",
    "5. **`dropna`**: Se impostato a `False`, include i valori `NaN` nel conteggio.\n",
    "    - *Tipo*: booleano (`True` o `False`).\n",
    "    - *Valore predefinito*: `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_state\n",
       "SP    0.419881\n",
       "MG    0.124135\n",
       "RJ    0.112760\n",
       "RS    0.048467\n",
       "BA    0.044510\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.value_counts('customer_state', normalize=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_state\n",
       "AC    1\n",
       "RR    2\n",
       "AP    3\n",
       "TO    3\n",
       "SE    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.value_counts('customer_state', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_state\n",
       "SP    849\n",
       "MG    251\n",
       "RJ    228\n",
       "RS     98\n",
       "BA     90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.value_counts('customer_state', dropna=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9420000000000002, 351.993]    2007\n",
       "(351.993, 700.997]                 10\n",
       "(700.997, 1050.0]                   5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv['price'].value_counts(bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.isnull() / .notnull()`` ‚Äì Checks for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I metodi `.isnull()` e `.notnull()` in Pandas sono utilizzati per identificare i valori mancanti (o nulli) in un DataFrame o una Serie. Entrambi i metodi restituiscono un oggetto della stessa forma con valori booleani (`True` o `False`), che indicano rispettivamente la presenza o l'assenza di valori nulli.\n",
    "\n",
    "#### `.isnull()`\n",
    "\n",
    "Questo metodo identifica i valori `NaN` (Not a Number) o `None` come `True` e gli altri valori come `False`.\n",
    "\n",
    "#### Esempio di utilizzo di `.isnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id  customer_state  product_category_name  product_weight_g  \\\n",
       "0        False           False                  False             False   \n",
       "1        False           False                  False             False   \n",
       "2        False           False                  False             False   \n",
       "3        False           False                  False             False   \n",
       "4        False           False                  False             False   \n",
       "...        ...             ...                    ...               ...   \n",
       "2017     False           False                  False             False   \n",
       "2018     False           False                  False             False   \n",
       "2019     False           False                  False             False   \n",
       "2020     False           False                  False             False   \n",
       "2021     False           False                  False             False   \n",
       "\n",
       "      review_score  price  freight_value  payment_value  order_approved_at  \\\n",
       "0            False  False          False          False              False   \n",
       "1            False  False          False          False              False   \n",
       "2            False  False          False          False              False   \n",
       "3            False  False          False          False              False   \n",
       "4            False  False          False          False              False   \n",
       "...            ...    ...            ...            ...                ...   \n",
       "2017         False  False          False          False              False   \n",
       "2018         False  False          False          False              False   \n",
       "2019         False  False          False          False              False   \n",
       "2020         False  False          False          False              False   \n",
       "2021         False  False          False          False              False   \n",
       "\n",
       "      order_purchase_timestamp  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "...                        ...  \n",
       "2017                     False  \n",
       "2018                     False  \n",
       "2019                     False  \n",
       "2020                     False  \n",
       "2021                     False  \n",
       "\n",
       "[2022 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I `True` indicano la presenza di valori mancanti (nulli).\n",
    "\n",
    "#### Uso comune: Conteggio dei Valori Nulli\n",
    "\n",
    "Puoi usare `.isnull().sum()` per contare il numero di valori nulli in ogni colonna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                    0\n",
       "customer_state              0\n",
       "product_category_name       0\n",
       "product_weight_g            0\n",
       "review_score                0\n",
       "price                       0\n",
       "freight_value               0\n",
       "payment_value               0\n",
       "order_approved_at           0\n",
       "order_purchase_timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.notnull()`\n",
    "\n",
    "Questo metodo √® l'opposto di `.isnull()`, identificando i valori **non nulli** (ossia `NaN` e `None` sono marcati come `False`, mentre gli altri valori come `True`).\n",
    "\n",
    "#### Esempio di utilizzo di `.notnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id  customer_state  product_category_name  product_weight_g  \\\n",
       "0         True            True                   True              True   \n",
       "1         True            True                   True              True   \n",
       "2         True            True                   True              True   \n",
       "3         True            True                   True              True   \n",
       "4         True            True                   True              True   \n",
       "...        ...             ...                    ...               ...   \n",
       "2017      True            True                   True              True   \n",
       "2018      True            True                   True              True   \n",
       "2019      True            True                   True              True   \n",
       "2020      True            True                   True              True   \n",
       "2021      True            True                   True              True   \n",
       "\n",
       "      review_score  price  freight_value  payment_value  order_approved_at  \\\n",
       "0             True   True           True           True               True   \n",
       "1             True   True           True           True               True   \n",
       "2             True   True           True           True               True   \n",
       "3             True   True           True           True               True   \n",
       "4             True   True           True           True               True   \n",
       "...            ...    ...            ...            ...                ...   \n",
       "2017          True   True           True           True               True   \n",
       "2018          True   True           True           True               True   \n",
       "2019          True   True           True           True               True   \n",
       "2020          True   True           True           True               True   \n",
       "2021          True   True           True           True               True   \n",
       "\n",
       "      order_purchase_timestamp  \n",
       "0                         True  \n",
       "1                         True  \n",
       "2                         True  \n",
       "3                         True  \n",
       "4                         True  \n",
       "...                        ...  \n",
       "2017                      True  \n",
       "2018                      True  \n",
       "2019                      True  \n",
       "2020                      True  \n",
       "2021                      True  \n",
       "\n",
       "[2022 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I `True` indicano la presenza di valori **non** nulli.\n",
    "\n",
    "#### Esempi pratici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Filtrare i valori non nulli in una colonna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>RJ</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>72.19</td>\n",
       "      <td>2017-09-13 09:45:35</td>\n",
       "      <td>2017-09-13 08:59:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130898c0987d1801452a8ed92a670612</td>\n",
       "      <td>GO</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>55.9</td>\n",
       "      <td>17.96</td>\n",
       "      <td>73.86</td>\n",
       "      <td>2017-06-29 02:44:11</td>\n",
       "      <td>2017-06-28 11:52:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532ed5e14e24ae1f0d735b91524b98b9</td>\n",
       "      <td>MG</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>18.33</td>\n",
       "      <td>83.23</td>\n",
       "      <td>2018-05-18 12:31:43</td>\n",
       "      <td>2018-05-18 10:25:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6f8c31653edb8c83e1a739408b5ff750</td>\n",
       "      <td>PR</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>16.17</td>\n",
       "      <td>75.07</td>\n",
       "      <td>2017-08-01 18:55:08</td>\n",
       "      <td>2017-08-01 18:38:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7d19f4ef4d04461989632411b7e588b9</td>\n",
       "      <td>MG</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>72.19</td>\n",
       "      <td>2017-08-10 22:05:11</td>\n",
       "      <td>2017-08-10 21:48:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id customer_state product_category_name  \\\n",
       "0  00010242fe8c5a6d1ba2dd792cb16214             RJ            cool_stuff   \n",
       "1  130898c0987d1801452a8ed92a670612             GO            cool_stuff   \n",
       "2  532ed5e14e24ae1f0d735b91524b98b9             MG            cool_stuff   \n",
       "3  6f8c31653edb8c83e1a739408b5ff750             PR            cool_stuff   \n",
       "4  7d19f4ef4d04461989632411b7e588b9             MG            cool_stuff   \n",
       "\n",
       "   product_weight_g  review_score  price  freight_value  payment_value  \\\n",
       "0             650.0             5   58.9          13.29          72.19   \n",
       "1             650.0             5   55.9          17.96          73.86   \n",
       "2             650.0             4   64.9          18.33          83.23   \n",
       "3             650.0             5   58.9          16.17          75.07   \n",
       "4             650.0             5   58.9          13.29          72.19   \n",
       "\n",
       "     order_approved_at order_purchase_timestamp  \n",
       "0  2017-09-13 09:45:35      2017-09-13 08:59:02  \n",
       "1  2017-06-29 02:44:11      2017-06-28 11:52:20  \n",
       "2  2018-05-18 12:31:43      2018-05-18 10:25:53  \n",
       "3  2017-08-01 18:55:08      2017-08-01 18:38:42  \n",
       "4  2017-08-10 22:05:11      2017-08-10 21:48:40  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_null = csv[csv['product_category_name'].notnull()]\n",
    "df_non_null.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Verificare se ci sono valori nulli nel DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Contare i valori non nulli in ogni colonna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                    2022\n",
       "customer_state              2022\n",
       "product_category_name       2022\n",
       "product_weight_g            2022\n",
       "review_score                2022\n",
       "price                       2022\n",
       "freight_value               2022\n",
       "payment_value               2022\n",
       "order_approved_at           2022\n",
       "order_purchase_timestamp    2022\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differenza tra i due\n",
    "\n",
    "- **`.isnull()`**: Restituisce `True` per i valori nulli.\n",
    "- **`.notnull()`**: Restituisce `True` per i valori **non** nulli.\n",
    "\n",
    "Questi metodi sono molto utili per gestire i valori mancanti nei dataset, una parte essenziale dell'analisi dei dati e della pulizia dei dati. Se hai altre domande, sono qui per aiutarti!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.duplicated()`` ‚Äì Checks for duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo `.duplicated()` in Pandas √® utilizzato per identificare le righe duplicate in un DataFrame o gli elementi duplicati in una Serie. Restituisce una Serie di valori booleani in cui `True` indica che una riga o un elemento √® un duplicato di una precedente e `False` indica che non lo √®.\n",
    "\n",
    "#### Principali Parametri di `.duplicated()`\n",
    "\n",
    "1. **`subset`**: Specifica le colonne su cui controllare i duplicati. Se non viene specificato, il controllo viene eseguito su tutte le colonne.\n",
    "    - *Tipo*: lista di stringhe (nomi di colonne).\n",
    "    - *Valore predefinito*: `None`.\n",
    "2. **`keep`**: Determina quale duplicato (se ce ne sono) contrassegnare come `True`.\n",
    "    - `\"first\"`: Marca tutte le duplicazioni successive come `True`, mantenendo il primo valore come unico (`False`).\n",
    "    - `\"last\"`: Marca tutte le duplicazioni precedenti come `True`, mantenendo l'ultimo valore come unico (`False`).\n",
    "    - `False`: Marca **tutti** i duplicati come `True`.\n",
    "    - *Valore predefinito*: `\"first\"`.\n",
    "\n",
    "#### Esempio di Utilizzo di `.duplicated()`\n",
    "\n",
    "#### Esempio 1: Identificare le righe duplicate in un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2017    False\n",
       "2018    False\n",
       "2019     True\n",
       "2020    False\n",
       "2021    False\n",
       "Length: 2022, dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 2: Utilizzare il parametro `keep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2017    False\n",
       "2018     True\n",
       "2019    False\n",
       "2020    False\n",
       "2021    False\n",
       "Length: 2022, dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mantenere solo l'ultima occorrenza come unica\n",
    "csv.duplicated(keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In questo caso, vengono mantenute le ultime occorrenze e le precedenti vengono considerate duplicate.\n",
    "\n",
    "#### Esempio 3: Identificare i duplicati basandosi su colonne specifiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "2017     True\n",
       "2018     True\n",
       "2019     True\n",
       "2020     True\n",
       "2021     True\n",
       "Length: 2022, dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.duplicated(subset='product_category_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 4: Marcatura di **tutti** i duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2017    False\n",
       "2018     True\n",
       "2019     True\n",
       "2020    False\n",
       "2021    False\n",
       "Length: 2022, dtype: bool"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `.duplicated()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = csv.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.nunique()`` ‚Äì Counts the number of unique values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo `.nunique()` in Pandas viene utilizzato per contare il numero di valori unici (distinti) presenti in ogni colonna di un DataFrame o in una Serie. Questo √® utile per avere una rapida panoramica della variet√† di dati all'interno di ogni colonna.\n",
    "\n",
    "#### Principali Parametri di `.nunique()`\n",
    "\n",
    "1. **`axis`**: Specifica se contare i valori unici per colonne o per righe.\n",
    "    - *Valore predefinito*: `0` o `'index'` (conteggio dei valori unici per colonna).\n",
    "    - Se `axis=1` o `'columns'`, conta i valori unici per ogni riga.\n",
    "2. **`dropna`**: Indica se escludere (`True`) o includere (`False`) i valori mancanti (NaN) nel conteggio.\n",
    "    - *Valore predefinito*: `True` (esclude i valori mancanti).\n",
    "\n",
    "#### Esempi di Utilizzo di `.nunique()`\n",
    "\n",
    "#### Esempio 1: Contare i valori unici in un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                    1735\n",
       "customer_state                27\n",
       "product_category_name         21\n",
       "product_weight_g             119\n",
       "review_score                   5\n",
       "price                        229\n",
       "freight_value                572\n",
       "payment_value                902\n",
       "order_approved_at           1734\n",
       "order_purchase_timestamp    1735\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 2: Contare i valori unici, inclusi i valori nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                    1735\n",
       "customer_state                27\n",
       "product_category_name         21\n",
       "product_weight_g             119\n",
       "review_score                   5\n",
       "price                        229\n",
       "freight_value                572\n",
       "payment_value                902\n",
       "order_approved_at           1734\n",
       "order_purchase_timestamp    1735\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 3: Contare i valori unici lungo le righe (con axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10\n",
       "1       10\n",
       "2       10\n",
       "3       10\n",
       "4       10\n",
       "        ..\n",
       "2017    10\n",
       "2018    10\n",
       "2019    10\n",
       "2020    10\n",
       "2021    10\n",
       "Length: 2022, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.nunique(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``.sample(n)`` ‚Äì Randomly selects n rows from the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo `.sample()` in Pandas viene utilizzato per estrarre un campione casuale di righe o colonne da un DataFrame o da una Serie. Pu√≤ essere utile per esplorare una parte dei dati in modo casuale o per generare un sottocampione per l'analisi.\n",
    "\n",
    "#### Principali Parametri di `.sample()`\n",
    "\n",
    "1. **`n`**: Specifica il numero di elementi (righe o colonne) da campionare.\n",
    "    - *Tipo*: intero.\n",
    "    - Non pu√≤ essere utilizzato contemporaneamente con il parametro `frac`.\n",
    "2. **`frac`**: Specifica la frazione di elementi da campionare rispetto al totale.\n",
    "    - *Tipo*: float, ad esempio `frac=0.5` campiona il 50% degli elementi.\n",
    "    - Non pu√≤ essere utilizzato insieme al parametro `n`.\n",
    "3. **`replace`**: Se `True`, consente il campionamento con ripetizione (ossia, gli stessi elementi possono essere estratti pi√π di una volta).\n",
    "    - *Tipo*: booleano.\n",
    "    - *Valore predefinito*: `False`.\n",
    "4. **`weights`**: Determina le probabilit√† con cui ogni elemento √® campionato. Pu√≤ essere una colonna del DataFrame o un array-like di pesi.\n",
    "    - *Tipo*: array-like o nome di colonna.\n",
    "5. **`random_state`**: Un seme o seed per la generazione di numeri casuali, che rende il campionamento riproducibile.\n",
    "    - *Tipo*: intero.\n",
    "6. **`axis`**: Specifica se campionare righe o colonne.\n",
    "    - `axis=0` o `'index'` per campionare righe (valore predefinito).\n",
    "    - `axis=1` o `'columns'` per campionare colonne.\n",
    "\n",
    "#### Esempi di Utilizzo di `.sample()`\n",
    "\n",
    "#### Esempio 1: Campionare un numero fisso di righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1a6c3832fcc2947c38b41bd24fe0201e</td>\n",
       "      <td>CE</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>45.90</td>\n",
       "      <td>35.67</td>\n",
       "      <td>81.57</td>\n",
       "      <td>2017-06-30 15:50:15</td>\n",
       "      <td>2017-06-30 15:31:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>807e1137296f0952dc5038aadf9d1f76</td>\n",
       "      <td>MG</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.99</td>\n",
       "      <td>15.13</td>\n",
       "      <td>69.12</td>\n",
       "      <td>2018-02-07 02:55:55</td>\n",
       "      <td>2018-02-06 16:33:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              order_id customer_state product_category_name  \\\n",
       "81    1a6c3832fcc2947c38b41bd24fe0201e             CE            cool_stuff   \n",
       "1165  807e1137296f0952dc5038aadf9d1f76             MG            perfumaria   \n",
       "\n",
       "      product_weight_g  review_score  price  freight_value  payment_value  \\\n",
       "81               650.0             5  45.90          35.67          81.57   \n",
       "1165             200.0             2  53.99          15.13          69.12   \n",
       "\n",
       "        order_approved_at order_purchase_timestamp  \n",
       "81    2017-06-30 15:50:15      2017-06-30 15:31:51  \n",
       "1165  2018-02-07 02:55:55      2018-02-06 16:33:24  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.sample(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 2: Campionare una frazione di righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>9b643bf8a8614206d936530d416aef57</td>\n",
       "      <td>PR</td>\n",
       "      <td>audio</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.90</td>\n",
       "      <td>14.10</td>\n",
       "      <td>34.00</td>\n",
       "      <td>2017-11-22 11:54:27</td>\n",
       "      <td>2017-11-22 11:42:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>bde305d08669a1b46554c10f03a85675</td>\n",
       "      <td>RJ</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.90</td>\n",
       "      <td>17.93</td>\n",
       "      <td>47.83</td>\n",
       "      <td>2018-05-08 01:11:58</td>\n",
       "      <td>2018-05-08 00:45:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>7c3e480eb90c173aae4ffde40bbaec26</td>\n",
       "      <td>SP</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>575.0</td>\n",
       "      <td>5</td>\n",
       "      <td>58.90</td>\n",
       "      <td>21.32</td>\n",
       "      <td>142.57</td>\n",
       "      <td>2017-08-23 02:55:54</td>\n",
       "      <td>2017-08-22 10:14:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>5ef2b9c9a5e997664dcaacc5fa769e07</td>\n",
       "      <td>PR</td>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>5</td>\n",
       "      <td>164.90</td>\n",
       "      <td>16.36</td>\n",
       "      <td>181.26</td>\n",
       "      <td>2017-03-25 02:10:41</td>\n",
       "      <td>2017-03-23 23:55:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2f839b79d9954ebfedeeba654f0f3de8</td>\n",
       "      <td>SP</td>\n",
       "      <td>telefonia</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.39</td>\n",
       "      <td>71.95</td>\n",
       "      <td>2018-03-26 14:50:21</td>\n",
       "      <td>2018-03-26 14:40:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>57c2914d78f0d7f4b76089b7844e77ea</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>550.0</td>\n",
       "      <td>3</td>\n",
       "      <td>84.99</td>\n",
       "      <td>8.79</td>\n",
       "      <td>93.78</td>\n",
       "      <td>2017-07-11 21:36:01</td>\n",
       "      <td>2017-07-11 20:58:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>bca3dc20a3ec02261c5b17dc270e9e65</td>\n",
       "      <td>MG</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>550.0</td>\n",
       "      <td>5</td>\n",
       "      <td>84.99</td>\n",
       "      <td>16.35</td>\n",
       "      <td>101.34</td>\n",
       "      <td>2017-12-06 02:50:38</td>\n",
       "      <td>2017-12-05 10:34:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>8092a1edb9b302ea942c2671edf4737c</td>\n",
       "      <td>SP</td>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.99</td>\n",
       "      <td>13.07</td>\n",
       "      <td>72.06</td>\n",
       "      <td>2018-06-29 16:11:39</td>\n",
       "      <td>2018-06-29 15:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>d339c3ad62c16e15e4c2f3e39abd1abb</td>\n",
       "      <td>RS</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4</td>\n",
       "      <td>56.99</td>\n",
       "      <td>16.10</td>\n",
       "      <td>73.09</td>\n",
       "      <td>2017-04-15 11:55:08</td>\n",
       "      <td>2017-04-15 11:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>acc3d23f43622a2ad8db0ee9d65003cf</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56.99</td>\n",
       "      <td>8.72</td>\n",
       "      <td>65.71</td>\n",
       "      <td>2018-01-10 10:32:24</td>\n",
       "      <td>2018-01-09 21:08:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              order_id customer_state product_category_name  \\\n",
       "427   9b643bf8a8614206d936530d416aef57             PR                 audio   \n",
       "242   bde305d08669a1b46554c10f03a85675             RJ              pet_shop   \n",
       "113   7c3e480eb90c173aae4ffde40bbaec26             SP            cool_stuff   \n",
       "760   5ef2b9c9a5e997664dcaacc5fa769e07             PR          beleza_saude   \n",
       "981   2f839b79d9954ebfedeeba654f0f3de8             SP             telefonia   \n",
       "...                                ...            ...                   ...   \n",
       "1041  57c2914d78f0d7f4b76089b7844e77ea             SP            perfumaria   \n",
       "1074  bca3dc20a3ec02261c5b17dc270e9e65             MG            perfumaria   \n",
       "1603  8092a1edb9b302ea942c2671edf4737c             SP          beleza_saude   \n",
       "1768  d339c3ad62c16e15e4c2f3e39abd1abb             RS            perfumaria   \n",
       "1864  acc3d23f43622a2ad8db0ee9d65003cf             SP            perfumaria   \n",
       "\n",
       "      product_weight_g  review_score   price  freight_value  payment_value  \\\n",
       "427              167.0             2   19.90          14.10          34.00   \n",
       "242             7300.0             5   29.90          17.93          47.83   \n",
       "113              575.0             5   58.90          21.32         142.57   \n",
       "760             1500.0             5  164.90          16.36         181.26   \n",
       "981              150.0             5    7.00           7.39          71.95   \n",
       "...                ...           ...     ...            ...            ...   \n",
       "1041             550.0             3   84.99           8.79          93.78   \n",
       "1074             550.0             5   84.99          16.35         101.34   \n",
       "1603             200.0             2   58.99          13.07          72.06   \n",
       "1768             400.0             4   56.99          16.10          73.09   \n",
       "1864             250.0             5   56.99           8.72          65.71   \n",
       "\n",
       "        order_approved_at order_purchase_timestamp  \n",
       "427   2017-11-22 11:54:27      2017-11-22 11:42:43  \n",
       "242   2018-05-08 01:11:58      2018-05-08 00:45:50  \n",
       "113   2017-08-23 02:55:54      2017-08-22 10:14:07  \n",
       "760   2017-03-25 02:10:41      2017-03-23 23:55:55  \n",
       "981   2018-03-26 14:50:21      2018-03-26 14:40:10  \n",
       "...                   ...                      ...  \n",
       "1041  2017-07-11 21:36:01      2017-07-11 20:58:08  \n",
       "1074  2017-12-06 02:50:38      2017-12-05 10:34:52  \n",
       "1603  2018-06-29 16:11:39      2018-06-29 15:27:05  \n",
       "1768  2017-04-15 11:55:08      2017-04-15 11:44:00  \n",
       "1864  2018-01-10 10:32:24      2018-01-09 21:08:24  \n",
       "\n",
       "[1011 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 3: Campionamento con ripetizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d829ae9ca5e0a9749f2574b62eb7ac10</td>\n",
       "      <td>BA</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>530.0</td>\n",
       "      <td>5</td>\n",
       "      <td>55.90</td>\n",
       "      <td>27.99</td>\n",
       "      <td>167.51</td>\n",
       "      <td>2017-07-13 02:56:03</td>\n",
       "      <td>2017-07-12 12:04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>3823f120a83e20af66f49d377207bbeb</td>\n",
       "      <td>SP</td>\n",
       "      <td>audio</td>\n",
       "      <td>200.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.90</td>\n",
       "      <td>8.29</td>\n",
       "      <td>23.19</td>\n",
       "      <td>2018-07-18 03:05:22</td>\n",
       "      <td>2018-07-17 18:18:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2909debcb57debbbdfe7034eaf7b28bc</td>\n",
       "      <td>SP</td>\n",
       "      <td>telefonia</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.85</td>\n",
       "      <td>18.85</td>\n",
       "      <td>2017-06-13 04:43:07</td>\n",
       "      <td>2017-06-10 17:06:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>aeefcf3435f9cc6db2c0b8019f17ca7f</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5</td>\n",
       "      <td>49.99</td>\n",
       "      <td>8.29</td>\n",
       "      <td>58.28</td>\n",
       "      <td>2018-03-23 18:30:42</td>\n",
       "      <td>2018-03-23 18:15:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              order_id customer_state product_category_name  \\\n",
       "18    d829ae9ca5e0a9749f2574b62eb7ac10             BA            cool_stuff   \n",
       "448   3823f120a83e20af66f49d377207bbeb             SP                 audio   \n",
       "977   2909debcb57debbbdfe7034eaf7b28bc             SP             telefonia   \n",
       "1869  aeefcf3435f9cc6db2c0b8019f17ca7f             SP            perfumaria   \n",
       "\n",
       "      product_weight_g  review_score  price  freight_value  payment_value  \\\n",
       "18               530.0             5  55.90          27.99         167.51   \n",
       "448              200.0             3  14.90           8.29          23.19   \n",
       "977              150.0             5   7.00          11.85          18.85   \n",
       "1869             250.0             5  49.99           8.29          58.28   \n",
       "\n",
       "        order_approved_at order_purchase_timestamp  \n",
       "18    2017-07-13 02:56:03      2017-07-12 12:04:28  \n",
       "448   2018-07-18 03:05:22      2018-07-17 18:18:59  \n",
       "977   2017-06-13 04:43:07      2017-06-10 17:06:01  \n",
       "1869  2018-03-23 18:30:42      2018-03-23 18:15:49  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.sample(n=4, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 4: Campionamento riproducibile usando random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>review_score</th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_value</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>b0e2da4433a10c624a9f71b187e93915</td>\n",
       "      <td>SP</td>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>400.0</td>\n",
       "      <td>5</td>\n",
       "      <td>99.90</td>\n",
       "      <td>9.51</td>\n",
       "      <td>109.41</td>\n",
       "      <td>2017-05-07 02:10:12</td>\n",
       "      <td>2017-05-06 21:55:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>b45d11b61c2a68756bbbd7665d67e812</td>\n",
       "      <td>MG</td>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4</td>\n",
       "      <td>89.99</td>\n",
       "      <td>16.39</td>\n",
       "      <td>106.38</td>\n",
       "      <td>2017-10-13 15:56:25</td>\n",
       "      <td>2017-10-11 21:55:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              order_id customer_state product_category_name  \\\n",
       "674   b0e2da4433a10c624a9f71b187e93915             SP          beleza_saude   \n",
       "1384  b45d11b61c2a68756bbbd7665d67e812             MG          beleza_saude   \n",
       "\n",
       "      product_weight_g  review_score  price  freight_value  payment_value  \\\n",
       "674              400.0             5  99.90           9.51         109.41   \n",
       "1384             250.0             4  89.99          16.39         106.38   \n",
       "\n",
       "        order_approved_at order_purchase_timestamp  \n",
       "674   2017-05-07 02:10:12      2017-05-06 21:55:41  \n",
       "1384  2017-10-13 15:56:25      2017-10-11 21:55:04  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.sample(n=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esempio 5: Campionare colonne invece di righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_approved_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-13 09:45:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-29 02:44:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-18 12:31:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-01 18:55:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-10 22:05:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2017-11-22 02:56:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2018-02-13 16:50:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2018-02-13 16:50:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2018-03-01 02:50:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2017-06-11 17:55:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        order_approved_at\n",
       "0     2017-09-13 09:45:35\n",
       "1     2017-06-29 02:44:11\n",
       "2     2018-05-18 12:31:43\n",
       "3     2017-08-01 18:55:08\n",
       "4     2017-08-10 22:05:11\n",
       "...                   ...\n",
       "2017  2017-11-22 02:56:28\n",
       "2018  2018-02-13 16:50:30\n",
       "2019  2018-02-13 16:50:30\n",
       "2020  2018-03-01 02:50:46\n",
       "2021  2017-06-11 17:55:17\n",
       "\n",
       "[2022 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.sample(n=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Selecting and Indexing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.iloc[]`¬†‚Äì Accede a gruppi di righe e colonne tramite posizioni (basate su interi)\n",
    "\n",
    "Il metodo `.iloc[]` di Pandas consente di selezionare dati da un DataFrame o da una Serie in base alla **posizione numerica degli indici (e delle colonne)**. √à utile per accedere a righe e colonne utilizzando indici numerici anzich√© etichette.\n",
    "\n",
    "### Principali parametri e utilizzi\n",
    "\n",
    "1. **`.iloc[<indice_riga>]`**\n",
    "    - Specifica la riga da selezionare.\n",
    "    - Pu√≤ essere un singolo numero, una lista, uno slice (es. `:`), o una condizione.\n",
    "2. **`.iloc[:, <indice_colonna>]`**\n",
    "    - Specifica la colonna da selezionare.\n",
    "    - Analogamente, pu√≤ essere un singolo numero, una lista, uno slice o una condizione.\n",
    "3. **Combinazione righe/colonne:**\n",
    "    - `.iloc[<indice_riga>, <indice_colonna>]` accede direttamente a una cella, riga o gruppo di righe e colonne.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Et√†\": [25, 30, 35],\n",
    "    \"Citt√†\": [\"Roma\", \"Milano\", \"Napoli\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†\n",
    "0    Alice   25    Roma\n",
    "1      Bob   30  Milano\n",
    "2  Charlie   35  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Selezione di una singola riga\n",
    "\n",
    "```python\n",
    "# Seleziona la prima riga (indice 0)\n",
    "print(df.iloc[0])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Nome     Alice\n",
    "Et√†         25\n",
    "Citt√†     Roma\n",
    "Name: 0, dtype: object\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Selezione di un intervallo di righe\n",
    "\n",
    "```python\n",
    "# Seleziona le prime due righe\n",
    "print(df.iloc[0:2])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "    Nome  Et√†   Citt√†\n",
    "0  Alice   25    Roma\n",
    "1    Bob   30  Milano\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Selezione di specifiche colonne\n",
    "\n",
    "```python\n",
    "# Seleziona tutte le righe e la seconda colonna (indice 1)\n",
    "print(df.iloc[:, 1])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0    25\n",
    "1    30\n",
    "2    35\n",
    "Name: Et√†, dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Selezione di una specifica cella\n",
    "\n",
    "```python\n",
    "# Seleziona la cella in posizione [1, 2] (riga 1, colonna 2)\n",
    "print(df.iloc[1, 2])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Milano\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Utilizzo con liste di indici\n",
    "\n",
    "```python\n",
    "# Seleziona la prima e l'ultima riga\n",
    "print(df.iloc[[0, 2]])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†\n",
    "0    Alice   25    Roma\n",
    "2  Charlie   35  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Uso combinato di righe e colonne\n",
    "\n",
    "```python\n",
    "# Seleziona le prime due righe e la prima colonna\n",
    "print(df.iloc[0:2, 0])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0    Alice\n",
    "1      Bob\n",
    "Name: Nome, dtype: object\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.at[]`¬†‚Äì Accede a un singolo valore tramite una coppia etichetta riga/colonna\n",
    "\n",
    "Il metodo `.at[]` di Pandas consente di accedere velocemente e in modo efficiente a **una singola cella** in un DataFrame o a un singolo elemento in una Serie, utilizzando **etichette** di riga e colonna. √à simile a `.loc[]`, ma √® ottimizzato per accedere a **un solo valore alla volta**.\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`.at[<etichetta_riga>, <etichetta_colonna>]`**\n",
    "    - **`<etichetta_riga>`**: l'etichetta della riga di interesse (non la posizione numerica).\n",
    "    - **`<etichetta_colonna>`**: il nome della colonna da selezionare.\n",
    "2. **Supporta solo accessi singoli**: non √® possibile utilizzarlo per selezionare pi√π righe o colonne contemporaneamente.\n",
    "\n",
    "---\n",
    "\n",
    "### Vantaggi di `.at[]`\n",
    "\n",
    "- **Pi√π veloce di `.loc[]`** quando si accede a un singolo elemento.\n",
    "- Chiaro e leggibile per accessi puntuali a dati.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Et√†\": [25, 30, 35],\n",
    "    \"Citt√†\": [\"Roma\", \"Milano\", \"Napoli\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=[\"a\", \"b\", \"c\"])\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†\n",
    "a    Alice   25    Roma\n",
    "b      Bob   30  Milano\n",
    "c  Charlie   35  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Selezionare un valore specifico\n",
    "\n",
    "```python\n",
    "# Accedi al valore nella riga \"b\" e colonna \"Citt√†\"\n",
    "print(df.at[\"b\", \"Citt√†\"])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Milano\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Modificare un valore\n",
    "\n",
    "```python\n",
    "# Cambia il valore nella riga \"a\" e colonna \"Et√†\"\n",
    "df.at[\"a\", \"Et√†\"] = 28\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†\n",
    "a    Alice   28    Roma\n",
    "b      Bob   30  Milano\n",
    "c  Charlie   35  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Usare `.at[]` con una Serie\n",
    "\n",
    "Se lavori con una Serie, `.at[]` usa solo l'etichetta della riga:\n",
    "\n",
    "```python\n",
    "# Estrarre un elemento da una Serie\n",
    "serie = df[\"Et√†\"]\n",
    "print(serie)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "a    28\n",
    "b    30\n",
    "c    35\n",
    "Name: Et√†, dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "# Accedere a un valore specifico\n",
    "print(serie.at[\"b\"])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "30\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Confronto con `.loc[]`\n",
    "\n",
    "```python\n",
    "# Con .loc[]\n",
    "print(df.loc[\"b\", \"Citt√†\"])  # Milano\n",
    "\n",
    "# Con .at[]\n",
    "print(df.at[\"b\", \"Citt√†\"])   # Milano\n",
    "\n",
    "```\n",
    "\n",
    "- **Differenze:**\n",
    "    - `.loc[]` supporta selezioni pi√π complesse (es. intervalli, array booleani, ecc.).\n",
    "    - `.at[]` √® pi√π veloce per selezioni puntuali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.iat[]`¬†‚Äì Accede a un singolo valore tramite una coppia posizione riga/colonna\n",
    "\n",
    "Il metodo `.iat[]` di Pandas consente di accedere velocemente e in modo efficiente a **una singola cella** in un DataFrame o a un singolo elemento in una Serie, utilizzando **posizioni numeriche** di riga e colonna. √à simile a `.iloc[]`, ma ottimizzato per accedere a **un solo valore alla volta**.\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`.iat[<indice_riga>, <indice_colonna>]`**\n",
    "    - **`<indice_riga>`**: la posizione numerica della riga di interesse.\n",
    "    - **`<indice_colonna>`**: la posizione numerica della colonna da selezionare.\n",
    "2. **Accesso a un singolo valore alla volta**: non supporta intervalli o array, a differenza di `.iloc[]`.\n",
    "\n",
    "---\n",
    "\n",
    "### Vantaggi di `.iat[]`\n",
    "\n",
    "- **Molto pi√π veloce di `.iloc[]`** per l'accesso puntuale.\n",
    "- Utilizza un approccio diretto per accedere o modificare un singolo valore tramite indici numerici.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Et√†\": [25, 30, 35],\n",
    "    \"Citt√†\": [\"Roma\", \"Milano\", \"Napoli\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†\n",
    "0    Alice   25    Roma\n",
    "1      Bob   30  Milano\n",
    "2  Charlie   35  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Selezionare un valore specifico\n",
    "\n",
    "```python\n",
    "# Accedi alla cella nella riga 1 e colonna 2\n",
    "print(df.iat[1, 2])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Milano\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Modificare un valore\n",
    "\n",
    "```python\n",
    "# Cambia il valore nella riga 0 e colonna 1\n",
    "df.iat[0, 1] = 28\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†\n",
    "0    Alice   28    Roma\n",
    "1      Bob   30  Milano\n",
    "2  Charlie   35  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Usare `.iat[]` con una Serie\n",
    "\n",
    "Quando si lavora con una Serie, `.iat[]` utilizza solo l'indice numerico della riga:\n",
    "\n",
    "```python\n",
    "# Estrarre una Serie\n",
    "serie = df[\"Et√†\"]\n",
    "print(serie)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0    28\n",
    "1    30\n",
    "2    35\n",
    "Name: Et√†, dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "# Accedere a un valore specifico\n",
    "print(serie.iat[2])\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "35\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Confronto con `.iloc[]`\n",
    "\n",
    "```python\n",
    "# Con .iloc[]\n",
    "print(df.iloc[1, 2])  # Milano\n",
    "\n",
    "# Con .iat[]\n",
    "print(df.iat[1, 2])   # Milano\n",
    "\n",
    "```\n",
    "\n",
    "- **Differenze:**\n",
    "    - `.iloc[]` pu√≤ selezionare intervalli o array, `.iat[]` √® limitato a un solo valore.\n",
    "    - `.iat[]` √® pi√π veloce quando si accede a un singolo elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.filter()`¬†‚Äì Sottoseleziona il DataFrame in base alle etichette di riga/colonna\n",
    "\n",
    "Il metodo `.filter()` di Pandas consente di selezionare righe o colonne da un DataFrame o da una Serie in base a specifici criteri, come nomi di etichette, pattern o altri metodi di filtraggio.\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`items`**:\n",
    "    - Specifica un elenco di etichette (nomi di colonne o righe) da mantenere.\n",
    "    - Utile quando sai esattamente quali etichette vuoi includere.\n",
    "2. **`like`**:\n",
    "    - Filtra etichette che contengono un determinato substring o pattern.\n",
    "    - √à case-sensitive.\n",
    "3. **`regex`**:\n",
    "    - Consente di filtrare usando un'espressione regolare (regex).\n",
    "    - Fornisce maggiore flessibilit√† rispetto a `like`.\n",
    "4. **`axis`**:\n",
    "    - Specifica se applicare il filtro a righe o colonne:\n",
    "        - `axis=0`: applica il filtro alle **righe**.\n",
    "        - `axis=1`: applica il filtro alle **colonne**.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Et√†\": [25, 30, 35],\n",
    "    \"Citt√†\": [\"Roma\", \"Milano\", \"Napoli\"],\n",
    "    \"Paese\": [\"Italia\", \"Italia\", \"Italia\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†   Paese\n",
    "0    Alice   25    Roma  Italia\n",
    "1      Bob   30  Milano  Italia\n",
    "2  Charlie   35  Napoli  Italia\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Usare `items` per selezionare colonne specifiche\n",
    "\n",
    "```python\n",
    "# Seleziona le colonne \"Nome\" e \"Citt√†\"\n",
    "result = df.filter(items=[\"Nome\", \"Citt√†\"], axis=1)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Citt√†\n",
    "0    Alice    Roma\n",
    "1      Bob  Milano\n",
    "2  Charlie  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Usare `like` per selezionare colonne con una sottostringa\n",
    "\n",
    "```python\n",
    "# Seleziona colonne che contengono \"t√†\"\n",
    "result = df.filter(like=\"t√†\", axis=1)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "    Et√†   Citt√†\n",
    "0   25    Roma\n",
    "1   30  Milano\n",
    "2   35  Napoli\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Usare `regex` per pattern pi√π complessi\n",
    "\n",
    "```python\n",
    "# Seleziona colonne che terminano con \"e\"\n",
    "result = df.filter(regex=\"e$\", axis=1)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Paese\n",
    "0    Alice  Italia\n",
    "1      Bob  Italia\n",
    "2  Charlie  Italia\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Applicare `.filter()` alle righe\n",
    "\n",
    "```python\n",
    "# Seleziona righe con indici specifici\n",
    "result = df.filter(items=[0, 2], axis=0)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†   Paese\n",
    "0    Alice   25    Roma  Italia\n",
    "2  Charlie   35  Napoli  Italia\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Quando utilizzare `.filter()`?\n",
    "\n",
    "- Quando devi **selezionare colonne o righe** basandoti su un sottoinsieme di nomi o pattern.\n",
    "- √à utile in operazioni dinamiche, come quando non conosci i nomi precisi ma vuoi lavorare su un gruppo di colonne/righe che condividono un tratto comune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.xs()`¬†‚Äì Estrae sezioni trasversali da un MultiIndex\n",
    "\n",
    "Il metodo `.xs()` di Pandas consente di accedere a **sottomatrici** o **valori specifici** da un DataFrame o una Serie multi-indice, utilizzando un'etichetta lungo un determinato livello di indice. √à particolarmente utile quando si lavora con indici gerarchici (MultiIndex).\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`key`**:\n",
    "    - Valore dell'etichetta nel livello dell'indice da selezionare.\n",
    "2. **`axis`**:\n",
    "    - Indica l'asse su cui applicare il filtro:\n",
    "        - `axis=0` (predefinito): applica il filtro alle righe.\n",
    "        - `axis=1`: applica il filtro alle colonne.\n",
    "3. **`level`**:\n",
    "    - Specifica il livello del MultiIndex (numerico o nome) su cui applicare il filtro.\n",
    "4. **`drop_level`**:\n",
    "    - Se `True` (default), rimuove il livello selezionato dal risultato.\n",
    "    - Se `False`, il livello selezionato viene mantenuto.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creare un DataFrame con un MultiIndex\n",
    "index = pd.MultiIndex.from_tuples(\n",
    "    [(\"A\", 1), (\"A\", 2), (\"B\", 1), (\"B\", 2)],\n",
    "    names=[\"Lettera\", \"Numero\"]\n",
    ")\n",
    "data = {\n",
    "    \"Valore1\": [10, 20, 30, 40],\n",
    "    \"Valore2\": [100, 200, 300, 400]\n",
    "}\n",
    "df = pd.DataFrame(data, index=index)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "                 Valore1  Valore2\n",
    "Lettera Numero\n",
    "A       1            10      100\n",
    "        2            20      200\n",
    "B       1            30      300\n",
    "        2            40      400\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Filtrare righe per un valore di un livello\n",
    "\n",
    "```python\n",
    "# Selezionare tutte le righe dove il livello \"Lettera\" √® \"A\"\n",
    "result = df.xs(key=\"A\", level=\"Lettera\")\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "        Valore1  Valore2\n",
    "Numero\n",
    "1            10      100\n",
    "2            20      200\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Filtrare righe per un valore di un livello senza rimuoverlo\n",
    "\n",
    "```python\n",
    "# Mantenere il livello \"Lettera\"\n",
    "result = df.xs(key=\"A\", level=\"Lettera\", drop_level=False)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "                 Valore1  Valore2\n",
    "Lettera Numero\n",
    "A       1            10      100\n",
    "        2            20      200\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Filtrare colonne utilizzando `axis=1`\n",
    "\n",
    "Se il MultiIndex √® sulle colonne:\n",
    "\n",
    "```python\n",
    "# Creare un DataFrame con MultiIndex sulle colonne\n",
    "columns = pd.MultiIndex.from_tuples(\n",
    "    [(\"Categoria1\", \"Valore1\"), (\"Categoria1\", \"Valore2\"), (\"Categoria2\", \"Valore3\")],\n",
    "    names=[\"Categoria\", \"Tipo\"]\n",
    ")\n",
    "df2 = pd.DataFrame([[10, 20, 30], [40, 50, 60]], columns=columns)\n",
    "print(df2)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Categoria  Categoria1        Categoria2\n",
    "Tipo        Valore1 Valore2    Valore3\n",
    "0                10      20        30\n",
    "1                40      50        60\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "# Selezionare colonne dal livello \"Categoria\" con valore \"Categoria1\"\n",
    "result = df2.xs(key=\"Categoria1\", level=\"Categoria\", axis=1)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "   Valore1  Valore2\n",
    "0       10       20\n",
    "1       40       50\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Filtrare usando valori interni al livello\n",
    "\n",
    "```python\n",
    "# Selezionare tutte le righe dove il livello \"Numero\" √® 1\n",
    "result = df.xs(key=1, level=\"Numero\")\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "        Valore1  Valore2\n",
    "Lettera\n",
    "A            10      100\n",
    "B            30      300\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Quando usare `.xs()`?\n",
    "\n",
    "- Per lavorare con **MultiIndex** in modo efficiente, selezionando dati specifici lungo livelli di indici.\n",
    "- √à pi√π chiaro e leggibile rispetto a combinazioni complesse di `.loc[]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.query()`¬†‚Äì Filtra il DataFrame usando un'espressione in formato stringa\n",
    "\n",
    "Il metodo `.query()` di Pandas consente di effettuare filtri su un DataFrame usando una sintassi simile al linguaggio SQL. √à particolarmente utile per scrivere condizioni in modo leggibile e conciso, senza utilizzare esplicitamente gli operatori di indicizzazione come `.loc[]`.\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`expr`**:\n",
    "    - L'espressione booleana da valutare per filtrare le righe. Pu√≤ includere condizioni su colonne e operatori logici.\n",
    "    - Esempi di operatori:\n",
    "        - `&` per \"AND\"\n",
    "        - `|` per \"OR\"\n",
    "        - `==`, `!=`, `<`, `<=`, `>`, `>=`\n",
    "2. **`inplace`** *(default: `False`)*:\n",
    "    - Se impostato a `True`, modifica il DataFrame esistente invece di restituirne una copia.\n",
    "3. **`engine`** *(default: `'python'`)*:\n",
    "    - Specifica il motore per valutare l'espressione (`'python'` o `'numexpr'`).\n",
    "4. **`parser`** *(opzionale)*:\n",
    "    - Specifica il parser per l'espressione (`'pandas'` o `'python'`).\n",
    "5. **`kwargs`**:\n",
    "    - Altri argomenti per il motore scelto.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"Et√†\": [25, 30, 35, 40],\n",
    "    \"Citt√†\": [\"Roma\", \"Milano\", \"Napoli\", \"Torino\"],\n",
    "    \"Salario\": [50000, 60000, 55000, 70000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†  Salario\n",
    "0    Alice   25    Roma    50000\n",
    "1      Bob   30  Milano    60000\n",
    "2  Charlie   35  Napoli    55000\n",
    "3    Diana   40  Torino    70000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Filtrare righe con una condizione semplice\n",
    "\n",
    "Selezionare le righe in cui l'et√† √® maggiore di 30:\n",
    "\n",
    "```python\n",
    "result = df.query(\"Et√† > 30\")\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†  Salario\n",
    "2  Charlie   35  Napoli    55000\n",
    "3    Diana   40  Torino    70000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Usare pi√π condizioni con `&` e `|`\n",
    "\n",
    "Selezionare le righe in cui l'et√† √® maggiore di 30 **e** il salario √® maggiore di 55000:\n",
    "\n",
    "```python\n",
    "result = df.query(\"Et√† > 30 & Salario > 55000\")\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "    Nome  Et√†   Citt√†  Salario\n",
    "3  Diana   40  Torino    70000\n",
    "\n",
    "```\n",
    "\n",
    "Selezionare righe in cui l'et√† √® minore di 30 **o** la citt√† √® \"Napoli\":\n",
    "\n",
    "```python\n",
    "result = df.query(\"Et√† < 30 | Citt√† == 'Napoli'\")\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†  Salario\n",
    "0    Alice   25    Roma    50000\n",
    "2  Charlie   35  Napoli    55000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Usare variabili esterne nel filtro\n",
    "\n",
    "```python\n",
    "# Variabile esterna\n",
    "salario_minimo = 55000\n",
    "result = df.query(\"Salario > @salario_minimo\")\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†  Salario\n",
    "1      Bob   30  Milano    60000\n",
    "3    Diana   40  Torino    70000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Filtrare righe basate su valori di stringhe\n",
    "\n",
    "Selezionare righe in cui la citt√† √® \"Milano\" o \"Roma\":\n",
    "\n",
    "```python\n",
    "result = df.query(\"Citt√† in ['Milano', 'Roma']\")\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "    Nome  Et√†   Citt√†  Salario\n",
    "0  Alice   25    Roma    50000\n",
    "1    Bob   30  Milano    60000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Modificare il DataFrame in loco\n",
    "\n",
    "Selezionare righe in cui l'et√† √® maggiore di 30 e aggiornare il DataFrame originale:\n",
    "\n",
    "```python\n",
    "df.query(\"Et√† > 30\", inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†  Salario\n",
    "2  Charlie   35  Napoli    55000\n",
    "3    Diana   40  Torino    70000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Quando utilizzare `.query()`?\n",
    "\n",
    "- Quando vuoi scrivere condizioni in modo pi√π leggibile rispetto a `.loc[]`.\n",
    "- Per combinare pi√π condizioni senza creare lunghi blocchi di codice.\n",
    "- √à utile in script dinamici, specialmente quando si usano variabili esterne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.get()`¬†‚Äì Recupera elementi da una Serie tramite chiave\n",
    "\n",
    "Il metodo `.get()` √® usato principalmente con oggetti **dizionario** (`dict`) in Python per accedere ai valori associati a una chiave, offrendo un modo sicuro per farlo senza rischiare errori se la chiave non esiste. √à particolarmente utile per evitare l'errore `KeyError` che si verifica quando si tenta di accedere a una chiave inesistente usando la notazione delle parentesi quadre (`[]`).\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`key`** (obbligatorio):\n",
    "    - La chiave che si desidera cercare nel dizionario.\n",
    "2. **`default`** (opzionale):\n",
    "    - Il valore da restituire se la chiave non esiste nel dizionario.\n",
    "    - Se non specificato, il valore predefinito √® `None`.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "# Un dizionario semplice\n",
    "dizionario = {\n",
    "    \"nome\": \"Alice\",\n",
    "    \"et√†\": 30,\n",
    "    \"citt√†\": \"Roma\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Recuperare il valore di una chiave esistente\n",
    "\n",
    "```python\n",
    "# Recuperare il valore associato alla chiave \"nome\"\n",
    "valore = dizionario.get(\"nome\")\n",
    "print(valore)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Alice\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Recuperare il valore di una chiave inesistente\n",
    "\n",
    "Se la chiave non esiste, `.get()` restituisce il valore predefinito (`None` se non specificato):\n",
    "\n",
    "```python\n",
    "# Recuperare una chiave inesistente senza specificare un valore predefinito\n",
    "valore = dizionario.get(\"professione\")\n",
    "print(valore)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "None\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Specificare un valore predefinito per chiavi inesistenti\n",
    "\n",
    "```python\n",
    "# Specificare un valore predefinito per una chiave inesistente\n",
    "valore = dizionario.get(\"professione\", \"Sconosciuto\")\n",
    "print(valore)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Sconosciuto\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Utilizzare `.get()` in un'operazione dinamica\n",
    "\n",
    "```python\n",
    "# Iterare su una lista di chiavi con valori predefiniti\n",
    "chiavi = [\"nome\", \"et√†\", \"professione\"]\n",
    "for chiave in chiavi:\n",
    "    valore = dizionario.get(chiave, \"Non disponibile\")\n",
    "    print(f\"{chiave}: {valore}\")\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "nome: Alice\n",
    "et√†: 30\n",
    "professione: Non disponibile\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Differenza con `[]`\n",
    "\n",
    "```python\n",
    "# Usare [] per accedere a una chiave inesistente genera un errore\n",
    "valore = dizionario[\"professione\"]  # KeyError: 'professione'\n",
    "\n",
    "```\n",
    "\n",
    "Usando `.get()`:\n",
    "\n",
    "```python\n",
    "# Non genera errori\n",
    "valore = dizionario.get(\"professione\")\n",
    "print(valore)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "None\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Quando utilizzare `.get()`?\n",
    "\n",
    "- Quando non sei sicuro che una chiave esista nel dizionario.\n",
    "- Per fornire un valore predefinito per chiavi mancanti.\n",
    "- Per evitare il rischio di eccezioni `KeyError` nel tuo codice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.isin()`¬†‚Äì Filtra righe in base alla presenza di valori in una lista\n",
    "\n",
    "Il metodo `.isin()` di Pandas √® utilizzato per verificare se gli elementi di una Serie o di un DataFrame appartengono a una lista, un array o una Serie di valori. Restituisce un oggetto di tipo booleano che indica per ogni elemento se √® presente o meno nell'insieme di valori.\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`values`**:\n",
    "    - La lista, l'array o la Serie di valori contro cui comparare gli elementi della Serie o del DataFrame.\n",
    "    - Pu√≤ essere una lista, un array NumPy, un oggetto Pandas `Series` o un dizionario.\n",
    "2. **`level`** (opzionale):\n",
    "    - Usato se si lavora con un DataFrame multi-indice. Permette di specificare il livello su cui eseguire il test.\n",
    "3. **`dropna`** (opzionale, default: `True`):\n",
    "    - Se impostato a `True`, ignora i valori `NaN` durante il confronto. Se impostato a `False`, considera i `NaN` come valori da confrontare.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"Et√†\": [25, 30, 35, 40],\n",
    "    \"Citt√†\": [\"Roma\", \"Milano\", \"Napoli\", \"Torino\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†   Citt√†\n",
    "0    Alice   25    Roma\n",
    "1      Bob   30  Milano\n",
    "2  Charlie   35  Napoli\n",
    "3    Diana   40  Torino\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Verificare se i valori di una colonna sono in una lista\n",
    "\n",
    "Supponiamo di voler verificare se i valori della colonna \"Citt√†\" sono tra \"Roma\" e \"Milano\":\n",
    "\n",
    "```python\n",
    "result = df[\"Citt√†\"].isin([\"Roma\", \"Milano\"])\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0     True\n",
    "1     True\n",
    "2    False\n",
    "3    False\n",
    "Name: Citt√†, dtype: bool\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Filtrare righe con `.isin()`\n",
    "\n",
    "Usiamo `.isin()` per selezionare solo le righe in cui la citt√† √® \"Roma\" o \"Milano\":\n",
    "\n",
    "```python\n",
    "result = df[df[\"Citt√†\"].isin([\"Roma\", \"Milano\"])]\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "    Nome  Et√†   Citt√†\n",
    "0  Alice   25    Roma\n",
    "1    Bob   30  Milano\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Verificare se i valori di pi√π colonne appartengono a una lista\n",
    "\n",
    "Puoi applicare `.isin()` su pi√π colonne per eseguire un confronto su ciascuna di esse:\n",
    "\n",
    "```python\n",
    "result = df[[\"Nome\", \"Citt√†\"]].isin([[\"Alice\", \"Roma\"], [\"Bob\", \"Milano\"]])\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "    Nome  Citt√†\n",
    "0   True   True\n",
    "1   True   True\n",
    "2  False  False\n",
    "3  False  False\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Verifica per valori `NaN`\n",
    "\n",
    "Se il DataFrame contiene valori `NaN`, puoi decidere se includerli nel confronto:\n",
    "\n",
    "```python\n",
    "df_with_nan = df.copy()\n",
    "df_with_nan.loc[1, \"Citt√†\"] = None  # Aggiungere un NaN\n",
    "\n",
    "result = df_with_nan[\"Citt√†\"].isin([\"Roma\", \"Milano\"])\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "Name: Citt√†, dtype: bool\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Utilizzare `.isin()` per selezionare pi√π colonne\n",
    "\n",
    "Supponiamo di voler verificare se i valori in entrambe le colonne \"Nome\" e \"Citt√†\" appartengono a due liste:\n",
    "\n",
    "```python\n",
    "result = df[df[\"Nome\"].isin([\"Alice\", \"Bob\"]) & df[\"Citt√†\"].isin([\"Roma\", \"Milano\"])]\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "    Nome  Et√†   Citt√†\n",
    "0  Alice   25    Roma\n",
    "1    Bob   30  Milano\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Quando utilizzare `.isin()`?\n",
    "\n",
    "- Quando hai bisogno di verificare se i valori di una Serie o DataFrame appartengono a un insieme di valori.\n",
    "- Per filtrare righe basandoti su una condizione di appartenenza a un insieme.\n",
    "- Per confrontare facilmente una colonna o un gruppo di colonne con un insieme di valori predefiniti (come una lista o un array)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.where()`¬†‚Äì Imposta valori in base a una condizione\n",
    "\n",
    "Il metodo `.where()` in **Pandas** √® utilizzato per applicare una condizione a un DataFrame o a una Serie. Restituisce un oggetto del tipo originale (DataFrame o Serie) in cui i valori che non soddisfano la condizione sono sostituiti con `NaN` (o un altro valore specificato). √à particolarmente utile per mascherare o filtrare i dati, mantenendo la struttura originale, ma con la possibilit√† di cambiare o sostituire i valori che non soddisfano la condizione.\n",
    "\n",
    "---\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`cond`** (obbligatorio):\n",
    "    - Una condizione booleana (come un'espressione che restituisce `True` o `False`) che definisce quali valori devono essere mantenuti e quali devono essere sostituiti. La condizione pu√≤ essere una Serie booleana, un array NumPy, o una condizione applicata direttamente alla colonna.\n",
    "2. **`other`** (opzionale):\n",
    "    - Il valore da sostituire nei punti in cui la condizione non √® soddisfatta. Se non specificato, i valori verranno sostituiti con `NaN`.\n",
    "3. **`inplace`** (opzionale, default: `False`):\n",
    "    - Se `True`, modifica l'oggetto originale. Se `False` (default), viene restituito un nuovo oggetto con le modifiche.\n",
    "4. **`axis`** (opzionale, default: `None`):\n",
    "    - Indica se applicare la condizione lungo l'asse delle righe o delle colonne.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"Et√†\": [25, 30, 35, 40],\n",
    "    \"Salario\": [50000, 60000, 70000, 80000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "0    Alice   25    50000\n",
    "1      Bob   30    60000\n",
    "2  Charlie   35    70000\n",
    "3    Diana   40    80000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Sostituire i valori che non soddisfano una condizione con `NaN`\n",
    "\n",
    "Ad esempio, vogliamo sostituire i valori della colonna \"Salario\" con `NaN` se sono inferiori a 70000:\n",
    "\n",
    "```python\n",
    "result = df[\"Salario\"].where(df[\"Salario\"] >= 70000)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0     NaN\n",
    "1     NaN\n",
    "2  70000.0\n",
    "3  80000.0\n",
    "Name: Salario, dtype: float64\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Sostituire i valori che non soddisfano la condizione con un altro valore\n",
    "\n",
    "Possiamo sostituire i valori che non soddisfano la condizione con un altro valore, ad esempio 0:\n",
    "\n",
    "```python\n",
    "result = df[\"Salario\"].where(df[\"Salario\"] >= 70000, other=0)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0    0\n",
    "1    0\n",
    "2    70000\n",
    "3    80000\n",
    "Name: Salario, dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Applicare `.where()` a tutto un DataFrame\n",
    "\n",
    "Se vogliamo applicare una condizione a tutte le colonne del DataFrame, possiamo farlo in modo simile:\n",
    "\n",
    "```python\n",
    "result = df.where(df >= 30)  # Mantieni solo valori >= 30\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Et√†  Salario\n",
    "0     NaN   25.0    NaN\n",
    "1     NaN   30.0    NaN\n",
    "2  Charlie   35.0  70000.0\n",
    "3    Diana   40.0  80000.0\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Utilizzare `inplace=True`\n",
    "\n",
    "Se vogliamo modificare direttamente il DataFrame senza creare una copia, possiamo utilizzare `inplace=True`:\n",
    "\n",
    "```python\n",
    "df.where(df[\"Et√†\"] > 30, inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Et√†  Salario\n",
    "0     NaN   NaN      NaN\n",
    "1     NaN   NaN      NaN\n",
    "2  Charlie  35.0  70000.0\n",
    "3    Diana  40.0  80000.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, tutte le righe che non soddisfano la condizione (`Et√† > 30`) sono state sostituite con `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Applicare la condizione su pi√π colonne\n",
    "\n",
    "Possiamo anche applicare condizioni su pi√π colonne. Ad esempio, possiamo sostituire i valori di \"Salario\" con 0 se sono inferiori a 70000 e i valori di \"Et√†\" con 0 se sono inferiori a 30:\n",
    "\n",
    "```python\n",
    "df = df.where((df[\"Salario\"] >= 70000) & (df[\"Et√†\"] >= 30), other=0)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Et√†  Salario\n",
    "0     0.0   0.0        0\n",
    "1     0.0   0.0        0\n",
    "2  Charlie   35.0  70000.0\n",
    "3    Diana   40.0  80000.0\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Quando utilizzare `.where()`?\n",
    "\n",
    "- Quando hai bisogno di applicare una condizione su un DataFrame o una Serie e vuoi mascherare o sostituire i valori che non soddisfano la condizione.\n",
    "- Quando desideri mantenere la struttura dei dati (ad esempio, le dimensioni del DataFrame o della Serie) ma con valori sostituiti da `NaN` o un altro valore a tua scelta.\n",
    "- Quando vuoi modificare in modo condizionale i dati senza alterare quelli che soddisfano la condizione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.mask()`¬†‚Äì Sostituisce valori dove una condizione √®¬†`True`\n",
    "\n",
    "Il metodo `.mask()` in **Pandas** √® simile al metodo `.where()`, ma con una differenza fondamentale: invece di mantenere i valori che soddisfano la condizione, `.mask()` sostituisce i valori che **non** soddisfano la condizione con un altro valore (come `NaN` o un valore personalizzato). In altre parole, applica una \"maschera\" che nasconde i valori che non rispettano una certa condizione, lasciando invariati quelli che la rispettano.\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`cond`** (obbligatorio):\n",
    "    - Una condizione booleana che indica quali valori devono essere sostituiti. La condizione pu√≤ essere una Serie booleana, un array NumPy o un'espressione che restituisce valori booleani.\n",
    "2. **`other`** (opzionale):\n",
    "    - Il valore con cui sostituire i valori che non soddisfano la condizione. Se non specificato, il valore di default √® `NaN`.\n",
    "3. **`inplace`** (opzionale, default: `False`):\n",
    "    - Se impostato su `True`, modifica l'oggetto originale senza restituire una copia. Se impostato su `False` (default), restituisce una nuova Serie o DataFrame con i valori modificati.\n",
    "4. **`axis`** (opzionale, default: `None`):\n",
    "    - Indica l'asse lungo cui applicare la maschera (se usato con un DataFrame multi-indice).\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"Et√†\": [25, 30, 35, 40],\n",
    "    \"Salario\": [50000, 60000, 70000, 80000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "0    Alice   25    50000\n",
    "1      Bob   30    60000\n",
    "2  Charlie   35    70000\n",
    "3    Diana   40    80000\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Sostituire i valori che non soddisfano una condizione\n",
    "\n",
    "Vogliamo sostituire i valori nella colonna \"Salario\" con `NaN` se sono inferiori a 70000:\n",
    "\n",
    "```python\n",
    "result = df[\"Salario\"].mask(df[\"Salario\"] < 70000)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0     NaN\n",
    "1     NaN\n",
    "2  70000.0\n",
    "3  80000.0\n",
    "Name: Salario, dtype: float64\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, i valori inferiori a 70000 sono stati sostituiti con `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Sostituire i valori che non soddisfano la condizione con un altro valore\n",
    "\n",
    "Se vogliamo sostituire i valori che non soddisfano la condizione con un altro valore, ad esempio `0`, possiamo farlo cos√¨:\n",
    "\n",
    "```python\n",
    "result = df[\"Salario\"].mask(df[\"Salario\"] < 70000, other=0)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "0    0\n",
    "1    0\n",
    "2    70000\n",
    "3    80000\n",
    "Name: Salario, dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, i valori inferiori a 70000 sono stati sostituiti con `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Applicare `.mask()` a tutto un DataFrame\n",
    "\n",
    "Se vogliamo applicare una condizione a tutte le colonne del DataFrame e sostituire i valori che non soddisfano la condizione, possiamo farlo cos√¨:\n",
    "\n",
    "```python\n",
    "result = df.mask(df >= 30)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Et√†  Salario\n",
    "0     NaN   NaN      NaN\n",
    "1     NaN   NaN      NaN\n",
    "2  Charlie   35.0  70000.0\n",
    "3    Diana   40.0  80000.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, tutte le righe con valori inferiori a 30 sono state sostituite con `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Utilizzare `inplace=True`\n",
    "\n",
    "Per modificare direttamente il DataFrame originale senza creare una copia, possiamo usare `inplace=True`:\n",
    "\n",
    "```python\n",
    "df.mask(df[\"Et√†\"] < 30, inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Et√†  Salario\n",
    "0     NaN   NaN      NaN\n",
    "1     NaN   NaN      NaN\n",
    "2  Charlie   35.0  70000.0\n",
    "3    Diana   40.0  80000.0\n",
    "\n",
    "```\n",
    "\n",
    "Le righe con et√† inferiore a 30 sono state sostituite con `NaN` direttamente nel DataFrame `df`.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Applicare la maschera su pi√π colonne\n",
    "\n",
    "Possiamo applicare la maschera su pi√π colonne contemporaneamente:\n",
    "\n",
    "```python\n",
    "df.mask((df[\"Salario\"] < 70000) & (df[\"Et√†\"] < 30), other=0, inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome   Et√†  Salario\n",
    "0    Alice   25    50000\n",
    "1      Bob   30    60000\n",
    "2  Charlie   35  70000.0\n",
    "3    Diana   40  80000.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, la maschera sostituisce i valori di \"Salario\" con `0` se sono inferiori a 70000 e \"Et√†\" inferiore a 30.\n",
    "\n",
    "---\n",
    "\n",
    "### Quando utilizzare `.mask()`?\n",
    "\n",
    "- Quando vuoi mascherare o nascondere i valori che non soddisfano una condizione, sostituendoli con un valore (ad esempio, `NaN` o un altro valore personalizzato).\n",
    "- Quando desideri filtrare i dati in modo simile a `.where()`, ma con la logica invertita (mascherare invece che mantenere).\n",
    "- Quando vuoi modificare direttamente il DataFrame o la Serie senza creare una copia (usando `inplace=True`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.squeeze()`¬†‚Äì Converte un DataFrame con una sola colonna in una Serie\n",
    "\n",
    "Il metodo `.squeeze()` in **Pandas** √® utilizzato per ridurre la dimensione di un oggetto DataFrame o Serie. Esso restituisce una versione \"squeezed\" dell'oggetto, cio√® riduce le dimensioni quando possibile. Questo significa che, se un DataFrame ha una sola colonna o una sola riga, il risultato sar√† una Serie invece di un DataFrame. Se non c'√® una riduzione di dimensioni possibile (ad esempio, se l'oggetto ha pi√π di una colonna o riga), l'oggetto rimarr√† invariato.\n",
    "\n",
    "### Principali parametri\n",
    "\n",
    "1. **`axis`** (opzionale):\n",
    "    - Se impostato su `0` (default), la riduzione avverr√† lungo le righe (trasformando un DataFrame con una sola colonna in una Serie).\n",
    "    - Se impostato su `1`, la riduzione avverr√† lungo le colonne (trasformando un DataFrame con una sola riga in una Serie).\n",
    "    - Se non √® possibile ridurre l'oggetto lungo l'asse specificato, il risultato rimarr√† invariato.\n",
    "\n",
    "---\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "### Dati di esempio\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Nome\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Et√†\": [25, 30, 35],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "      Nome  Et√†\n",
    "0    Alice   25\n",
    "1      Bob   30\n",
    "2  Charlie   35\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Utilizzare `.squeeze()` su un DataFrame con una sola colonna\n",
    "\n",
    "Se abbiamo un DataFrame con una sola colonna, `.squeeze()` trasformer√† il DataFrame in una Serie:\n",
    "\n",
    "```python\n",
    "df_single_column = df[[\"Nome\"]]  # DataFrame con una sola colonna\n",
    "print(df_single_column)\n",
    "\n",
    "squeezed = df_single_column.squeeze()\n",
    "print(squeezed)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "# DataFrame con una colonna\n",
    "      Nome\n",
    "0    Alice\n",
    "1      Bob\n",
    "2  Charlie\n",
    "\n",
    "# Serie risultante\n",
    "0      Alice\n",
    "1        Bob\n",
    "2    Charlie\n",
    "Name: Nome, dtype: object\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, il DataFrame `df_single_column` √® stato trasformato in una Serie contenente i nomi.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Utilizzare `.squeeze()` su un DataFrame con una sola riga\n",
    "\n",
    "Se abbiamo un DataFrame con una sola riga, `.squeeze()` lo trasformer√† in una Serie:\n",
    "\n",
    "```python\n",
    "df_single_row = df.iloc[0:1]  # DataFrame con una sola riga\n",
    "print(df_single_row)\n",
    "\n",
    "squeezed = df_single_row.squeeze()\n",
    "print(squeezed)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "# DataFrame con una riga\n",
    "      Nome  Et√†\n",
    "0    Alice   25\n",
    "\n",
    "# Serie risultante\n",
    "Nome    Alice\n",
    "Et√†        25\n",
    "dtype: object\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, il DataFrame con una sola riga √® stato trasformato in una Serie con i valori delle colonne.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Utilizzare `.squeeze()` su una Serie\n",
    "\n",
    "Se il DataFrame √® gi√† una Serie (ad esempio, una colonna estratta da un DataFrame), `.squeeze()` non cambier√† nulla:\n",
    "\n",
    "```python\n",
    "series = df[\"Nome\"]\n",
    "print(series)\n",
    "\n",
    "squeezed = series.squeeze()\n",
    "print(squeezed)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "# Serie\n",
    "0      Alice\n",
    "1        Bob\n",
    "2    Charlie\n",
    "Name: Nome, dtype: object\n",
    "\n",
    "# La Serie resta invariata\n",
    "0      Alice\n",
    "1        Bob\n",
    "2    Charlie\n",
    "Name: Nome, dtype: object\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Utilizzare `.squeeze()` per un DataFrame con pi√π di una colonna\n",
    "\n",
    "Se il DataFrame ha pi√π di una colonna o pi√π di una riga, il metodo `.squeeze()` non avr√† alcun effetto:\n",
    "\n",
    "```python\n",
    "df_multiple_columns = df  # DataFrame con pi√π di una colonna\n",
    "squeezed = df_multiple_columns.squeeze()\n",
    "print(squeezed)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "# DataFrame originale (non cambia)\n",
    "      Nome  Et√†\n",
    "0    Alice   25\n",
    "1      Bob   30\n",
    "2  Charlie   35\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, il DataFrame con pi√π di una colonna non verr√† modificato.\n",
    "\n",
    "---\n",
    "\n",
    "### Quando utilizzare `.squeeze()`?\n",
    "\n",
    "- Quando hai un DataFrame con una sola colonna o riga e desideri convertirlo automaticamente in una Serie, per ridurre la complessit√† dell'oggetto.\n",
    "- Quando lavori con il risultato di operazioni che possono restituire DataFrame con una sola colonna o riga e desideri semplificarne la struttura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.drop()` ‚Äì Rimuove etichette specifiche da righe o colonne in un DataFrame\n",
    "\n",
    "Il metodo `.drop()` di Pandas √® usato per rimuovere righe o colonne da un DataFrame. Pu√≤ essere utilizzato per rimuovere dati che non sono pi√π necessari, come colonne obsolete o righe con valori che non servono all'analisi.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **labels**:\n",
    "    - Tipo: `str`, `list of str`\n",
    "    - Descrizione: Specifica le etichette delle righe o delle colonne che si desidera rimuovere.\n",
    "    - Esempio: `'colonna1'` o `['colonna1', 'colonna2']` per rimuovere pi√π colonne.\n",
    "2. **axis**:\n",
    "    - Tipo: `int`, `str`\n",
    "    - Descrizione: Indica se rimuovere righe (`axis=0` o `axis='index'`) o colonne (`axis=1` o `axis='columns'`).\n",
    "    - Default: `axis=0` (per rimuovere righe).\n",
    "    - Esempio: `axis=1` per rimuovere colonne, `axis=0` per rimuovere righe.\n",
    "3. **inplace**:\n",
    "    - Tipo: `bool`\n",
    "    - Descrizione: Se impostato su `True`, l'operazione modifica il DataFrame originale senza restituirne una copia. Se impostato su `False` (comportamento predefinito), restituisce un nuovo DataFrame senza modificare quello originale.\n",
    "    - Default: `False`.\n",
    "    - Esempio: `inplace=True` se si desidera modificare il DataFrame direttamente.\n",
    "4. **errors**:\n",
    "    - Tipo: `{'raise', 'ignore'}`, default 'raise'\n",
    "    - Descrizione: Se impostato su `'raise'` (predefinito), viene sollevata un'eccezione se le etichette non esistono. Se impostato su `'ignore'`, non viene sollevata alcuna eccezione se una o pi√π etichette non vengono trovate.\n",
    "    - Esempio: `errors='ignore'` per evitare eccezioni se le etichette non esistono.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "**1. Rimuovere una colonna dal DataFrame:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di un DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Rimuovi la colonna 'B'\n",
    "df = df.drop('B', axis=1)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  C\n",
    "0  1  7\n",
    "1  2  8\n",
    "2  3  9\n",
    "\n",
    "```\n",
    "\n",
    "**2. Rimuovere pi√π colonne:**\n",
    "\n",
    "```python\n",
    "df = df.drop(['A', 'C'], axis=1)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Empty DataFrame\n",
    "Columns: []\n",
    "Index: [0, 1, 2]\n",
    "\n",
    "```\n",
    "\n",
    "**3. Rimuovere una riga dal DataFrame:**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Rimuovi la riga con l'indice 1\n",
    "df = df.drop(1, axis=0)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C\n",
    "0  1  4  7\n",
    "2  3  6  9\n",
    "\n",
    "```\n",
    "\n",
    "**4. Modifica il DataFrame in loco (senza creare una copia):**\n",
    "\n",
    "```python\n",
    "df.drop('B', axis=1, inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  C\n",
    "0  1  7\n",
    "1  2  8\n",
    "2  3  9\n",
    "\n",
    "```\n",
    "\n",
    "**5. Gestire l'errore se l'etichetta non esiste:**\n",
    "\n",
    "```python\n",
    "df = df.drop('D', axis=1, errors='ignore')\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  C\n",
    "0  1  7\n",
    "1  2  8\n",
    "2  3  9\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**: Utilizza `.drop()` quando desideri eliminare righe o colonne non necessarie da un DataFrame, ad esempio per rimuovere dati errati, fare pulizia o preparare il dataset per l'analisi.\n",
    "- **Performance**: Se stai lavorando con un DataFrame molto grande e non hai bisogno di mantenere una copia, `inplace=True` pu√≤ essere utile per evitare di creare una copia aggiuntiva in memoria.\n",
    "- **Gestione degli errori**: Se non sei sicuro che una colonna o una riga esista, √® una buona pratica usare `errors='ignore'` per evitare interruzioni non necessarie nel codice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.dropna()` ‚Äì Rimuove righe o colonne con valori mancanti\n",
    "\n",
    "Il metodo `.dropna()` di Pandas √® utilizzato per rimuovere righe o colonne che contengono valori mancanti (`NaN`). Questo √® particolarmente utile quando si desidera rimuovere dati incompleti da un DataFrame per garantire che l'analisi successiva non venga influenzata da valori nulli.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **axis**:\n",
    "    - Tipo: `int` o `str`\n",
    "    - Descrizione: Specifica se rimuovere righe (`axis=0` o `axis='index'`) o colonne (`axis=1` o `axis='columns'`).\n",
    "    - Default: `axis=0` (per rimuovere righe).\n",
    "    - Esempio: `axis=1` per rimuovere colonne, `axis=0` per rimuovere righe.\n",
    "2. **how**:\n",
    "    - Tipo: `{'any', 'all'}`, default `any`\n",
    "    - Descrizione: Determina come deve essere gestito il valore mancante:\n",
    "        - `'any'`: Rimuove la riga o la colonna se **qualsiasi** valore √® `NaN`.\n",
    "        - `'all'`: Rimuove la riga o la colonna solo se **tutti** i valori sono `NaN`.\n",
    "    - Esempio: `how='all'` per rimuovere solo righe o colonne che contengono esclusivamente `NaN`.\n",
    "3. **thresh**:\n",
    "    - Tipo: `int`, default `None`\n",
    "    - Descrizione: Richiede che almeno un certo numero di valori non `NaN` siano presenti. Se ad esempio si imposta `thresh=2` per rimuovere una riga, la riga verr√† mantenuta solo se contiene almeno 2 valori non `NaN`.\n",
    "    - Esempio: `thresh=2` per mantenere righe con almeno 2 valori non nulli.\n",
    "4. **subset**:\n",
    "    - Tipo: `array-like`, default `None`\n",
    "    - Descrizione: Specifica le colonne su cui applicare l'operazione di rimozione dei valori mancanti. Se non specificato, l'operazione viene applicata a tutte le colonne.\n",
    "    - Esempio: `subset=['colonna1', 'colonna2']` per rimuovere righe solo se i valori in queste colonne sono `NaN`.\n",
    "5. **inplace**:\n",
    "    - Tipo: `bool`\n",
    "    - Descrizione: Se impostato su `True`, l'operazione modifica direttamente il DataFrame originale. Se impostato su `False` (comportamento predefinito), viene restituito un nuovo DataFrame senza modificare quello originale.\n",
    "    - Default: `False`.\n",
    "    - Esempio: `inplace=True` se desideri modificare il DataFrame direttamente.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "**1. Rimuovere righe con valori mancanti:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di un DataFrame di esempio con valori mancanti\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, 2, 3, 4],\n",
    "    'C': [1, None, 3, 4]\n",
    "})\n",
    "\n",
    "# Rimuovere righe con almeno un valore mancante\n",
    "df_cleaned = df.dropna(axis=0)\n",
    "print(df_cleaned)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "3  4.0  4.0  4.0\n",
    "\n",
    "```\n",
    "\n",
    "**2. Rimuovere colonne con valori mancanti:**\n",
    "\n",
    "```python\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "print(df_cleaned)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A\n",
    "0  1.0\n",
    "1  2.0\n",
    "2  NaN\n",
    "3  4.0\n",
    "\n",
    "```\n",
    "\n",
    "**3. Rimuovere righe dove tutte le colonne contengono valori mancanti:**\n",
    "\n",
    "```python\n",
    "df_cleaned = df.dropna(axis=0, how='all')\n",
    "print(df_cleaned)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "0  1.0  NaN  1.0\n",
    "1  2.0  2.0  NaN\n",
    "2  NaN  3.0  3.0\n",
    "3  4.0  4.0  4.0\n",
    "\n",
    "```\n",
    "\n",
    "**4. Mantenere righe con almeno 2 valori non nulli:**\n",
    "\n",
    "```python\n",
    "df_cleaned = df.dropna(axis=0, thresh=2)\n",
    "print(df_cleaned)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "0  1.0  NaN  1.0\n",
    "1  2.0  2.0  NaN\n",
    "2  NaN  3.0  3.0\n",
    "3  4.0  4.0  4.0\n",
    "\n",
    "```\n",
    "\n",
    "**5. Rimuovere righe con valori mancanti in colonne specifiche:**\n",
    "\n",
    "```python\n",
    "df_cleaned = df.dropna(axis=0, subset=['A', 'B'])\n",
    "print(df_cleaned)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "1  2.0  2.0  NaN\n",
    "2  NaN  3.0  3.0\n",
    "3  4.0  4.0  4.0\n",
    "\n",
    "```\n",
    "\n",
    "**6. Modifica in loco (senza creare una copia):**\n",
    "\n",
    "```python\n",
    "df.dropna(axis=1, inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A\n",
    "0  1.0\n",
    "1  2.0\n",
    "2  NaN\n",
    "3  4.0\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**: Utilizza `.dropna()` quando i valori mancanti sono problematici per l'analisi o quando si desidera rimuovere righe o colonne incomplete per migliorare la qualit√† dei dati.\n",
    "- **Performance**: Se il DataFrame √® molto grande, l'uso di `inplace=True` pu√≤ aiutare a risparmiare memoria, poich√© evita di creare una copia del DataFrame.\n",
    "- **Alternative**: Se i valori mancanti non sono troppi e non vuoi rimuoverli completamente, considera l'uso di metodi come `.fillna()` per sostituire i `NaN` con un valore di tua scelta, come la media o la mediana.\n",
    "- **Attenzione**: Se usi `axis=0` (righe) e rimuovi troppe righe, il tuo dataset potrebbe diventare troppo piccolo. Assicurati che la rimozione dei `NaN` non comprometta troppo i tuoi dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.fillna()` ‚Äì Sostituisce i valori mancanti con un valore specificato\n",
    "\n",
    "Il metodo `.fillna()` di Pandas √® utilizzato per sostituire i valori mancanti (`NaN`) in un DataFrame o una Serie con un valore specificato. √à particolarmente utile quando si vuole riempire i dati mancanti con un valore di imputazione (come la media, la mediana, o un valore costante), per evitare che l'analisi venga influenzata dalla presenza di valori nulli.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **value**:\n",
    "    - Tipo: `scalar`, `dict`, `Series`, `DataFrame`\n",
    "    - Descrizione: Specifica il valore con cui sostituire i valori mancanti. Pu√≤ essere un singolo valore (ad esempio, un numero o una stringa) o una struttura di dati (come un dizionario o un DataFrame) che mappa le colonne ai valori da usare.\n",
    "    - Esempio:\n",
    "        - `value=0`: Sostituisce tutti i `NaN` con 0.\n",
    "        - `value={'col1': 0, 'col2': 1}`: Sostituisce i `NaN` in `col1` con 0 e in `col2` con 1.\n",
    "2. **axis**:\n",
    "    - Tipo: `int`, `str`\n",
    "    - Descrizione: Indica se applicare la sostituzione per righe (`axis=0` o `axis='index'`) o per colonne (`axis=1` o `axis='columns'`).\n",
    "    - Default: `None`, che significa applicare il riempimento a tutte le righe e colonne.\n",
    "    - Esempio: `axis=0` per riempire le righe, `axis=1` per riempire le colonne.\n",
    "3. **method**:\n",
    "    - Tipo: `{'ffill', 'bfill'}`, default `None`\n",
    "    - Descrizione: Metodo di riempimento:\n",
    "        - `'ffill'`: Propaga il valore precedente (forward fill).\n",
    "        - `'bfill'`: Propaga il valore successivo (backward fill).\n",
    "    - Esempio: `method='ffill'` per riempire i `NaN` con il valore precedente.\n",
    "4. **limit**:\n",
    "    - Tipo: `int`, default `None`\n",
    "    - Descrizione: Limita il numero di valori da riempire. Se ad esempio si imposta `limit=1`, solo il primo valore mancante verr√† sostituito.\n",
    "    - Esempio: `limit=1` per riempire solo il primo valore `NaN`.\n",
    "5. **inplace**:\n",
    "    - Tipo: `bool`, default `False`\n",
    "    - Descrizione: Se impostato su `True`, l'operazione modifica il DataFrame originale senza restituirne una copia. Se impostato su `False` (comportamento predefinito), viene restituito un nuovo DataFrame con i valori riempiti.\n",
    "    - Esempio: `inplace=True` se si desidera modificare direttamente il DataFrame senza creare una copia.\n",
    "6. **regex** (disponibile in alcune versioni di Pandas):\n",
    "    - Tipo: `bool` o `str`\n",
    "    - Descrizione: Se √® un'espressione regolare, il riempimento avviene solo sulle colonne che soddisfano il pattern regex.\n",
    "    - Esempio: `regex=True` per fare il riempimento basato su pattern.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "**1. Sostituire tutti i valori `NaN` con un valore costante (ad esempio, 0):**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di un DataFrame con valori mancanti\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, None, 3, None],\n",
    "    'B': [None, 2, None, 4],\n",
    "    'C': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "# Sostituire tutti i NaN con 0\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B  C\n",
    "0  1.0  0.0  1\n",
    "1  0.0  2.0  2\n",
    "2  3.0  0.0  3\n",
    "3  0.0  4.0  4\n",
    "\n",
    "```\n",
    "\n",
    "**2. Sostituire i valori `NaN` in colonne specifiche con valori diversi:**\n",
    "\n",
    "```python\n",
    "df_filled = df.fillna({'A': 0, 'B': 1})\n",
    "print(df_filled)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B  C\n",
    "0  1.0  1.0  1\n",
    "1  0.0  2.0  2\n",
    "2  3.0  1.0  3\n",
    "3  0.0  4.0  4\n",
    "\n",
    "```\n",
    "\n",
    "**3. Sostituire i `NaN` con il valore precedente (forward fill):**\n",
    "\n",
    "```python\n",
    "df_filled = df.fillna(method='ffill')\n",
    "print(df_filled)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B  C\n",
    "0  1.0  NaN  1\n",
    "1  1.0  2.0  2\n",
    "2  3.0  2.0  3\n",
    "3  3.0  4.0  4\n",
    "\n",
    "```\n",
    "\n",
    "**4. Sostituire i `NaN` con il valore successivo (backward fill):**\n",
    "\n",
    "```python\n",
    "df_filled = df.fillna(method='bfill')\n",
    "print(df_filled)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B  C\n",
    "0  1.0  2.0  1\n",
    "1  3.0  2.0  2\n",
    "2  3.0  4.0  3\n",
    "3  3.0  4.0  4\n",
    "\n",
    "```\n",
    "\n",
    "**5. Limite sul numero di sostituzioni (ad esempio, sostituire solo 1 valore `NaN`):**\n",
    "\n",
    "```python\n",
    "df_filled = df.fillna(0, limit=1)\n",
    "print(df_filled)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B  C\n",
    "0  1.0  0.0  1\n",
    "1  0.0  2.0  2\n",
    "2  3.0  NaN  3\n",
    "3  0.0  4.0  4\n",
    "\n",
    "```\n",
    "\n",
    "**6. Modifica in loco (senza creare una copia):**\n",
    "\n",
    "```python\n",
    "df.fillna(0, inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B  C\n",
    "0  1.0  0.0  1\n",
    "1  0.0  2.0  2\n",
    "2  3.0  0.0  3\n",
    "3  0.0  4.0  4\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**: Utilizza `.fillna()` quando i valori mancanti sono frequenti e vuoi riempirli con un valore significativo per l'analisi. Questo √® utile quando i `NaN` potrebbero compromettere il processo di modellizzazione o l'analisi statistica.\n",
    "- **Sostituzione con la media/mediana**: Una strategia comune √® sostituire i `NaN` con la **media** o **mediana** della colonna, specialmente nei modelli di machine learning.\n",
    "- **Metodo di propagazione**: Quando hai dati sequenziali (come serie temporali), il riempimento con valori precedenti (`ffill`) o successivi (`bfill`) pu√≤ essere utile per evitare di introdurre distorsioni nei dati.\n",
    "- **Attenzione**: Quando riempi i `NaN`, verifica che il valore scelto non distorca troppo l'analisi. Ad esempio, riempire con valori di media o mediana pu√≤ mascherare informazioni utili. Considera anche l'uso di altre tecniche di imputazione se i `NaN` sono presenti in modo non casuale o se la sostituzione con un valore costante non √® adeguata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.replace()` ‚Äì Sostituisce valori nel DataFrame\n",
    "\n",
    "Il metodo `.replace()` di Pandas viene utilizzato per sostituire i valori in un DataFrame o in una Serie con altri valori specificati. √à un'operazione molto utile quando si desidera modificare i dati in modo selettivo, come sostituire valori errati, sostituire categorie numeriche con etichette o altre trasformazioni simili.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **to_replace**:\n",
    "    - Tipo: `scalar`, `dict`, `list`, `Series`, o `DataFrame`\n",
    "    - Descrizione: Il valore o i valori da sostituire. Pu√≤ essere un singolo valore (come un numero o una stringa), una lista o un dizionario che mappa i valori da sostituire nelle colonne o righe specifiche.\n",
    "    - Esempio: `to_replace=1` per sostituire tutte le occorrenze di 1.\n",
    "2. **value**:\n",
    "    - Tipo: `scalar`, `dict`, `list`, `Series`, o `DataFrame`\n",
    "    - Descrizione: I nuovi valori con cui sostituire quelli indicati in `to_replace`. Se `to_replace` √® un dizionario, anche `value` deve essere un dizionario che mappa le colonne o le righe ai nuovi valori.\n",
    "    - Esempio: `value=10` per sostituire ogni occorrenza di `1` con `10`.\n",
    "3. **inplace**:\n",
    "    - Tipo: `bool`, default `False`\n",
    "    - Descrizione: Se impostato su `True`, l'operazione modifica il DataFrame originale senza restituirne una copia. Se impostato su `False`, viene restituito un nuovo DataFrame con i valori sostituiti.\n",
    "    - Esempio: `inplace=True` per modificare direttamente il DataFrame senza creare una copia.\n",
    "4. **regex**:\n",
    "    - Tipo: `bool` o `str`\n",
    "    - Descrizione: Se impostato su `True` o su una stringa (espressione regolare), `.replace()` applicher√† il valore di sostituzione a tutte le occorrenze che corrispondono al pattern regex fornito.\n",
    "    - Esempio: `regex=True` per cercare e sostituire valori che corrispondono a un pattern.\n",
    "5. **method**:\n",
    "    - Tipo: `{'pad', 'ffill', 'bfill'}`, default `None`\n",
    "    - Descrizione: Metodo per riempire i valori mancanti, quando √® utilizzato in combinazione con `to_replace` e `value` che sono `NaN` o valori nulli. I metodi disponibili sono:\n",
    "        - `'pad'` o `'ffill'`: Propaga il valore precedente.\n",
    "        - `'bfill'`: Propaga il valore successivo.\n",
    "    - Esempio: `method='ffill'` per riempire i `NaN` con il valore precedente.\n",
    "6. **limit**:\n",
    "    - Tipo: `int`, default `None`\n",
    "    - Descrizione: Limita il numero di sostituzioni che devono essere effettuate. Questo √® utile se vuoi sostituire solo un numero specifico di occorrenze.\n",
    "    - Esempio: `limit=2` per sostituire solo le prime due occorrenze di `to_replace`.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "**1. Sostituire un valore singolo con un altro valore:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di un DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 1],\n",
    "    'B': [1, 1, 2, 2, 3]\n",
    "})\n",
    "\n",
    "# Sostituire 1 con 10 in tutto il DataFrame\n",
    "df_replaced = df.replace(1, 10)\n",
    "print(df_replaced)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    A   B\n",
    "0  10  10\n",
    "1   2  10\n",
    "2   3   2\n",
    "3   4   2\n",
    "4  10   3\n",
    "\n",
    "```\n",
    "\n",
    "**2. Sostituire valori specifici in colonne diverse:**\n",
    "\n",
    "```python\n",
    "df_replaced = df.replace({'A': {1: 100, 4: 400}, 'B': {1: 10, 2: 20}})\n",
    "print(df_replaced)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A   B\n",
    "0  100  10\n",
    "1    2  10\n",
    "2    3  20\n",
    "3    4  20\n",
    "4  400   3\n",
    "\n",
    "```\n",
    "\n",
    "**3. Sostituire pi√π valori contemporaneamente con un dizionario:**\n",
    "\n",
    "```python\n",
    "df_replaced = df.replace({1: 100, 2: 200, 3: 300})\n",
    "print(df_replaced)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  100  100\n",
    "1  200  100\n",
    "2  300  200\n",
    "3    4  200\n",
    "4  100  300\n",
    "\n",
    "```\n",
    "\n",
    "**4. Usare una lista di valori da sostituire con una lista di nuovi valori:**\n",
    "\n",
    "```python\n",
    "df_replaced = df.replace([1, 2, 3], [10, 20, 30])\n",
    "print(df_replaced)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0   10   10\n",
    "1   20   10\n",
    "2   30   20\n",
    "3    4   20\n",
    "4   10   30\n",
    "\n",
    "```\n",
    "\n",
    "**5. Sostituire usando espressioni regolari:**\n",
    "\n",
    "```python\n",
    "df_replaced = df.replace(r'^1$', 100, regex=True)\n",
    "print(df_replaced)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  100  100\n",
    "1    2  100\n",
    "2    3    2\n",
    "3    4    2\n",
    "4  100    3\n",
    "\n",
    "```\n",
    "\n",
    "**6. Sostituire valori mancanti (`NaN`) con un valore specificato:**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, 2, 3, 4]\n",
    "})\n",
    "\n",
    "# Sostituire i NaN con 0\n",
    "df_filled = df.replace({None: 0})\n",
    "print(df_filled)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A  B\n",
    "0  1.0  0\n",
    "1  2.0  2\n",
    "2  0.0  3\n",
    "3  4.0  4\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**: Usa `.replace()` quando hai bisogno di sostituire specifici valori in un DataFrame o una Serie, come per correggere errori nei dati, trasformare categorie numeriche in etichette o fare una mappatura di valori. √à anche utile quando lavori con dati di testo o quando i dati contengono valori speciali che devono essere standardizzati.\n",
    "- **Sostituzione selettiva**: `.replace()` √® pi√π utile quando vuoi essere selettivo nel sostituire solo determinati valori, come ad esempio valori specifici in determinate colonne o righe, rispetto ad altri metodi di sostituzione come `.fillna()` o `.dropna()`, che sono pi√π generali.\n",
    "- **Regex e `to_replace`**: L'uso di espressioni regolari √® utile quando i valori da sostituire seguono uno schema complesso e non sono semplici valori costanti.\n",
    "- **Limitazione delle sostituzioni**: Il parametro `limit` √® utile se hai bisogno di sostituire solo un numero limitato di valori, per esempio quando hai valori ripetitivi e non vuoi modificare tutti i casi.\n",
    "- **Inplace**: L'opzione `inplace=True` √® molto utile se vuoi modificare direttamente il DataFrame originale senza creare una copia, ma fai attenzione a non alterare i dati originali se hai bisogno di conservarli per future analisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.rename()` ‚Äì Rinomina colonne o indici\n",
    "\n",
    "Il metodo `.rename()` di Pandas permette di rinominare le etichette delle righe (indici) o delle colonne di un DataFrame. √à utile quando si desidera cambiare i nomi in modo selettivo o quando si lavora con dataset che contengono nomi di colonne non chiari o che necessitano di una standardizzazione.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **columns**:\n",
    "    - Tipo: `dict`, opzionale\n",
    "    - Descrizione: Un dizionario che mappa i vecchi nomi delle colonne ai nuovi nomi. Se passato, solo le colonne indicate nel dizionario verranno rinominate.\n",
    "    - Esempio: `columns={'old_name': 'new_name'}`.\n",
    "2. **index**:\n",
    "    - Tipo: `dict`, opzionale\n",
    "    - Descrizione: Un dizionario che mappa i vecchi nomi degli indici ai nuovi nomi. Se passato, solo gli indici indicati nel dizionario verranno rinominati.\n",
    "    - Esempio: `index={0: 'row1', 1: 'row2'}`.\n",
    "3. **inplace**:\n",
    "    - Tipo: `bool`, default `False`\n",
    "    - Descrizione: Se impostato su `True`, modifica direttamente il DataFrame senza restituire una copia modificata. Se impostato su `False` (comportamento predefinito), viene restituito un nuovo DataFrame con i nomi aggiornati.\n",
    "    - Esempio: `inplace=True` per aggiornare direttamente il DataFrame originale.\n",
    "4. **level**:\n",
    "    - Tipo: `int`, `str`, o `tuple`, opzionale\n",
    "    - Descrizione: Specifica il livello da rinominare, se il DataFrame ha un MultiIndex. Se il DataFrame √® a pi√π livelli, questo parametro pu√≤ essere usato per rinominare solo un livello specifico.\n",
    "    - Esempio: `level=0` per rinominare solo il livello 0.\n",
    "5. **axis**:\n",
    "    - Tipo: `int` o `str`, opzionale\n",
    "    - Descrizione: Specifica se rinominare le colonne (`axis=1` o `axis='columns'`) o gli indici (`axis=0` o `axis='index'`). Questo parametro √® utile quando si vuole cambiare i nomi degli indici senza cambiare quelli delle colonne.\n",
    "    - Esempio: `axis=1` per rinominare le colonne.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "**1. Rinominare colonne specifiche:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di un DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Rinominare le colonne 'A' e 'B'\n",
    "df_renamed = df.rename(columns={'A': 'Alpha', 'B': 'Beta'})\n",
    "print(df_renamed)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   Alpha  Beta  C\n",
    "0      1     4  7\n",
    "1      2     5  8\n",
    "2      3     6  9\n",
    "\n",
    "```\n",
    "\n",
    "**2. Rinominare gli indici (righe):**\n",
    "\n",
    "```python\n",
    "df_renamed = df.rename(index={0: 'row_1', 1: 'row_2', 2: 'row_3'})\n",
    "print(df_renamed)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      A  B  C\n",
    "row_1  1  4  7\n",
    "row_2  2  5  8\n",
    "row_3  3  6  9\n",
    "\n",
    "```\n",
    "\n",
    "**3. Rinominare sia indici che colonne:**\n",
    "\n",
    "```python\n",
    "df_renamed = df.rename(index={0: 'row_1', 1: 'row_2'}, columns={'A': 'Alpha'})\n",
    "print(df_renamed)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Alpha  B  C\n",
    "row_1     1  4  7\n",
    "row_2     2  5  8\n",
    "2         3  6  9\n",
    "\n",
    "```\n",
    "\n",
    "**4. Modificare direttamente il DataFrame usando `inplace=True`:**\n",
    "\n",
    "```python\n",
    "df.rename(columns={'A': 'Alpha', 'B': 'Beta'}, inplace=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   Alpha  Beta  C\n",
    "0      1     4  7\n",
    "1      2     5  8\n",
    "2      3     6  9\n",
    "\n",
    "```\n",
    "\n",
    "**5. Rinominare colonne in un DataFrame a pi√π livelli (MultiIndex):**\n",
    "\n",
    "```python\n",
    "# Creazione di un DataFrame con MultiIndex\n",
    "df_multi = pd.DataFrame({\n",
    "    ('A', 'X'): [1, 2, 3],\n",
    "    ('A', 'Y'): [4, 5, 6],\n",
    "    ('B', 'X'): [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Rinominare un livello del MultiIndex\n",
    "df_multi_renamed = df_multi.rename(columns={('A', 'X'): ('Alpha', 'X')})\n",
    "print(df_multi_renamed)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   (Alpha, X)  (A, Y)  (B, X)\n",
    "0           1       4       7\n",
    "1           2       5       8\n",
    "2           3       6       9\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**: Usa `.rename()` quando devi cambiare i nomi delle colonne o degli indici per rendere il tuo DataFrame pi√π leggibile o standardizzato. Questo metodo √® utile quando hai bisogno di rinominare solo alcune colonne o righe, invece di cambiare tutti i nomi del DataFrame.\n",
    "- **Inplace vs nuovo DataFrame**: Se vuoi evitare di creare una nuova variabile, puoi usare `inplace=True`. Tuttavia, fai attenzione quando utilizzi questa opzione, perch√© modifica direttamente il DataFrame originale.\n",
    "- **Uso con MultiIndex**: Quando lavori con DataFrame a pi√π livelli (MultiIndex), `.rename()` ti permette di rinominare sia i livelli degli indici che delle colonne. In questo caso, puoi specificare esattamente quali livelli vuoi modificare.\n",
    "- **Rinominare selettivamente**: √à molto utile per rinominare solo una parte delle colonne o degli indici, piuttosto che dover rinominare tutto il DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.interpolate()` ‚Äì Sostituisce valori NaN con valori interpolati\n",
    "\n",
    "Il metodo `.interpolate()` di Pandas √® utilizzato per riempire i valori `NaN` (Not a Number) in un DataFrame o in una Serie con valori interpolati, cio√® stimati in base ai dati circostanti. √à una tecnica comune nel trattamento dei dati mancanti quando si vuole preservare la tendenza o il pattern dei dati senza introdurre valori arbitri.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **method**:\n",
    "    - Tipo: `str`, opzionale\n",
    "    - Descrizione: Specifica il metodo di interpolazione da utilizzare. I metodi pi√π comuni sono:\n",
    "        - `'linear'`: Interpolazione lineare (default).\n",
    "        - `'polynomial'`: Interpolazione polinomiale, richiede il parametro `order`.\n",
    "        - `'spline'`: Interpolazione a splines, richiede il parametro `order`.\n",
    "        - `'barycentric'`: Interpolazione baricentrica.\n",
    "        - `'pchip'`: Interpolazione di tipo PCHIP (Piecewise Cubic Hermite Interpolating Polynomial).\n",
    "        - `'nearest'`, `'zero'`, `'slinear'`, ecc.\n",
    "    - Esempio: `method='linear'`.\n",
    "2. **axis**:\n",
    "    - Tipo: `int`, opzionale\n",
    "    - Descrizione: Indica l'asse lungo il quale effettuare l'interpolazione:\n",
    "        - `axis=0` per interpolare lungo le righe (default).\n",
    "        - `axis=1` per interpolare lungo le colonne.\n",
    "    - Esempio: `axis=1`.\n",
    "3. **limit**:\n",
    "    - Tipo: `int`, opzionale\n",
    "    - Descrizione: Limita il numero massimo di valori `NaN` che possono essere sostituiti. Se non specificato, il metodo interpoler√† tutti i valori `NaN`.\n",
    "    - Esempio: `limit=2`.\n",
    "4. **limit_direction**:\n",
    "    - Tipo: `str`, opzionale\n",
    "    - Descrizione: Definisce la direzione in cui applicare l'interpolazione:\n",
    "        - `'forward'`: Interpolazione solo dai valori precedenti.\n",
    "        - `'backward'`: Interpolazione solo dai valori successivi.\n",
    "        - `'both'`: Interpolazione in entrambe le direzioni (predefinito).\n",
    "    - Esempio: `limit_direction='forward'`.\n",
    "5. **limit_area**:\n",
    "    - Tipo: `str`, opzionale\n",
    "    - Descrizione: Limita l'area su cui eseguire l'interpolazione:\n",
    "        - `'inside'`: Interpolazione solo tra i valori numerici.\n",
    "        - `'outside'`: Interpolazione solo per i valori esterni.\n",
    "    - Esempio: `limit_area='inside'`.\n",
    "6. **order**:\n",
    "    - Tipo: `int`, opzionale\n",
    "    - Descrizione: Usato con il metodo `'polynomial'` o `'spline'`, specifica l'ordine del polinomio o il grado del spline.\n",
    "    - Esempio: `order=3` per un polinomio di terzo grado.\n",
    "7. **downcast**:\n",
    "    - Tipo: `bool`, opzionale\n",
    "    - Descrizione: Se impostato su `True`, tenta di fare il \"downcast\" dei tipi di dati dopo l'interpolazione.\n",
    "    - Esempio: `downcast=True`.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "**1. Interpolazione lineare (default):**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creazione di un DataFrame con valori NaN\n",
    "data = {'A': [1, 2, np.nan, 4, 5],\n",
    "        'B': [10, np.nan, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Interpolazione lineare per riempire i valori NaN\n",
    "df_interpolated = df.interpolate(method='linear')\n",
    "print(df_interpolated)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A     B\n",
    "0  1.0  10.0\n",
    "1  2.0  20.0\n",
    "2  3.0  30.0\n",
    "3  4.0  40.0\n",
    "4  5.0  50.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, i valori `NaN` vengono riempiti tramite interpolazione lineare, ossia, il valore intermedio √® calcolato come una media ponderata tra i valori precedenti e successivi.\n",
    "\n",
    "**2. Interpolazione polinomiale (di ordine 2):**\n",
    "\n",
    "```python\n",
    "df_interpolated = df.interpolate(method='polynomial', order=2)\n",
    "print(df_interpolated)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "          A     B\n",
    "0  1.000000  10.0\n",
    "1  2.000000  20.0\n",
    "2  3.000000  30.0\n",
    "3  4.000000  40.0\n",
    "4  5.000000  50.0\n",
    "\n",
    "```\n",
    "\n",
    "Qui, i valori `NaN` vengono riempiti utilizzando un polinomio di secondo grado che si adatta ai dati disponibili.\n",
    "\n",
    "**3. Interpolazione solo in avanti:**\n",
    "\n",
    "```python\n",
    "df_interpolated = df.interpolate(method='linear', limit_direction='forward')\n",
    "print(df_interpolated)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A     B\n",
    "0  1.0  10.0\n",
    "1  2.0  20.0\n",
    "2  3.0  30.0\n",
    "3  4.0  40.0\n",
    "4  5.0  50.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, l'interpolazione avviene solo dai valori precedenti (in avanti) e non vengono utilizzati i dati successivi.\n",
    "\n",
    "**4. Interpolazione limitata (2 valori al massimo):**\n",
    "\n",
    "```python\n",
    "df_interpolated = df.interpolate(method='linear', limit=2)\n",
    "print(df_interpolated)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A     B\n",
    "0  1.0  10.0\n",
    "1  2.0  20.0\n",
    "2  3.0  30.0\n",
    "3  4.0  40.0\n",
    "4  5.0  50.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, vengono interpolati al massimo 2 valori `NaN`.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**: `.interpolate()` √® utile quando si desidera riempire i valori `NaN` in un dataset in modo intelligente, mantenendo la tendenza e la coerenza dei dati. L'interpolazione √® particolarmente utile per serie temporali, dove √® importante preservare le relazioni tra i dati in sequenza.\n",
    "- **Vantaggi**:\n",
    "    - Permette di gestire valori mancanti senza ricorrere alla sostituzione con valori arbitrari (ad esempio, la media o la mediana).\n",
    "    - √à possibile scegliere tra vari metodi di interpolazione in base alla natura dei dati.\n",
    "- **Svantaggi**:\n",
    "    - L'interpolazione potrebbe non essere sempre appropriata per tutti i tipi di dati, ad esempio, se i dati sono altamente non lineari o contengono outlier significativi.\n",
    "    - Pu√≤ introdurre distorsioni se non viene scelto il metodo giusto.\n",
    "- **Uso**:\n",
    "    - Usa l'interpolazione quando hai dei valori `NaN` nei tuoi dati e desideri un riempimento basato sulla tendenza dei dati esistenti. √à particolarmente utile in contesti di analisi di serie temporali o dati continui.\n",
    "    - Evita di usarla quando i dati mancanti sono troppo numerosi o se l'interpolazione rischia di distorcere i risultati, come nei dati categorici o altamente discontinuativi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.bfill()` / `.ffill()` ‚Äì Riempimento all'indietro o in avanti dei valori NaN\n",
    "\n",
    "I metodi `.bfill()` e `.ffill()` di Pandas vengono utilizzati per riempire i valori mancanti (`NaN`) nei DataFrame o nelle Serie. Questi metodi sono utili per completare i dati in modo rapido e intuitivo, utilizzando i valori circostanti.\n",
    "\n",
    "### 1. **`.ffill()` (Forward Fill)**:\n",
    "\n",
    "Il metodo **forward fill** riempie i valori `NaN` con il valore precedente nella stessa colonna o riga. In altre parole, se un valore `NaN` viene trovato, il valore non `NaN` pi√π vicino prima di esso viene copiato al posto del `NaN`.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "- **axis**:\n",
    "    - Tipo: `int`, opzionale\n",
    "    - Descrizione: Specifica lungo quale asse applicare il riempimento.\n",
    "        - `axis=0` per applicare lungo le righe (default).\n",
    "        - `axis=1` per applicare lungo le colonne.\n",
    "- **limit**:\n",
    "    - Tipo: `int`, opzionale\n",
    "    - Descrizione: Limita il numero di valori `NaN` da riempire.\n",
    "- **inplace**:\n",
    "    - Tipo: `bool`, opzionale\n",
    "    - Descrizione: Se `True`, modifica il DataFrame in modo in-place, cio√® senza creare una nuova copia.\n",
    "\n",
    "### Esempio `.ffill()`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creazione di un DataFrame con valori NaN\n",
    "data = {'A': [1, np.nan, 3, np.nan, 5],\n",
    "        'B': [np.nan, 2, np.nan, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Riempimento in avanti dei valori NaN\n",
    "df_ffill = df.ffill()\n",
    "print(df_ffill)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  1.0  2.0\n",
    "1  1.0  2.0\n",
    "2  3.0  2.0\n",
    "3  3.0  4.0\n",
    "4  5.0  5.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, il valore `NaN` nella colonna 'A' alla posizione 1 viene riempito con il valore precedente (1.0). Allo stesso modo, i `NaN` nella colonna 'B' vengono riempiti in avanti con il valore pi√π vicino disponibile.\n",
    "\n",
    "### 2. **`.bfill()` (Backward Fill)**:\n",
    "\n",
    "Il metodo **backward fill** riempie i valori `NaN` con il valore successivo nella stessa colonna o riga. Se un valore `NaN` viene trovato, il valore successivo non `NaN` viene copiato al suo posto.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "- **axis**:\n",
    "    - Tipo: `int`, opzionale\n",
    "    - Descrizione: Specifica lungo quale asse applicare il riempimento.\n",
    "        - `axis=0` per applicare lungo le righe (default).\n",
    "        - `axis=1` per applicare lungo le colonne.\n",
    "- **limit**:\n",
    "    - Tipo: `int`, opzionale\n",
    "    - Descrizione: Limita il numero di valori `NaN` da riempire.\n",
    "- **inplace**:\n",
    "    - Tipo: `bool`, opzionale\n",
    "    - Descrizione: Se `True`, modifica il DataFrame in modo in-place.\n",
    "\n",
    "### Esempio `.bfill()`:\n",
    "\n",
    "```python\n",
    "# Riempimento all'indietro dei valori NaN\n",
    "df_bfill = df.bfill()\n",
    "print(df_bfill)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  1.0  2.0\n",
    "1  3.0  2.0\n",
    "2  3.0  4.0\n",
    "3  5.0  4.0\n",
    "4  5.0  5.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, il valore `NaN` nella colonna 'A' alla posizione 1 √® riempito con il valore successivo (3.0). Allo stesso modo, i `NaN` nella colonna 'B' sono riempiti con il valore successivo disponibile.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarli**:\n",
    "    - `.ffill()` √® utile quando si desidera riempire i valori mancanti con informazioni precedenti, ad esempio, in serie temporali dove i dati precedenti possono fornire una stima valida per i valori mancanti.\n",
    "    - `.bfill()` √® utile quando si desidera riempire i valori mancanti utilizzando informazioni future, spesso utilizzato quando si presume che i valori successivi possano essere rilevanti per il riempimento.\n",
    "- **Vantaggi**:\n",
    "    - Entrambi i metodi sono semplici e veloci da utilizzare per riempire i valori mancanti in modo consistente.\n",
    "    - Possono essere utilizzati quando non si vuole interpolare i dati, ma si desidera semplicemente riempire i `NaN` con i valori vicini.\n",
    "- **Svantaggi**:\n",
    "    - I metodi non sono adatti per dati non sequenziali o per dataset dove i valori mancanti non possono essere presunti basati sui dati precedenti o successivi.\n",
    "    - Non √® possibile effettuare un riempimento accurato in presenza di molti `NaN` consecutivi, a meno che non si usi il parametro `limit`.\n",
    "- **Uso**:\n",
    "    - Usa `.ffill()` quando i valori passati (precedenti) possono ragionevolmente stimare i valori futuri. Ad esempio, se stai lavorando con dati di sensori o serie temporali.\n",
    "    - Usa `.bfill()` quando i valori futuri sono preferibili per completare i valori mancanti, ad esempio, in serie temporali con previsione di valori futuri.\n",
    "\n",
    "Entrambi i metodi sono comunemente usati nella preparazione dei dati prima dell'analisi o del training di modelli, in particolare quando si hanno valori mancanti in contesti sequenziali o temporali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.convert_dtypes()` ‚Äì Converte le colonne nei migliori tipi di dati possibili\n",
    "\n",
    "Il metodo **`.convert_dtypes()`** di Pandas √® uno strumento potente per ottimizzare e migliorare i tipi di dati nelle colonne di un DataFrame. Questo metodo permette di convertire automaticamente le colonne ai tipi pi√π appropriati in base ai dati che contengono, migliorando l'efficienza della memoria e le prestazioni delle operazioni.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "- **infer_objects**:\n",
    "    - Tipo: `bool`, opzionale\n",
    "    - Descrizione: Se `True`, tenta di inferire il tipo di dati per le colonne che contengono oggetti (tipicamente stringhe). Impostato su `False`, non tenta di fare questa inferenza.\n",
    "- **convert_string**:\n",
    "    - Tipo: `bool`, opzionale\n",
    "    - Descrizione: Se `True`, tenter√† di convertire le colonne di tipo `object` in colonne di tipo `string` (Pandas ha il tipo di dati `string` a partire dalla versione 1.0).\n",
    "- **convert_integer**:\n",
    "    - Tipo: `bool`, opzionale\n",
    "    - Descrizione: Se `True`, tenter√† di convertire i valori interi che possono essere memorizzati in un tipo con una rappresentazione di memoria pi√π compatta (ad esempio, `Int8`, `Int16`, ecc.).\n",
    "\n",
    "### Funzionamento:\n",
    "\n",
    "Il metodo `.convert_dtypes()` esamina automaticamente i dati nel DataFrame e applica il tipo di dato pi√π appropriato per ciascuna colonna. Per esempio:\n",
    "\n",
    "- Se una colonna contiene solo numeri interi, Pandas la convertir√† in un tipo intero (`int` o `Int64`).\n",
    "- Se una colonna contiene numeri con decimali, la convertir√† in un tipo float.\n",
    "- Se una colonna contiene solo valori booleani, verr√† convertita in tipo `bool`.\n",
    "- Se una colonna contiene solo stringhe o oggetti, la convertir√† in tipo `string` se `convert_string=True`.\n",
    "\n",
    "### Esempio di utilizzo di `.convert_dtypes()`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di un DataFrame con tipi di dati misti\n",
    "data = {'A': ['1', '2', '3'],\n",
    "        'B': [1.5, 2.5, 3.5],\n",
    "        'C': [True, False, True],\n",
    "        'D': ['a', 'b', 'c']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualizzazione dei tipi di dati originali\n",
    "print(\"Tipi di dati originali:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Converto i tipi di dati nei migliori tipi possibili\n",
    "df_converted = df.convert_dtypes()\n",
    "\n",
    "# Visualizzazione dei tipi di dati dopo la conversione\n",
    "print(\"\\nTipi di dati dopo la conversione:\")\n",
    "print(df_converted.dtypes)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Tipi di dati originali:\n",
    "A     object\n",
    "B    float64\n",
    "C       bool\n",
    "D     object\n",
    "dtype: object\n",
    "\n",
    "Tipi di dati dopo la conversione:\n",
    "A     string\n",
    "B    float64\n",
    "C       bool\n",
    "D     string\n",
    "dtype: object\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - Usa `.convert_dtypes()` quando hai un DataFrame con tipi di dati non ottimizzati o quando vuoi migliorare l'efficienza della memoria senza dover convertire manualmente ciascuna colonna. √à utile soprattutto per ottimizzare la memoria, ridurre l'uso della RAM e migliorare la velocit√† di elaborazione.\n",
    "    - √à particolarmente utile quando i dati sono caricati da file CSV, Excel o da altre fonti dove i tipi di dati non sono sempre ideali.\n",
    "- **Vantaggi**:\n",
    "    - **Ottimizzazione della memoria**: La conversione ai tipi pi√π appropriati riduce l'uso della memoria, migliorando le prestazioni, specialmente su grandi dataset.\n",
    "    - **Automazione**: Non √® necessario eseguire manualmente la conversione di ciascuna colonna. Pandas si occupa automaticamente di applicare i tipi di dati migliori.\n",
    "    - **Compatibilit√† con nuovi tipi di dati**: Con l'introduzione di tipi come `string` e `Int64`, `.convert_dtypes()` facilita l'adattamento ai nuovi tipi di dati Pandas.\n",
    "- **Svantaggi**:\n",
    "    - In alcuni casi, la conversione automatica potrebbe non essere completamente corretta, specialmente se ci sono colonne con dati incoerenti. √à sempre una buona pratica controllare i risultati dopo la conversione per assicurarsi che le colonne siano convertite come desiderato.\n",
    "- **Uso**:\n",
    "    - Dopo aver caricato i dati da file esterni, puoi utilizzare `.convert_dtypes()` per garantire che le colonne abbiano i tipi pi√π adatti, riducendo il rischio di errori e ottimizzando l'elaborazione dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.clip()` ‚Äì Limita i valori al di sotto o al di sopra di una soglia\n",
    "\n",
    "Il metodo **`.clip()`** di Pandas √® utilizzato per limitare (o \"tagliare\") i valori in un DataFrame o in una Serie. Questo significa che puoi sostituire i valori che sono al di sotto o al di sopra di una certa soglia con i limiti specificati. Questo metodo √® molto utile quando hai bisogno di limitare i valori a un determinato intervallo o quando vuoi evitare outlier estremi in un dataset.\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "- **lower**:\n",
    "    - Tipo: `scalar` o `None`, opzionale\n",
    "    - Descrizione: Specifica il valore minimo consentito. Tutti i valori sotto questo valore vengono sostituiti con `lower`. Se non viene specificato, non viene applicato alcun limite inferiore.\n",
    "- **upper**:\n",
    "    - Tipo: `scalar` o `None`, opzionale\n",
    "    - Descrizione: Specifica il valore massimo consentito. Tutti i valori sopra questo valore vengono sostituiti con `upper`. Se non viene specificato, non viene applicato alcun limite superiore.\n",
    "- **axis**:\n",
    "    - Tipo: `int` o `None`, opzionale\n",
    "    - Descrizione: Specifica lungo quale asse applicare il taglio. `axis=0` per righe e `axis=1` per colonne. Se non viene specificato, il taglio viene applicato a livello di elemento.\n",
    "- **inplace**:\n",
    "    - Tipo: `bool`, opzionale\n",
    "    - Descrizione: Se `True`, modifica il DataFrame o la Serie in modo in-place (senza restituire una nuova copia). Il default √® `False`.\n",
    "\n",
    "### Funzionamento:\n",
    "\n",
    "Il metodo `.clip()` applica i limiti sui valori nel DataFrame o nella Serie. I valori che sono inferiori al limite inferiore vengono impostati sul limite inferiore, mentre i valori superiori al limite superiore vengono impostati sul limite superiore.\n",
    "\n",
    "### Esempio di utilizzo di `.clip()`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di un DataFrame con valori di esempio\n",
    "data = {'A': [1, 5, 10, 15, 20],\n",
    "        'B': [3, 12, 18, 25, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Limiti inferiori e superiori\n",
    "df_clipped = df.clip(lower=5, upper=20)\n",
    "\n",
    "print(df_clipped)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    A   B\n",
    "0   5   5\n",
    "1   5  12\n",
    "2  10  18\n",
    "3  15  20\n",
    "4  20  20\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- I valori inferiori a 5 nella colonna 'A' (1) sono stati sostituiti con 5.\n",
    "- I valori superiori a 20 nella colonna 'A' (20) sono rimasti invariati.\n",
    "- I valori superiori a 20 nella colonna 'B' (25, 30) sono stati sostituiti con 20.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - Usa `.clip()` quando vuoi limitare i valori di un dataset all'interno di un intervallo specificato. Questo √® utile per evitare outlier o valori estremi che potrebbero influenzare negativamente l'analisi dei dati, come nelle applicazioni di machine learning o nella pulizia dei dati.\n",
    "    - √à utile anche in contesti in cui vuoi forzare un intervallo fisico, come ad esempio la limitazione di temperature, velocit√†, o altre misurazioni a valori realistici o pratici.\n",
    "- **Vantaggi**:\n",
    "    - **Semplicit√†**: √à molto semplice da usare, basta fornire un valore per il limite inferiore e/o superiore.\n",
    "    - **Controllo sui dati**: Ti consente di proteggere il tuo dataset da outlier estremi che potrebbero danneggiare la qualit√† del modello o dell'analisi.\n",
    "- **Svantaggi**:\n",
    "    - **Perdita di informazioni**: Limita i dati, il che significa che i valori originali estremi vengono sostituiti, il che potrebbe non essere sempre desiderabile.\n",
    "    - **Non applicabile a tutti i casi**: In alcuni contesti, la sostituzione di valori estremi potrebbe non avere senso o potrebbe distorcere i dati.\n",
    "- **Uso**:\n",
    "    - Usa `.clip()` prima di applicare modelli statistici o di machine learning quando vuoi rimuovere gli outlier.\n",
    "    - √à anche utile per evitare errori o anomalie nei dati quando si lavora con sensori o misurazioni che potrebbero produrre valori fuori scala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.abs()` ‚Äì Calcola il valore assoluto delle colonne numeriche\n",
    "\n",
    "Il metodo **`.abs()`** di Pandas viene utilizzato per calcolare il valore assoluto di ogni elemento in un DataFrame o in una Serie. In altre parole, converte tutti i numeri negativi in positivi, mantenendo invariati i numeri gi√† positivi o uguali a zero. √à utile quando si desidera analizzare le magnitudini di valori numerici indipendentemente dal segno.\n",
    "\n",
    "### Funzionamento:\n",
    "\n",
    "Il metodo `.abs()` √® applicato a tutte le colonne numeriche di un DataFrame o a una Serie, restituendo il valore assoluto di ciascun elemento.\n",
    "\n",
    "### Esempi di utilizzo di `.abs()`:\n",
    "\n",
    "### Esempio 1: Applicazione su una Serie\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di una Serie con valori positivi e negativi\n",
    "s = pd.Series([-10, -5, 3, 8, -2])\n",
    "\n",
    "# Calcolare il valore assoluto\n",
    "s_abs = s.abs()\n",
    "\n",
    "print(s_abs)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    10\n",
    "1     5\n",
    "2     3\n",
    "3     8\n",
    "4     2\n",
    "dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, tutti i valori negativi sono stati convertiti nei loro valori positivi.\n",
    "\n",
    "### Esempio 2: Applicazione su un DataFrame\n",
    "\n",
    "```python\n",
    "# Creazione di un DataFrame con valori positivi e negativi\n",
    "df = pd.DataFrame({\n",
    "    'A': [-1, 2, -3],\n",
    "    'B': [4, -5, 6]\n",
    "})\n",
    "\n",
    "# Calcolare il valore assoluto di tutte le colonne\n",
    "df_abs = df.abs()\n",
    "\n",
    "print(df_abs)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0  1  4\n",
    "1  2  5\n",
    "2  3  6\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, tutte le celle del DataFrame sono state convertite nei loro valori assoluti.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - Usa `.abs()` quando hai bisogno di lavorare con le magnitudini dei valori numerici e non ti interessa la direzione (positiva o negativa). √à utile, ad esempio, quando si analizzano distanze, velocit√†, errori assoluti o in altre situazioni dove il segno non √® importante.\n",
    "    - √à anche molto utile quando si vogliono rimuovere gli effetti dei numeri negativi o quando si preparano i dati per modelli che non gestiscono bene i valori negativi.\n",
    "- **Vantaggi**:\n",
    "    - **Semplicit√†**: √à un metodo semplice e diretto per ottenere il valore assoluto di una colonna numerica.\n",
    "    - **Efficiente**: Funziona velocemente su grandi dataset numerici e consente di manipolare i dati in modo pulito senza dover iterare manualmente.\n",
    "- **Svantaggi**:\n",
    "    - **Perdita di informazione**: Il valore assoluto rimuove il segno negativo, quindi se il segno ha un'importanza semantica, questa operazione potrebbe non essere adatta.\n",
    "    - **Non adatto a tutti i dati**: Non √® utile per dati categoriali o dati che richiedono il mantenimento del segno.\n",
    "- **Uso**:\n",
    "    - √à molto comune nelle applicazioni di machine learning, dove spesso si desidera analizzare solo la magnitudine di un valore (ad esempio, in problemi di regressione dove si utilizzano errori assoluti per valutare le prestazioni).\n",
    "    - √à anche utile nelle statistiche quando si analizzano deviazioni da un valore medio o quando si calcolano errori senza preoccuparsi della direzione dell'errore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.round(decimals)` ‚Äì Arrotonda i valori a un determinato numero di decimali\n",
    "\n",
    "Il metodo **`.round()`** di Pandas viene utilizzato per arrotondare i valori numerici di un DataFrame o di una Serie a un determinato numero di decimali. Questo metodo √® utile quando si desidera una maggiore precisione o si desidera uniformare i dati numerici a un formato specifico, ad esempio per la visualizzazione o il calcolo di statistiche.\n",
    "\n",
    "### Parametro principale:\n",
    "\n",
    "- **decimals**:\n",
    "    - Tipo: `int` o `dict`, opzionale\n",
    "    - Descrizione: Il numero di decimali a cui arrotondare i valori. Se √® un numero intero, viene applicato a tutte le colonne o righe del DataFrame o Serie. Se √® un dizionario, pu√≤ essere specificato un numero di decimali diverso per ogni colonna o riga.\n",
    "\n",
    "### Funzionamento:\n",
    "\n",
    "- Quando si applica `.round()`, Pandas arrotonda ogni valore numerico in base al numero di decimali specificato. Se il parametro `decimals` √® un intero, l'arrotondamento verr√† applicato uniformemente a tutte le colonne o righe numeriche. Se si utilizza un dizionario, √® possibile definire il numero di decimali per ogni singola colonna.\n",
    "\n",
    "### Esempi di utilizzo di `.round()`:\n",
    "\n",
    "### Esempio 1: Arrotondare a un determinato numero di decimali in una Serie\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione di una Serie con valori decimali\n",
    "s = pd.Series([3.14159, 2.71828, 1.61803, 0.57721])\n",
    "\n",
    "# Arrotondare i valori a 2 decimali\n",
    "s_rounded = s.round(2)\n",
    "\n",
    "print(s_rounded)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    3.14\n",
    "1    2.72\n",
    "2    1.62\n",
    "3    0.58\n",
    "dtype: float64\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, tutti i valori nella Serie sono stati arrotondati a due decimali.\n",
    "\n",
    "### Esempio 2: Arrotondare a numeri di decimali diversi per ciascuna colonna in un DataFrame\n",
    "\n",
    "```python\n",
    "# Creazione di un DataFrame con valori decimali\n",
    "df = pd.DataFrame({\n",
    "    'A': [3.14159, 2.71828, 1.61803],\n",
    "    'B': [0.57721, 1.23456, 7.89101]\n",
    "})\n",
    "\n",
    "# Arrotondare la colonna 'A' a 2 decimali e la colonna 'B' a 3 decimali\n",
    "df_rounded = df.round({'A': 2, 'B': 3})\n",
    "\n",
    "print(df_rounded)\n",
    "\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A      B\n",
    "0  3.14  0.577\n",
    "1  2.72  1.235\n",
    "2  1.62  7.891\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- La colonna 'A' √® stata arrotondata a 2 decimali.\n",
    "- La colonna 'B' √® stata arrotondata a 3 decimali.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - Usa `.round()` quando desideri arrotondare i valori numerici per una migliore visualizzazione, per la normalizzazione dei dati o quando desideri evitare lunghe sequenze di decimali che non aggiungono valore pratico.\n",
    "    - √à utile quando si stanno preparando i dati per report, grafici o altre applicazioni in cui la precisione oltre un certo numero di decimali non √® necessaria.\n",
    "- **Vantaggi**:\n",
    "    - **Semplicit√†**: √à un metodo semplice e veloce per arrotondare i valori numerici in un DataFrame o in una Serie.\n",
    "    - **Controllo preciso**: Puoi arrotondare singole colonne a numeri di decimali diversi usando un dizionario, offrendo flessibilit√†.\n",
    "    - **Ottimizzazione della visualizzazione**: Ridurre il numero di decimali √® utile per migliorare la leggibilit√† dei dati nelle visualizzazioni.\n",
    "- **Svantaggi**:\n",
    "    - **Perdita di precisione**: L'arrotondamento potrebbe ridurre la precisione dei dati, il che potrebbe essere un problema per calcoli che richiedono alta precisione.\n",
    "    - **Non utile per dati categorici**: Non √® applicabile a dati non numerici, come stringhe o categorie.\n",
    "- **Uso**:\n",
    "    - √à molto utile in contesti finanziari o di reporting, dove l'arrotondamento a due o tre decimali √® standard.\n",
    "    - Utilizza `.round()` anche quando lavorano con modelli di machine learning per migliorare la comprensione dei risultati, o per rendere pi√π compatti i dati in output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.astype()` ‚Äì Cambia il tipo di dati delle colonne\n",
    "\n",
    "Il metodo `.astype()` in pandas viene utilizzato per cambiare il tipo di dati di una colonna o di un'intera struttura DataFrame o Serie. √à particolarmente utile quando si ha bisogno di convergere i dati in un tipo specifico per l'analisi o per applicare operazioni che richiedono determinati tipi di dati.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.astype(dtype, copy=True, errors='raise')\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`dtype`** (obbligatorio):\n",
    "    \n",
    "    Il tipo di dati a cui vuoi convertire la colonna. Pu√≤ essere un singolo tipo (ad esempio, `int`, `float`, `str`, `datetime64`, ecc.) oppure un dizionario che associa i nomi delle colonne ai tipi di dati specifici.\n",
    "    \n",
    "2. **`copy`** (opzionale, default `True`):\n",
    "    \n",
    "    Se impostato su `True`, restituisce una nuova copia del DataFrame o della Serie con i dati convertiti. Se impostato su `False`, potrebbe restituire una vista dei dati (modificando i dati originali).\n",
    "    \n",
    "3. **`errors`** (opzionale, default `'raise'`):\n",
    "    \n",
    "    Determina il comportamento in caso di errore. Le opzioni sono:\n",
    "    \n",
    "    - `'raise'`: genera un errore se la conversione non √® possibile.\n",
    "    - `'ignore'`: ignora eventuali errori e restituisce l'oggetto originale se non √® possibile effettuare la conversione.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Conversione di una colonna a un tipo numerico (ad esempio, da stringa a intero)**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creiamo un DataFrame di esempio\n",
    "df = pd.DataFrame({'A': ['1', '2', '3', '4']})\n",
    "\n",
    "# Convertiamo la colonna 'A' da stringa a intero\n",
    "df['A'] = df['A'].astype(int)\n",
    "\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A\n",
    "0  1\n",
    "1  2\n",
    "2  3\n",
    "3  4\n",
    "\n",
    "```\n",
    "\n",
    "1. **Conversione di un'intera colonna in float**:\n",
    "\n",
    "```python\n",
    "df['A'] = df['A'].astype(float)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     A\n",
    "0  1.0\n",
    "1  2.0\n",
    "2  3.0\n",
    "3  4.0\n",
    "\n",
    "```\n",
    "\n",
    "1. **Uso di un dizionario per convertire pi√π colonne**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': ['1', '2', '3'], 'B': ['4.0', '5.1', '6.2']})\n",
    "\n",
    "# Convertiamo 'A' in int e 'B' in float\n",
    "df = df.astype({'A': 'int', 'B': 'float'})\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A    B\n",
    "0  1  4.0\n",
    "1  2  5.1\n",
    "2  3  6.2\n",
    "\n",
    "```\n",
    "\n",
    "1. **Gestione degli errori (se si tenta di convertire in un tipo non valido)**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': ['1', 'abc', '3']})\n",
    "\n",
    "# Tentiamo di convertire la colonna 'A' in interi, ma c'√® un valore non numerico ('abc')\n",
    "try:\n",
    "    df['A'] = df['A'].astype(int)\n",
    "except ValueError as e:\n",
    "    print(f\"Errore: {e}\")\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Errore: invalid literal for int() with base 10: 'abc'\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**: `.astype()` √® utile quando √® necessario convertire i dati in un tipo specifico prima di eseguire operazioni, come calcoli, aggregazioni, o quando i dati vengono letti da file in formati non ideali (ad esempio, numeri letti come stringhe). √à anche utile quando si lavora con tipi di dati complessi, come la conversione tra tipi numerici e di data/ora.\n",
    "- **Performance**: Se il dataset √® molto grande, la conversione di tipi di dati pu√≤ essere costosa in termini di tempo di esecuzione e memoria, quindi √® consigliabile farlo in modo mirato, solo per le colonne che ne necessitano davvero.\n",
    "- **Errori comuni**: Fai attenzione agli errori di conversione, soprattutto quando cerchi di convertire stringhe in numeri o date. Puoi usare il parametro `errors='ignore'` per evitare che vengano sollevati errori, ma questo potrebbe non essere sempre la soluzione migliore.\n",
    "\n",
    "In generale, √® uno strumento potente per la gestione dei dati, che ti consente di manipolare e preparare i dati per analisi pi√π avanzate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.apply()` ‚Äì Applica una funzione lungo un asse (righe/colonne)\n",
    "\n",
    "Il metodo `.apply()` in pandas √® uno strumento versatile che permette di applicare una funzione a livello di DataFrame o Serie, lungo un determinato asse (righe o colonne). √à molto utile per eseguire operazioni pi√π complesse rispetto a quelle che si possono fare con i metodi base come `sum()`, `mean()`, ecc.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwds)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`func`** (obbligatorio):\n",
    "    \n",
    "    La funzione da applicare. Pu√≤ essere una funzione predefinita, una funzione lambda o una funzione personalizzata.\n",
    "    \n",
    "2. **`axis`** (opzionale, default `0`):\n",
    "    \n",
    "    Specifica lungo quale asse applicare la funzione:\n",
    "    \n",
    "    - `axis=0`: la funzione viene applicata **lungo le colonne** (default).\n",
    "    - `axis=1`: la funzione viene applicata **lungo le righe**.\n",
    "3. **`raw`** (opzionale, default `False`):\n",
    "    \n",
    "    Se impostato su `True`, la funzione viene applicata direttamente ai dati grezzi (come array NumPy) piuttosto che ai singoli valori delle righe/colonne del DataFrame. Questo pu√≤ migliorare le prestazioni, ma la funzione applicata deve essere in grado di gestire array NumPy.\n",
    "    \n",
    "4. **`result_type`** (opzionale, default `None`):\n",
    "    \n",
    "    Pu√≤ essere usato per definire come dovrebbe essere restituito il risultato:\n",
    "    \n",
    "    - `None`: restituir√† un oggetto della stessa forma dell'input.\n",
    "    - `'expand'`: espande il risultato (utile per restituire pi√π colonne o righe).\n",
    "    - `'reduce'`: riduce il risultato a una Serie (utile per aggregazioni).\n",
    "    - `'broadcast'`: il risultato sar√† un oggetto che mantiene la forma dell'originale.\n",
    "5. **`args`** (opzionale):\n",
    "    \n",
    "    Una tupla di argomenti da passare alla funzione.\n",
    "    \n",
    "6. **`kwds`** (opzionale):\n",
    "    \n",
    "    Argomenti aggiuntivi da passare alla funzione.\n",
    "    \n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Applicare una funzione di somma alle colonne**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Somma di ogni colonna\n",
    "result = df.apply(sum, axis=0)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A     6\n",
    "B    15\n",
    "C    24\n",
    "dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "1. **Applicare una funzione lungo le righe**:\n",
    "\n",
    "```python\n",
    "# Somma di ogni riga\n",
    "result = df.apply(sum, axis=1)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    12\n",
    "1    15\n",
    "2    18\n",
    "dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "1. **Applicare una funzione personalizzata (per esempio, una funzione che calcola la somma e la moltiplicazione di due colonne)**:\n",
    "\n",
    "```python\n",
    "# Funzione personalizzata che somma e moltiplica 'A' e 'B'\n",
    "def custom_func(row):\n",
    "    return row['A'] + row['B'] * 2\n",
    "\n",
    "# Applicare la funzione lungo le righe\n",
    "result = df.apply(custom_func, axis=1)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     9\n",
    "1    12\n",
    "2    15\n",
    "dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "1. **Uso di `lambda` per applicare una funzione**:\n",
    "\n",
    "```python\n",
    "# Applicare una funzione lambda per calcolare il quadrato dei valori di ogni colonna\n",
    "result = df.apply(lambda x: x**2)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A   B   C\n",
    "0  1  16  49\n",
    "1  4  25  64\n",
    "2  9  36  81\n",
    "\n",
    "```\n",
    "\n",
    "1. **Uso di `raw=True` per performance migliori**:\n",
    "\n",
    "```python\n",
    "# Applicare una funzione in modo grezzo (pi√π veloce)\n",
    "result = df.apply(sum, axis=0, raw=True)\n",
    "print(result)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A     6\n",
    "B    15\n",
    "C    24\n",
    "dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.apply()` √® molto utile quando hai bisogno di eseguire operazioni complesse che non sono facilmente realizzabili con le funzioni predefinite di pandas. Pu√≤ essere usato per manipolare i dati a livello di colonna o riga, applicare funzioni personalizzate o anche aggregare valori in modi non standard.\n",
    "    \n",
    "- **Performance**:\n",
    "    \n",
    "    Sebbene `.apply()` sia molto flessibile, non √® sempre il metodo pi√π veloce, specialmente su DataFrame molto grandi, poich√© la funzione viene applicata riga per riga o colonna per colonna. Se la tua funzione pu√≤ essere vettorizzata, √® meglio usare operazioni dirette su pandas o NumPy, che sono pi√π veloci. L'uso del parametro `raw=True` pu√≤ migliorare le performance in alcuni casi, poich√© evita il passaggio attraverso la struttura di pandas.\n",
    "    \n",
    "- **Alternative**:\n",
    "    \n",
    "    Per operazioni semplici come somme, medie, aggregazioni, o manipolazioni elementari, le funzioni predefinite come `sum()`, `mean()`, `applymap()` o `agg()` sono generalmente pi√π rapide. `.apply()` √® pi√π adatto a situazioni in cui √® necessaria una logica complessa che coinvolge pi√π colonne o righe.\n",
    "    \n",
    "\n",
    "In generale, `.apply()` √® uno degli strumenti pi√π potenti di pandas per applicare funzioni personalizzate sui tuoi dati, ma va utilizzato con attenzione per evitare impatti sulle performance quando lavori con dataset grandi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.applymap()` ‚Äì Applica una funzione elemento per elemento\n",
    "\n",
    "Il metodo `.applymap()` in pandas √® simile a `.apply()`, ma viene utilizzato esclusivamente per applicare una funzione **a livello di singolo elemento** in un DataFrame. √à utile quando vuoi eseguire operazioni che devono essere applicate a ciascun valore individuale del DataFrame, come trasformazioni o formattazioni specifiche.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.applymap(func)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`func`** (obbligatorio):\n",
    "La funzione da applicare, che deve prendere un singolo valore e restituire un valore trasformato. La funzione verr√† applicata a ogni singolo elemento nel DataFrame.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Applicare una funzione per elevare al quadrato ogni elemento del DataFrame**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Applicare una funzione per elevare al quadrato ogni elemento\n",
    "df_squared = df.applymap(lambda x: x**2)\n",
    "print(df_squared)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A   B   C\n",
    "0  1  16  49\n",
    "1  4  25  64\n",
    "2  9  36  81\n",
    "\n",
    "```\n",
    "\n",
    "1. **Applicare una funzione di formattazione (ad esempio, per aggiungere simboli monetari)**:\n",
    "\n",
    "```python\n",
    "# Applicare una funzione per formattare i numeri come valuta\n",
    "df_formatted = df.applymap(lambda x: f\"${x:.2f}\")\n",
    "print(df_formatted)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      A     B     C\n",
    "0  $1.00  $4.00  $7.00\n",
    "1  $2.00  $5.00  $8.00\n",
    "2  $3.00  $6.00  $9.00\n",
    "\n",
    "```\n",
    "\n",
    "1. **Applicare una funzione che gestisce condizioni sui valori**:\n",
    "\n",
    "```python\n",
    "# Applicare una funzione che converte i valori pari in 'Even' e quelli dispari in 'Odd'\n",
    "df_labels = df.applymap(lambda x: 'Even' if x % 2 == 0 else 'Odd')\n",
    "print(df_labels)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "0  Odd  Even  Odd\n",
    "1  Even  Odd  Even\n",
    "2  Odd  Even  Odd\n",
    "\n",
    "```\n",
    "\n",
    "1. **Esegui una funzione di tipo \"round\" su un DataFrame con valori decimali**:\n",
    "\n",
    "```python\n",
    "df_float = pd.DataFrame({\n",
    "    'A': [1.1234, 2.3456, 3.5678],\n",
    "    'B': [4.7890, 5.6789, 6.9876]\n",
    "})\n",
    "\n",
    "# Arrotondare i valori a 2 decimali\n",
    "df_rounded = df_float.applymap(lambda x: round(x, 2))\n",
    "print(df_rounded)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      A     B\n",
    "0  1.12  4.79\n",
    "1  2.35  5.68\n",
    "2  3.57  6.99\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.applymap()` √® perfetto quando hai bisogno di applicare una funzione **a livello di elemento** su un intero DataFrame. √à ideale per trasformazioni che coinvolgono ogni singolo valore, come formattazioni, arrotondamenti, operazioni matematiche o categorizzazioni basate sui valori.\n",
    "    \n",
    "- **Performance**:\n",
    "    \n",
    "    Anche se `.applymap()` √® un metodo potente, √® importante sapere che √® **meno efficiente** rispetto ad altre operazioni di pandas o NumPy quando si tratta di grandi dataset. Questo perch√© la funzione viene applicata **singolarmente a ogni elemento** del DataFrame, il che pu√≤ essere lento rispetto a operazioni vettorializzate. Se la tua funzione √® semplice e pu√≤ essere applicata in modo vettoriale, √® meglio usare le operazioni pandas native o NumPy, che sono pi√π performanti.\n",
    "    \n",
    "- **Alternative**:\n",
    "    \n",
    "    Se la tua funzione pu√≤ essere applicata a intere righe o colonne, √® preferibile usare `.apply()`. Se lavori con un singolo valore o una struttura che non √® un DataFrame, considera l'uso di `apply()` su una Serie o funzioni NumPy per ottenere performance migliori.\n",
    "    \n",
    "\n",
    "In generale, `.applymap()` √® molto utile per operazioni personalizzate sui dati di un DataFrame, ma va utilizzato con attenzione, specialmente su dataset di grandi dimensioni, a causa delle sue implicazioni sulle performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.map()` ‚Äì Associa valori da una colonna a un'altra\n",
    "\n",
    "Il metodo `.map()` in pandas √® utilizzato per **mappare** o **sostituire** i valori in una Serie (una singola colonna) con nuovi valori provenienti da un altro dizionario, una Serie o una funzione. √à molto utile quando si vuole sostituire o mappare valori specifici a partire da una colonna di dati, senza dover ricorrere a operazioni pi√π complesse.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "Series.map(arg, na_action=None)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`arg`** (obbligatorio):\n",
    "Questo pu√≤ essere:\n",
    "    - Un **dizionario** che mappa i vecchi valori ai nuovi valori.\n",
    "    - Una **Serie** che ha lo stesso indice della Serie originale (i valori saranno sostituiti da quelli corrispondenti nella Serie).\n",
    "    - Una **funzione** che viene applicata a ciascun valore nella Serie.\n",
    "2. **`na_action`** (opzionale):\n",
    "Se impostato su `ignore`, i valori `NaN` non saranno modificati. Se non √® specificato (impostato su `None`), i valori `NaN` verranno sostituiti con `NaN`.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Mappare i valori tramite un dizionario**:\n",
    "Supponiamo di avere una Serie di categorie e vogliamo sostituirle con nuovi nomi pi√π descrittivi.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creare una Serie di esempio\n",
    "categories = pd.Series([0, 1, 2, 1, 0, 2, 1])\n",
    "\n",
    "# Mappare i valori usando un dizionario\n",
    "category_map = {0: 'A', 1: 'B', 2: 'C'}\n",
    "mapped_categories = categories.map(category_map)\n",
    "print(mapped_categories)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    A\n",
    "1    B\n",
    "2    C\n",
    "3    B\n",
    "4    A\n",
    "5    C\n",
    "6    B\n",
    "dtype: object\n",
    "\n",
    "```\n",
    "\n",
    "1. **Mappare i valori usando una funzione**:\n",
    "Puoi usare una funzione per trasformare i valori della Serie. Ad esempio, se vogliamo raddoppiare ogni valore.\n",
    "\n",
    "```python\n",
    "# Funzione che raddoppia un numero\n",
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "# Applicare la funzione alla Serie\n",
    "numbers = pd.Series([1, 2, 3, 4, 5])\n",
    "doubled_numbers = numbers.map(double)\n",
    "print(doubled_numbers)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     2\n",
    "1     4\n",
    "2     6\n",
    "3     8\n",
    "4    10\n",
    "dtype: int64\n",
    "\n",
    "```\n",
    "\n",
    "1. **Mappare valori mancanti (NaN)**:\n",
    "Se la Serie contiene valori mancanti (`NaN`), questi possono essere trattati separatamente o lasciati invariati.\n",
    "\n",
    "```python\n",
    "# Serie con valori NaN\n",
    "data = pd.Series([1, 2, 3, None, 5])\n",
    "\n",
    "# Mappare i valori, ma lasciare invariati i NaN\n",
    "mapped_data = data.map(lambda x: x * 10 if x is not None else x)\n",
    "print(mapped_data)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    10.0\n",
    "1    20.0\n",
    "2    30.0\n",
    "3     NaN\n",
    "4    50.0\n",
    "dtype: float64\n",
    "\n",
    "```\n",
    "\n",
    "1. **Mappare tramite una Serie con lo stesso indice**:\n",
    "Se hai un'altra Serie con lo stesso indice, puoi usarla per mappare i valori.\n",
    "\n",
    "```python\n",
    "# Serie di origine\n",
    "source = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Serie di mappatura\n",
    "mapping = pd.Series({1: 'A', 2: 'B', 3: 'C', 4: 'D', 5: 'E'})\n",
    "\n",
    "# Mappare i valori usando la Serie\n",
    "mapped_values = source.map(mapping)\n",
    "print(mapped_values)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    A\n",
    "1    B\n",
    "2    C\n",
    "3    D\n",
    "4    E\n",
    "dtype: object\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.map()` √® molto utile quando hai una Serie e desideri sostituire o trasformare i valori in modo semplice ed efficiente. √à ideale quando hai bisogno di mappare valori da un set predefinito (ad esempio, un dizionario di traduzioni o categorie), applicare una trasformazione su ogni elemento o fare il mapping tra due Serie con lo stesso indice.\n",
    "    \n",
    "- **Performance**:\n",
    "    \n",
    "    Il metodo `.map()` √® generalmente veloce ed efficiente, soprattutto quando applicato a una Serie relativamente piccola. Tuttavia, su dataset molto grandi, l'uso di funzioni personalizzate o l'accesso a un altro oggetto (come un dizionario o una Serie) potrebbe rallentare l'operazione. Se si tratta di un'operazione semplice e vettorizzata (ad esempio, applicare una funzione semplice), √® meglio considerare alternative come `.apply()`.\n",
    "    \n",
    "- **Alternative**:\n",
    "    \n",
    "    Se stai lavorando con un DataFrame e hai bisogno di mappare valori in pi√π colonne o manipolare dati su pi√π dimensioni (righe e colonne), potresti voler utilizzare `.apply()` o `.applymap()`. Inoltre, per operazioni di sostituzione massiva, il metodo `.replace()` pu√≤ essere un'alternativa valida, soprattutto se hai bisogno di sostituire pi√π valori contemporaneamente.\n",
    "    \n",
    "\n",
    "In generale, `.map()` √® uno strumento potente per applicare mappature semplici e trasformazioni a una Serie, con un uso versatile in vari contesti di manipolazione dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.sort_values()` ‚Äì Ordina il DataFrame in base alle colonne\n",
    "\n",
    "Il metodo `.sort_values()` in pandas √® utilizzato per ordinare un DataFrame in base ai valori di una o pi√π colonne. Questo √® utile quando vuoi riorganizzare i dati in un ordine crescente o decrescente in base a determinati criteri. L'ordinamento √® eseguito su una o pi√π colonne, ed √® possibile specificare se l'ordinamento debba essere crescente o decrescente.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, na_position='last', ignore_index=False)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`by`** (obbligatorio):\n",
    "    \n",
    "    Una lista di colonne o una singola colonna in base alla quale ordinare. Se si vogliono ordinare i dati in base a pi√π colonne, si pu√≤ passare una lista di colonne.\n",
    "    \n",
    "2. **`axis`** (opzionale):\n",
    "    \n",
    "    Impostato su `0` per ordinare lungo le righe (default), e su `1` per ordinare lungo le colonne. Nella maggior parte dei casi, lavorerai con `axis=0` per ordinare le righe.\n",
    "    \n",
    "3. **`ascending`** (opzionale):\n",
    "    \n",
    "    Un valore booleano o una lista di valori booleani che specificano se ordinare in ordine crescente (`True`) o decrescente (`False`). Pu√≤ essere una lista di lunghezza uguale a `by` se si stanno ordinando pi√π colonne. Il valore di default √® `True`.\n",
    "    \n",
    "4. **`inplace`** (opzionale):\n",
    "    \n",
    "    Se impostato su `True`, il DataFrame verr√† modificato in loco, senza restituire un nuovo DataFrame ordinato. Se impostato su `False` (default), il metodo restituir√† un nuovo DataFrame ordinato.\n",
    "    \n",
    "5. **`na_position`** (opzionale):\n",
    "    \n",
    "    Specifica dove mettere i valori `NaN` (\"first\" per metterli all'inizio, \"last\" per metterli alla fine). Il valore di default √® `'last'`.\n",
    "    \n",
    "6. **`ignore_index`** (opzionale):\n",
    "    \n",
    "    Se impostato su `True`, i vecchi indici verranno ignorati e verr√† assegnato un nuovo indice numerico al DataFrame ordinato.\n",
    "    \n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Ordinare un DataFrame in base a una singola colonna (in ordine crescente)**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creare un DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Et√†': [25, 30, 35, 20],\n",
    "    'Salario': [50000, 60000, 55000, 45000]\n",
    "})\n",
    "\n",
    "# Ordinare in base alla colonna 'Et√†' in ordine crescente\n",
    "df_sorted = df.sort_values(by='Et√†')\n",
    "print(df_sorted)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "3    David   20    45000\n",
    "0    Alice   25    50000\n",
    "1      Bob   30    60000\n",
    "2  Charlie   35    55000\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare in ordine decrescente**:\n",
    "\n",
    "```python\n",
    "# Ordinare in base alla colonna 'Salario' in ordine decrescente\n",
    "df_sorted_desc = df.sort_values(by='Salario', ascending=False)\n",
    "print(df_sorted_desc)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "1      Bob   30    60000\n",
    "2  Charlie   35    55000\n",
    "0    Alice   25    50000\n",
    "3    David   20    45000\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare in base a pi√π colonne**:\n",
    "\n",
    "```python\n",
    "# Ordinare in base a pi√π colonne ('Et√†' e 'Salario')\n",
    "df_sorted_multi = df.sort_values(by=['Et√†', 'Salario'], ascending=[True, False])\n",
    "print(df_sorted_multi)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "3    David   20    45000\n",
    "0    Alice   25    50000\n",
    "1      Bob   30    60000\n",
    "2  Charlie   35    55000\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare mantenendo l'indice originale o resettandolo**:\n",
    "\n",
    "```python\n",
    "# Ordinare e ignorare l'indice originale\n",
    "df_sorted_ignore_index = df.sort_values(by='Et√†', ignore_index=True)\n",
    "print(df_sorted_ignore_index)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "0    David   20    45000\n",
    "1    Alice   25    50000\n",
    "2      Bob   30    60000\n",
    "3  Charlie   35    55000\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare con valori `NaN`**:\n",
    "\n",
    "```python\n",
    "# Creare un DataFrame con valori NaN\n",
    "df_with_nan = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Et√†': [25, None, 35, 20],\n",
    "    'Salario': [50000, 60000, None, 45000]\n",
    "})\n",
    "\n",
    "# Ordinare mettendo prima i valori NaN\n",
    "df_sorted_nan_first = df_with_nan.sort_values(by='Et√†', na_position='first')\n",
    "print(df_sorted_nan_first)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "1      Bob  NaN    60000\n",
    "3    David   20    45000\n",
    "0    Alice   25    50000\n",
    "2  Charlie   35     NaN\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.sort_values()` √® utile quando desideri organizzare o riorganizzare i dati in un ordine specifico. Puoi usarlo per ordinare i dati in base a una o pi√π colonne, sia in ordine crescente che decrescente, o per visualizzare i dati in modo pi√π significativo (ad esempio, ordinando per et√†, salario o altre metriche).\n",
    "    \n",
    "- **Performance**:\n",
    "    \n",
    "    Il metodo √® generalmente efficiente, ma quando si ordina un DataFrame molto grande, le operazioni di ordinamento possono diventare costose in termini di tempo di esecuzione. Pandas utilizza algoritmi di ordinamento efficienti, ma la complessit√† computazionale pu√≤ crescere con l'aumentare delle dimensioni dei dati.\n",
    "    \n",
    "- **Alternative**:\n",
    "    \n",
    "    Se hai bisogno di ordinare solo una Serie, puoi usare `.sort_values()` direttamente sulla Serie, che √® pi√π efficiente in questo caso. Inoltre, se vuoi ordinare e mantenere intatti i dati originali, puoi utilizzare il parametro `inplace=True`, ma ricorda che ci√≤ modificher√† il DataFrame originale e non restituir√† un nuovo oggetto.\n",
    "    \n",
    "\n",
    "In generale, `.sort_values()` √® un metodo molto potente e flessibile per organizzare i dati in un DataFrame in base a uno o pi√π criteri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.sort_index()` ‚Äì Ordina il DataFrame in base all'indice\n",
    "\n",
    "Il metodo `.sort_index()` in pandas √® utilizzato per ordinare un DataFrame (o una Serie) in base ai valori degli indici, anzich√© in base ai valori di una colonna specifica. Questo metodo √® utile quando desideri riorganizzare i dati in base all'ordine degli indici, che pu√≤ essere numerico o basato su etichette.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.sort_index(axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`axis`** (opzionale):\n",
    "    \n",
    "    Impostato su `0` per ordinare lungo le righe (default), e su `1` per ordinare lungo le colonne. La maggior parte delle volte lavorerai con `axis=0` per ordinare le righe.\n",
    "    \n",
    "2. **`level`** (opzionale):\n",
    "    \n",
    "    Se l'indice √® multi-livello (MultiIndex), puoi ordinare in base a un livello specifico dell'indice. Puoi passare un intero (il livello da ordinare) o una lista di interi per ordinare su pi√π livelli.\n",
    "    \n",
    "3. **`ascending`** (opzionale):\n",
    "    \n",
    "    Un valore booleano o una lista di valori booleani che specificano se l'ordinamento deve essere crescente (`True`) o decrescente (`False`). Il valore di default √® `True`.\n",
    "    \n",
    "4. **`inplace`** (opzionale):\n",
    "    \n",
    "    Se impostato su `True`, il DataFrame verr√† ordinato in loco, senza restituire un nuovo DataFrame ordinato. Se impostato su `False` (default), il metodo restituir√† un nuovo DataFrame ordinato.\n",
    "    \n",
    "5. **`kind`** (opzionale):\n",
    "    \n",
    "    Il tipo di algoritmo di ordinamento da utilizzare. I valori possibili sono:\n",
    "    \n",
    "    - `'quicksort'` (default)\n",
    "    - `'mergesort'`\n",
    "    - `'heapsort'`\n",
    "    - `'stable'`\n",
    "6. **`na_position`** (opzionale):\n",
    "    \n",
    "    Se ci sono valori `NaN` nell'indice, puoi specificare se desideri metterli all'inizio (`'first'`) o alla fine (`'last'`, default).\n",
    "    \n",
    "7. **`ignore_index`** (opzionale):\n",
    "    \n",
    "    Se impostato su `True`, ignora gli indici originali e assegna un nuovo indice numerico al DataFrame ordinato. Il valore predefinito √® `False`.\n",
    "    \n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Ordinare un DataFrame in base all'indice (ordinamento crescente)**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creare un DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Et√†': [25, 30, 35, 20],\n",
    "    'Salario': [50000, 60000, 55000, 45000]\n",
    "}, index=[3, 1, 4, 2])\n",
    "\n",
    "# Ordinare in base all'indice in ordine crescente\n",
    "df_sorted = df.sort_index()\n",
    "print(df_sorted)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "1      Bob   30    60000\n",
    "2    David   20    45000\n",
    "3    Alice   25    50000\n",
    "4  Charlie   35    55000\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare in ordine decrescente**:\n",
    "\n",
    "```python\n",
    "# Ordinare in base all'indice in ordine decrescente\n",
    "df_sorted_desc = df.sort_index(ascending=False)\n",
    "print(df_sorted_desc)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "4  Charlie   35    55000\n",
    "3    Alice   25    50000\n",
    "2    David   20    45000\n",
    "1      Bob   30    60000\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare un DataFrame con MultiIndex**:\n",
    "\n",
    "```python\n",
    "# Creare un DataFrame con MultiIndex\n",
    "arrays = [['A', 'A', 'B', 'B'], [1, 2, 1, 2]]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('lettera', 'numero'))\n",
    "\n",
    "df_multi = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Et√†': [25, 30, 35, 20]\n",
    "}, index=index)\n",
    "\n",
    "# Ordinare in base al primo livello dell'indice (lettura)\n",
    "df_sorted_multi = df_multi.sort_index(level='lettera')\n",
    "print(df_sorted_multi)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "               Nome  Et√†\n",
    "lettera numero\n",
    "A       1       Alice   25\n",
    "        2         Bob   30\n",
    "B       1     Charlie   35\n",
    "        2       David   20\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare l'indice con `NaN`**:\n",
    "\n",
    "```python\n",
    "# Creare un DataFrame con NaN nell'indice\n",
    "df_with_nan = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Et√†': [25, 30, 35, 20]\n",
    "}, index=[3, None, 4, 2])\n",
    "\n",
    "# Ordinare mettendo i NaN all'inizio\n",
    "df_sorted_nan_first = df_with_nan.sort_index(na_position='first')\n",
    "print(df_sorted_nan_first)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†\n",
    "NaN   NaN  NaN\n",
    "2    David   20\n",
    "3    Alice   25\n",
    "4  Charlie   35\n",
    "\n",
    "```\n",
    "\n",
    "1. **Ordinare ignorando l'indice originale**:\n",
    "\n",
    "```python\n",
    "# Ordinare e ignorare l'indice originale\n",
    "df_sorted_ignore_index = df.sort_index(ignore_index=True)\n",
    "print(df_sorted_ignore_index)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†  Salario\n",
    "0    Bob   30    60000\n",
    "1  David   20    45000\n",
    "2  Alice   25    50000\n",
    "3  Charlie   35    55000\n",
    "\n",
    "```\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.sort_index()` √® utile quando desideri riorganizzare il DataFrame in base all'ordine dell'indice. √à spesso utilizzato quando l'indice ha un significato, come quando √® un identificatore temporale, numerico o categorico, e vuoi che i dati siano ordinati secondo l'indice stesso, piuttosto che secondo i valori delle colonne.\n",
    "    \n",
    "- **Performance**:\n",
    "    \n",
    "    Come per `.sort_values()`, l'ordinamento basato sull'indice √® relativamente efficiente, ma pu√≤ diventare pi√π lento quando si lavora con DataFrame di grandi dimensioni, specialmente se si utilizza un MultiIndex.\n",
    "    \n",
    "- **MultiIndex**:\n",
    "    \n",
    "    Se lavori con un MultiIndex, `.sort_index()` pu√≤ essere utilizzato per ordinare i dati in base a uno o pi√π livelli. Questo √® utile quando vuoi controllare l'ordine su pi√π dimensioni (ad esempio, anno e mese in un DataFrame con un MultiIndex temporale).\n",
    "    \n",
    "- **Alternative**:\n",
    "    \n",
    "    Se desideri ordinare un DataFrame in base ai valori di una colonna, allora `.sort_values()` √® il metodo da utilizzare. Invece, `.sort_index()` √® il metodo specifico per l'ordinamento basato sull'indice.\n",
    "    \n",
    "\n",
    "In generale, `.sort_index()` √® molto utile per mantenere l'ordine degli indici o per ripristinare l'ordine naturale dell'indice, specialmente in contesti in cui l'indice ha una struttura significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.reset_index()` ‚Äì Reimposta l'indice del DataFrame\n",
    "\n",
    "Il metodo `.reset_index()` in pandas viene utilizzato per reimpostare l'indice di un DataFrame e, se necessario, trasformare l'indice corrente in una colonna. Questo metodo √® particolarmente utile quando hai manipolato un DataFrame (ad esempio, con operazioni di raggruppamento o ordinamento) e desideri ripristinare l'indice al suo stato originale o trasformarlo in una colonna normale.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.reset_index(level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`level`** (opzionale):\n",
    "    \n",
    "    Specifica quale livello dell'indice (nel caso di un `MultiIndex`) desideri ripristinare. Puoi fornire un singolo livello (un intero o una stringa) o una lista di livelli da ripristinare. Se non viene specificato, vengono ripristinati tutti i livelli dell'indice.\n",
    "    \n",
    "2. **`drop`** (opzionale):\n",
    "    \n",
    "    Se impostato su `True`, l'indice verr√† semplicemente rimosso senza essere trasformato in una colonna. Il valore predefinito √® `False`, il che significa che l'indice diventer√† una colonna nel DataFrame.\n",
    "    \n",
    "3. **`inplace`** (opzionale):\n",
    "    \n",
    "    Se impostato su `True`, il DataFrame originale verr√† modificato in loco, senza restituire un nuovo oggetto. Il valore predefinito √® `False`, che restituisce un nuovo DataFrame con l'indice ripristinato.\n",
    "    \n",
    "4. **`col_level`** (opzionale):\n",
    "    \n",
    "    Se hai un `MultiIndex` nelle colonne, puoi specificare a quale livello della colonna deve essere applicata l'operazione di reset.\n",
    "    \n",
    "5. **`col_fill`** (opzionale):\n",
    "    \n",
    "    Questo parametro viene utilizzato quando si resetta l'indice di un `MultiIndex` e si deve riempire eventuali vuoti nel livello delle colonne con un determinato valore.\n",
    "    \n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Reimpostare l'indice di un DataFrame (con l'indice trasformato in colonna)**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creare un DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Et√†': [25, 30, 35, 20]\n",
    "}, index=[3, 1, 4, 2])\n",
    "\n",
    "# Reimpostare l'indice\n",
    "df_reset = df.reset_index()\n",
    "print(df_reset)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   index     Nome  Et√†\n",
    "0      3    Alice   25\n",
    "1      1      Bob   30\n",
    "2      4  Charlie   35\n",
    "3      2    David   20\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, l'indice originale √® stato trasformato in una colonna chiamata `index`, mentre √® stato creato un nuovo indice numerico predefinito.\n",
    "\n",
    "1. **Reimpostare l'indice e rimuoverlo (senza trasformarlo in una colonna)**:\n",
    "\n",
    "```python\n",
    "# Reimpostare l'indice e rimuoverlo\n",
    "df_reset_drop = df.reset_index(drop=True)\n",
    "print(df_reset_drop)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Nome  Et√†\n",
    "0    Alice   25\n",
    "1      Bob   30\n",
    "2  Charlie   35\n",
    "3    David   20\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, l'indice √® stato reimpostato, ma non √® stato aggiunto come colonna. Il nuovo indice numerico √® stato creato automaticamente.\n",
    "\n",
    "1. **Reimpostare l'indice di un DataFrame con MultiIndex**:\n",
    "\n",
    "```python\n",
    "# Creare un DataFrame con MultiIndex\n",
    "arrays = [['A', 'A', 'B', 'B'], [1, 2, 1, 2]]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('lettera', 'numero'))\n",
    "\n",
    "df_multi = pd.DataFrame({\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Et√†': [25, 30, 35, 20]\n",
    "}, index=index)\n",
    "\n",
    "# Reimpostare l'indice\n",
    "df_multi_reset = df_multi.reset_index()\n",
    "print(df_multi_reset)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  lettera  numero     Nome  Et√†\n",
    "0       A       1    Alice   25\n",
    "1       A       2      Bob   30\n",
    "2       B       1  Charlie   35\n",
    "3       B       2    David   20\n",
    "\n",
    "```\n",
    "\n",
    "Nel caso di un `MultiIndex`, entrambe le dimensioni dell'indice vengono trasformate in colonne nel DataFrame.\n",
    "\n",
    "1. **Reimpostare solo uno dei livelli del MultiIndex**:\n",
    "\n",
    "```python\n",
    "# Reimpostare solo il livello 'lettera' del MultiIndex\n",
    "df_multi_reset_level = df_multi.reset_index(level='lettera')\n",
    "print(df_multi_reset_level)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  lettera     Nome  Et√†\n",
    "0       A    Alice   25\n",
    "1       A      Bob   30\n",
    "2       B  Charlie   35\n",
    "3       B    David   20\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, solo il livello `lettera` √® stato reimpostato come colonna, mentre il livello `numero` √® rimasto come indice.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.reset_index()` √® utile quando si desidera ripristinare l'indice predefinito numerico (0, 1, 2, ...) dopo aver effettuato operazioni che modificano l'indice, come il raggruppamento (`groupby()`), l'ordinamento o il filtraggio. √à anche utile quando si desidera trasformare un `MultiIndex` in colonne singole per facilitare la manipolazione dei dati.\n",
    "    \n",
    "- **Uso di `drop=True`**:\n",
    "    \n",
    "    Se non hai bisogno di conservare l'indice come colonna (ad esempio, dopo una operazione di raggruppamento), l'uso di `drop=True` √® la soluzione ideale, poich√© evita la creazione di una colonna extra.\n",
    "    \n",
    "- **MultiIndex**:\n",
    "    \n",
    "    In caso di `MultiIndex`, `.reset_index()` offre una buona flessibilit√† per lavorare con indici complessi, consentendo di scegliere quali livelli ripristinare.\n",
    "    \n",
    "- **Performance**:\n",
    "    \n",
    "    `.reset_index()` √® una operazione leggera, ma pu√≤ diventare pi√π costosa in termini di memoria e velocit√† se lavoriamo con DataFrame molto grandi o con un `MultiIndex` complesso.\n",
    "    \n",
    "\n",
    "In generale, `.reset_index()` √® uno strumento utile quando si desidera gestire l'indice del DataFrame in modo pi√π esplicito, riportandolo alla sua forma numerica standard o trasformandolo in colonne normali per facilitare ulteriori manipolazioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.pivot()` ‚Äì Ristruttura i dati in base ai valori delle colonne\n",
    "\n",
    "Il metodo `.pivot()` di pandas permette di ristrutturare un DataFrame, trasformando le righe in colonne. √à un'operazione che consente di cambiare la struttura del DataFrame, specificando una colonna per le righe, una per le colonne e una per i valori da inserire nella tabella risultante.\n",
    "\n",
    "Questa operazione √® particolarmente utile quando si desidera trasformare dati \"lunghi\" in dati \"larghi\", in modo che ogni combinazione unica di valori in una colonna diventi una colonna del DataFrame, con i corrispondenti valori nelle celle.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.pivot(index=None, columns=None, values=None)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`index`** (opzionale):\n",
    "    \n",
    "    La colonna (o le colonne) da utilizzare come indice nel DataFrame ristrutturato. Questi valori diventeranno le righe nel nuovo DataFrame.\n",
    "    \n",
    "2. **`columns`** (opzionale):\n",
    "    \n",
    "    La colonna (o le colonne) da utilizzare per creare le nuove colonne del DataFrame. Ogni valore unico in questa colonna diventer√† una colonna separata nel DataFrame risultante.\n",
    "    \n",
    "3. **`values`** (opzionale):\n",
    "    \n",
    "    La colonna i cui valori vengono utilizzati per popolare le celle del nuovo DataFrame. Se non viene specificata, verranno utilizzati tutti i valori numerici presenti nel DataFrame.\n",
    "    \n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Pivot di un DataFrame semplice**:\n",
    "Supponiamo di avere un DataFrame con informazioni sui venditori, sui prodotti e sulle vendite.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Venditore': ['Alice', 'Bob', 'Alice', 'Bob', 'Alice', 'Bob'],\n",
    "    'Prodotto': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Vendite': [100, 200, 150, 250, 200, 300]\n",
    "})\n",
    "\n",
    "# Pivot del DataFrame\n",
    "df_pivot = df.pivot(index='Venditore', columns='Prodotto', values='Vendite')\n",
    "print(df_pivot)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Prodotto     A    B    C\n",
    "Venditore\n",
    "Alice     100  150  200\n",
    "Bob       200  250  300\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, abbiamo creato un DataFrame in cui le righe sono i venditori (`Venditore`), le colonne sono i prodotti (`Prodotto`), e i valori sono le vendite (`Vendite`). Ogni cella rappresenta il totale delle vendite di un prodotto specifico per ciascun venditore.\n",
    "\n",
    "1. **Pivot con pi√π colonne come indice**:\n",
    "Se si desidera utilizzare pi√π colonne come indice, √® possibile farlo specificando una lista di colonne.\n",
    "\n",
    "```python\n",
    "# DataFrame con pi√π colonne\n",
    "df_multi = pd.DataFrame({\n",
    "    'Anno': [2021, 2021, 2022, 2022, 2023, 2023],\n",
    "    'Mese': ['Gennaio', 'Febbraio', 'Gennaio', 'Febbraio', 'Gennaio', 'Febbraio'],\n",
    "    'Venditore': ['Alice', 'Bob', 'Alice', 'Bob', 'Alice', 'Bob'],\n",
    "    'Vendite': [100, 200, 150, 250, 200, 300]\n",
    "})\n",
    "\n",
    "# Pivot con pi√π colonne come indice\n",
    "df_pivot_multi = df_multi.pivot(index=['Anno', 'Mese'], columns='Venditore', values='Vendite')\n",
    "print(df_pivot_multi)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Venditore          Alice  Bob\n",
    "Anno Mese\n",
    "2021 Gennaio        100  200\n",
    "     Febbraio       NaN  250\n",
    "2022 Gennaio        150  NaN\n",
    "     Febbraio       NaN  300\n",
    "2023 Gennaio        200  NaN\n",
    "     Febbraio       NaN  NaN\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, abbiamo usato `Anno` e `Mese` come indice, e ogni venditore diventa una colonna separata. I valori rappresentano le vendite.\n",
    "\n",
    "1. **Errore comune (duplicazione di valori)**:\n",
    "Se i dati contengono pi√π di una combinazione di valori per ogni coppia di indice e colonna, il metodo `.pivot()` solleva un errore. Ad esempio:\n",
    "\n",
    "```python\n",
    "# DataFrame con duplicati\n",
    "df_duplicato = pd.DataFrame({\n",
    "    'Anno': [2021, 2021, 2021, 2021],\n",
    "    'Prodotto': ['A', 'A', 'B', 'B'],\n",
    "    'Venditore': ['Alice', 'Bob', 'Alice', 'Bob'],\n",
    "    'Vendite': [100, 150, 200, 250]\n",
    "})\n",
    "\n",
    "# Tentativo di pivot\n",
    "try:\n",
    "    df_duplicato_pivot = df_duplicato.pivot(index='Anno', columns='Prodotto', values='Vendite')\n",
    "    print(df_duplicato_pivot)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "ValueError: Index contains duplicate entries, cannot reshape\n",
    "\n",
    "```\n",
    "\n",
    "L'errore si verifica perch√© c'√® una duplicazione nei valori per l'indice `Anno` e la colonna `Prodotto`. In questo caso, bisogna usare il metodo `.pivot_table()`, che permette di aggregare i dati duplicati.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.pivot()` √® molto utile quando hai un DataFrame con informazioni in forma lunga e desideri trasformarlo in una forma pi√π ampia, in cui le colonne rappresentano categorie specifiche (come prodotti, venditori, date, ecc.), e i valori corrispondono ai dati che desideri visualizzare. √à particolarmente utile per creare tabelle pivot simili a quelle che si trovano in Excel.\n",
    "    \n",
    "- **Limitazioni**:\n",
    "    \n",
    "    `.pivot()` non gestisce i dati duplicati. Se ci sono pi√π valori per una combinazione di indice e colonna, si verificher√† un errore. In questo caso, si dovrebbe usare `.pivot_table()`, che consente di specificare una funzione di aggregazione (ad esempio, `sum`, `mean`, ecc.) per gestire i duplicati.\n",
    "    \n",
    "- **Alternativa con `.pivot_table()`**:\n",
    "    \n",
    "    Se hai dati duplicati o vuoi applicare un'aggregazione, usa `.pivot_table()`. Ad esempio, se due venditori hanno venduto lo stesso prodotto nello stesso anno, puoi sommare le vendite o calcolare la media per quella combinazione.\n",
    "    \n",
    "\n",
    "In generale, `.pivot()` √® uno strumento potente per ristrutturare i dati e ottenere una visualizzazione pi√π chiara e organizzata delle informazioni in un formato tabellare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.rank()` ‚Äì Classifica i valori in ogni colonna\n",
    "\n",
    "Il metodo `.rank()` di pandas √® utilizzato per assegnare un \"rank\" (posizione) ai valori di una colonna o di un DataFrame. I valori vengono ordinati in ordine crescente o decrescente e a ciascun valore viene assegnato un numero che rappresenta la sua posizione relativa rispetto agli altri valori. √à particolarmente utile per determinare il posizionamento dei dati in un determinato ordine, come per esempio nelle classifiche o quando si vogliono assegnare punteggi o ordini relativi.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.rank(axis=0, method='average', numeric_only=None, ascending=True, na_option='keep', pct=False)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`axis`**:\n",
    "    - **0** (default): Classifica lungo le righe, quindi le posizioni vengono assegnate per ogni colonna.\n",
    "    - **1**: Classifica lungo le colonne, quindi le posizioni vengono assegnate per ogni riga.\n",
    "2. **`method`**:\n",
    "    - **'average'** (default): In caso di valori duplicati, assegna a tutti gli elementi duplicati il rango medio.\n",
    "    - **'min'**: Assegna a tutti i valori duplicati il rango minimo.\n",
    "    - **'max'**: Assegna a tutti i valori duplicati il rango massimo.\n",
    "    - **'first'**: Assegna ai valori duplicati il rango in base all'ordine di apparizione.\n",
    "    - **'dense'**: I ranghi sono numerati senza interruzione. Se ci sono duplicati, i ranghi successivi sono numerati consecutivamente.\n",
    "3. **`ascending`**:\n",
    "    - **True** (default): Ordina i valori in ordine crescente (il valore pi√π basso ottiene il rango 1).\n",
    "    - **False**: Ordina in ordine decrescente (il valore pi√π alto ottiene il rango 1).\n",
    "4. **`na_option`**:\n",
    "    - **'keep'** (default): Mantiene i valori `NaN` senza assegnare un rango.\n",
    "    - **'top'**: Considera i `NaN` come i valori pi√π piccoli.\n",
    "    - **'bottom'**: Considera i `NaN` come i valori pi√π alti.\n",
    "5. **`pct`**:\n",
    "    - **False** (default): Restituisce il rango assoluto.\n",
    "    - **True**: Restituisce la percentuale del rango (i ranghi sono normalizzati tra 0 e 1).\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "1. **Esempio base di `.rank()`**:\n",
    "Supponiamo di avere un DataFrame con i punteggi di alcuni studenti e vogliamo assegnare loro un rango basato sui punteggi.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Studente': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Punteggio': [85, 92, 78, 92, 88]\n",
    "})\n",
    "\n",
    "# Classifica i punteggi in ordine crescente\n",
    "df['Rango'] = df['Punteggio'].rank()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   Studente  Punteggio  Rango\n",
    "0     Alice         85    4.0\n",
    "1       Bob         92    1.5\n",
    "2   Charlie         78    5.0\n",
    "3     David         92    1.5\n",
    "4       Eva         88    3.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, Bob e David hanno ottenuto lo stesso punteggio (92), quindi entrambi ricevono lo stesso rango (1.5). I punteggi successivi sono assegnati un rango basato sul loro valore medio.\n",
    "\n",
    "1. **Classifica con metodo `dense`**:\n",
    "Utilizzando il metodo `dense`, i ranghi non saltano quando ci sono valori duplicati.\n",
    "\n",
    "```python\n",
    "df['Rango_dens'] = df['Punteggio'].rank(method='dense')\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   Studente  Punteggio  Rango  Rango_dens\n",
    "0     Alice         85    4.0          4.0\n",
    "1       Bob         92    1.5          1.0\n",
    "2   Charlie         78    5.0          5.0\n",
    "3     David         92    1.5          2.0\n",
    "4       Eva         88    3.0          3.0\n",
    "\n",
    "```\n",
    "\n",
    "Nel metodo `dense`, i ranghi non saltano (ad esempio, dopo il rango 1, il rango successivo √® 2, anche se ci sono duplicati).\n",
    "\n",
    "1. **Classifica in ordine decrescente**:\n",
    "Se si vuole ordinare in modo decrescente (il punteggio pi√π alto ottiene il rango 1), si pu√≤ impostare `ascending=False`.\n",
    "\n",
    "```python\n",
    "df['Rango_decrescente'] = df['Punteggio'].rank(ascending=False)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   Studente  Punteggio  Rango  Rango_dens  Rango_decrescente\n",
    "0     Alice         85    4.0          4.0                4.0\n",
    "1       Bob         92    1.5          1.0                2.5\n",
    "2   Charlie         78    5.0          5.0                5.0\n",
    "3     David         92    1.5          2.0                2.5\n",
    "4       Eva         88    3.0          3.0                3.0\n",
    "\n",
    "```\n",
    "\n",
    "Nel caso dell'ordine decrescente, i punteggi pi√π alti hanno il rango 1.\n",
    "\n",
    "1. **Classifica con `NaN`**:\n",
    "Se ci sono valori `NaN`, puoi scegliere come trattarli utilizzando il parametro `na_option`.\n",
    "\n",
    "```python\n",
    "df['Punteggio_con_NaN'] = [85, 92, None, 92, 88]\n",
    "df['Rango_con_NaN'] = df['Punteggio_con_NaN'].rank(na_option='top')\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   Studente  Punteggio  Rango  Rango_dens  Rango_decrescente  Punteggio_con_NaN  Rango_con_NaN\n",
    "0     Alice         85    4.0          4.0                4.0               85.0            4.0\n",
    "1       Bob         92    1.5          1.0                2.5               92.0            1.5\n",
    "2   Charlie         78    5.0          5.0                5.0                NaN            1.0\n",
    "3     David         92    1.5          2.0                2.5               92.0            1.5\n",
    "4       Eva         88    3.0          3.0                3.0               88.0            3.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, i valori `NaN` sono trattati come i valori pi√π piccoli (grazie all'uso di `na_option='top'`), quindi ottengono un rango di 1.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    \n",
    "    `.rank()` √® molto utile quando si ha bisogno di classificare i dati in base ai valori in una o pi√π colonne. √à spesso utilizzato in contesti come la creazione di classifiche, la valutazione delle performance (ad esempio, punteggi, vendite, ecc.), o quando si vogliono assegnare posizioni relative a dei valori.\n",
    "    \n",
    "- **Limitazioni**:\n",
    "    - Quando si hanno duplicati nei dati, √® importante scegliere il metodo di assegnazione dei ranghi (`method`) in modo che la classificazione riflettente la realt√†. Se non viene scelto un metodo adeguato, potrebbero esserci conflitti nelle posizioni.\n",
    "    - Il trattamento dei valori `NaN` deve essere configurato correttamente per evitare che influiscano negativamente sulla classificazione.\n",
    "\n",
    "In generale, `.rank()` √® uno strumento utile per analizzare e presentare i dati in modo da evidenziare le posizioni relative di ogni elemento in un determinato ordine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.cumsum()` / `.cumprod()` ‚Äì Calcola somma/prodotto cumulativi\n",
    "\n",
    "I metodi `.cumsum()` e `.cumprod()` in pandas sono utilizzati per calcolare la somma cumulativa e il prodotto cumulativo di una serie o di un DataFrame lungo un determinato asse (righe o colonne). Questi metodi sono utili quando si desidera tenere traccia dei cambiamenti progressivi in un dataset, come nei calcoli di bilancio, analisi di crescita, o altre applicazioni che richiedono il monitoraggio di valori cumulativi.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.cumsum(axis=None, skipna=True, *args, **kwargs)\n",
    "DataFrame.cumprod(axis=None, skipna=True, *args, **kwargs)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`axis`**:\n",
    "    - **0** (default): Calcola la somma o il prodotto cumulativo lungo le righe (ovvero per ogni colonna).\n",
    "    - **1**: Calcola lungo le colonne (ovvero per ogni riga).\n",
    "2. **`skipna`**:\n",
    "    - **True** (default): I valori `NaN` vengono ignorati nel calcolo. Se uno o pi√π valori nella colonna o nella riga sono `NaN`, vengono esclusi dal calcolo.\n",
    "    - **False**: Se c'√® un `NaN`, l'intero risultato diventa `NaN` a partire dalla posizione del `NaN`.\n",
    "3. **`args` e `*kwargs`**: Parametri aggiuntivi che possono essere passati per esigenze specifiche, ma generalmente non sono necessari per il calcolo di base.\n",
    "\n",
    "### Differenze tra `.cumsum()` e `.cumprod()`:\n",
    "\n",
    "- **`.cumsum()`** calcola la **somma cumulativa**: ogni elemento del risultato √® la somma di tutti gli elementi precedenti (incluso l'elemento corrente).\n",
    "- **`.cumprod()`** calcola il **prodotto cumulativo**: ogni elemento del risultato √® il prodotto di tutti gli elementi precedenti (incluso l'elemento corrente).\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "### 1. **Esempio di `.cumsum()`**:\n",
    "\n",
    "Supponiamo di avere un DataFrame con i guadagni mensili di un'azienda e vogliamo calcolare i guadagni cumulativi nel tempo.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Mese': ['Gennaio', 'Febbraio', 'Marzo', 'Aprile'],\n",
    "    'Guadagni': [100, 200, 150, 300]\n",
    "})\n",
    "\n",
    "# Calcolare la somma cumulativa dei guadagni\n",
    "df['Guadagni_cumulativi'] = df['Guadagni'].cumsum()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Mese  Guadagni  Guadagni_cumulativi\n",
    "0   Gennaio       100                  100\n",
    "1  Febbraio       200                  300\n",
    "2     Marzo       150                  450\n",
    "3    Aprile       300                  750\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, ogni valore della colonna `Guadagni_cumulativi` √® la somma cumulativa dei guadagni fino a quel mese.\n",
    "\n",
    "### 2. **Esempio di `.cumprod()`**:\n",
    "\n",
    "Supponiamo ora di avere un DataFrame con un prodotto di crescita (ad esempio, un tasso di crescita mensile) e vogliamo calcolare il valore cumulativo nel tempo.\n",
    "\n",
    "```python\n",
    "# DataFrame di esempio con tassi di crescita\n",
    "df = pd.DataFrame({\n",
    "    'Mese': ['Gennaio', 'Febbraio', 'Marzo', 'Aprile'],\n",
    "    'Tasso_di_crescita': [1.05, 1.10, 1.08, 1.06]\n",
    "})\n",
    "\n",
    "# Calcolare il prodotto cumulativo dei tassi di crescita\n",
    "df['Crescita_cumulativa'] = df['Tasso_di_crescita'].cumprod()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Mese  Tasso_di_crescita  Crescita_cumulativa\n",
    "0   Gennaio               1.05               1.05\n",
    "1  Febbraio               1.10               1.155\n",
    "2     Marzo               1.08               1.247\n",
    "3    Aprile               1.06               1.320\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, ogni valore della colonna `Crescita_cumulativa` √® il prodotto cumulativo dei tassi di crescita fino a quel mese.\n",
    "\n",
    "### 3. **Utilizzo con `skipna`**:\n",
    "\n",
    "Se nel dataset ci sono valori mancanti (`NaN`), possiamo gestirli con il parametro `skipna`. Vediamo un esempio dove ci sono dei `NaN` nei dati.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Mese': ['Gennaio', 'Febbraio', 'Marzo', 'Aprile'],\n",
    "    'Guadagni': [100, None, 150, 200]\n",
    "})\n",
    "\n",
    "# Calcolare la somma cumulativa ignorando i NaN\n",
    "df['Guadagni_cumulativi'] = df['Guadagni'].cumsum(skipna=True)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Mese  Guadagni  Guadagni_cumulativi\n",
    "0   Gennaio       100                  100\n",
    "1  Febbraio      NaN                  100\n",
    "2     Marzo       150                  250\n",
    "3    Aprile       200                  450\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, la funzione ha ignorato il `NaN` in Febbraio e ha continuato a calcolare la somma cumulativa per il resto dei mesi.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - `.cumsum()` √® utile per tracciare progressi o accumuli, come in analisi finanziarie (somma dei guadagni nel tempo) o in altre aree in cui si vuole vedere un accumulo progressivo di valori.\n",
    "    - `.cumprod()` √® utile quando si lavora con crescite esponenziali o processi che coinvolgono moltiplicazioni successive, come nei calcoli finanziari (ad esempio, calcolare il valore cumulativo di un investimento che cresce a tassi composti).\n",
    "- **Limitazioni**:\n",
    "    - Se i dati contengono `NaN` e si sceglie `skipna=False`, il risultato sar√† anch'esso `NaN` se si incontra un `NaN` nel calcolo.\n",
    "    - Entrambi i metodi restituiscono una serie o DataFrame di dimensioni uguali a quelle originali, ma i valori risultanti potrebbero non essere direttamente interpretabili senza contesto (ad esempio, un prodotto cumulativo che diventa molto grande pu√≤ non avere significato immediato).\n",
    "\n",
    "In generale, questi metodi sono molto utili per analisi che richiedono la comprensione dell'accumulo o dell'effetto di cambiamenti successivi su un dato set di valori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.diff()` ‚Äì Calcola la differenza tra righe successive\n",
    "\n",
    "Il metodo `.diff()` in pandas √® utilizzato per calcolare la **differenza tra i valori di righe successive** in un DataFrame o una Serie. Questo √® utile per analizzare i cambiamenti tra i valori in un dataset, come ad esempio il cambiamento nei prezzi, nei guadagni o nelle misure di performance tra periodi consecutivi.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.diff(periods=1, axis=0)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`periods`** (default = 1):\n",
    "    - Indica di quante righe deve essere spostata la differenza. Se √® impostato su 1 (default), calcola la differenza tra righe consecutive.\n",
    "    - Se impostato su un valore maggiore (ad esempio 2), calcola la differenza tra la riga attuale e quella che si trova `n` righe sopra.\n",
    "2. **`axis`** (default = 0):\n",
    "    - **0**: Calcola la differenza lungo le righe (ovvero per ogni colonna).\n",
    "    - **1**: Calcola la differenza lungo le colonne (ovvero per ogni riga). Questo non √® comune, ma pu√≤ essere utile in casi specifici.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "### 1. **Esempio di base con `.diff()`**:\n",
    "\n",
    "Supponiamo di avere un DataFrame che mostra i guadagni mensili di un'azienda e vogliamo calcolare la differenza tra i guadagni di ciascun mese rispetto al mese precedente.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Mese': ['Gennaio', 'Febbraio', 'Marzo', 'Aprile'],\n",
    "    'Guadagni': [100, 200, 150, 300]\n",
    "})\n",
    "\n",
    "# Calcolare la differenza tra i guadagni del mese corrente e quelli del mese precedente\n",
    "df['Differenza_guadagni'] = df['Guadagni'].diff()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Mese  Guadagni  Differenza_guadagni\n",
    "0   Gennaio       100                 NaN\n",
    "1  Febbraio       200               100.0\n",
    "2     Marzo       150              -50.0\n",
    "3    Aprile       300               150.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- La differenza per \"Gennaio\" √® `NaN` perch√© non ci sono dati precedenti.\n",
    "- La differenza per \"Febbraio\" √® `200 - 100 = 100`.\n",
    "- La differenza per \"Marzo\" √® `150 - 200 = -50`.\n",
    "- La differenza per \"Aprile\" √® `300 - 150 = 150`.\n",
    "\n",
    "### 2. **Esempio con `periods`**:\n",
    "\n",
    "Supponiamo di voler calcolare la differenza tra un mese e il mese precedente, ma anche tra due mesi fa (ad esempio, calcolare la differenza a intervalli di due mesi).\n",
    "\n",
    "```python\n",
    "# Calcolare la differenza tra il mese corrente e il mese precedente (periodo=1)\n",
    "df['Differenza_2_mesi'] = df['Guadagni'].diff(periods=2)\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "      Mese  Guadagni  Differenza_guadagni  Differenza_2_mesi\n",
    "0   Gennaio       100                 NaN                NaN\n",
    "1  Febbraio       200               100.0                NaN\n",
    "2     Marzo       150              -50.0               50.0\n",
    "3    Aprile       300               150.0              100.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, abbiamo:\n",
    "\n",
    "- Per \"Marzo\", la differenza con il mese che si trova due posizioni indietro (`Febbraio` ‚Üí `Gennaio`) √® `150 - 100 = 50`.\n",
    "- Per \"Aprile\", la differenza con il mese che si trova due posizioni indietro (`Marzo` ‚Üí `Febbraio`) √® `300 - 200 = 100`.\n",
    "\n",
    "### 3. **Esempio con `axis=1`**:\n",
    "\n",
    "Se desideriamo calcolare la differenza tra le colonne (non tra le righe), possiamo usare il parametro `axis=1`.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [10, 20, 30, 40],\n",
    "    'B': [5, 15, 25, 35],\n",
    "    'C': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "# Calcolare la differenza tra le colonne per ogni riga\n",
    "df_diff = df.diff(axis=1)\n",
    "print(df_diff)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    A   B  C\n",
    "0 NaN  0.0 NaN\n",
    "1 NaN  0.0 NaN\n",
    "2 NaN  0.0 NaN\n",
    "3 NaN  0.0 NaN\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, la differenza tra le colonne viene calcolata per ogni riga. Poich√© i valori sono in ordine crescente, il risultato della differenza tra le colonne per ciascuna riga √® 0, ad eccezione dei valori `NaN` per le prime colonne.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - `.diff()` √® utile quando si desidera analizzare la variazione tra i valori successivi di una colonna, come nei casi di:\n",
    "        - Analisi di performance nel tempo (es. variazione giornaliera o mensile dei guadagni, prezzi, temperature, ecc.).\n",
    "        - Analisi delle differenze tra periodi consecutivi per rilevare cambiamenti o trend.\n",
    "    - Pu√≤ essere utile anche per calcolare la variazione tra periodi distanti (utilizzando il parametro `periods`).\n",
    "- **Limitazioni**:\n",
    "    - Se c'√® un valore `NaN` all'inizio o durante il calcolo, i risultati saranno anch'essi `NaN`.\n",
    "    - Se i dati non sono ordinati temporalmente o in un ordine significativo, l'uso di `.diff()` potrebbe non avere senso o produrre risultati fuorvianti.\n",
    "\n",
    "In generale, `.diff()` √® un metodo potente per analizzare e visualizzare le variazioni nei dati tra righe consecutive o a intervalli specifici, rendendolo ideale per le analisi di serie temporali o altre applicazioni in cui √® importante osservare i cambiamenti nel tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.expanding()` ‚Äì Applica trasformazioni espansive (es. somma cumulativa)\n",
    "\n",
    "Il metodo `.expanding()` di pandas √® utilizzato per applicare trasformazioni cumulative (o espansive) a un DataFrame o una Serie. Le operazioni cumulative calcolano valori basati su un intervallo che si espande progressivamente, prendendo in considerazione tutte le righe precedenti fino alla riga corrente.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.expanding(min_periods=1).funzione()\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`min_periods`** (default = 1):\n",
    "    - Imposta il numero minimo di periodi (righe) richiesti per calcolare il valore cumulativo. Se il numero di righe precedenti √® inferiore a `min_periods`, restituir√† `NaN` per quella riga.\n",
    "    - √à utile quando si desidera evitare calcoli cumulativi che non sono ancora \"completi\", come ad esempio la somma dei valori a partire dalla seconda riga.\n",
    "2. **Funzioni applicabili**:\n",
    "    - Le funzioni che possono essere applicate a un oggetto `.expanding()` includono funzioni statistiche e di aggregazione, come `.sum()`, `.mean()`, `.min()`, `.max()`, `.std()`, `.median()`, e altre funzioni personalizzate.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "### 1. **Esempio con la somma cumulativa (`.sum()`)**:\n",
    "\n",
    "Supponiamo di avere un DataFrame che contiene vendite giornaliere e vogliamo calcolare la somma cumulativa delle vendite fino a ogni giorno.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Giorno': ['Lun', 'Mar', 'Mer', 'Gio', 'Ven'],\n",
    "    'Vendite': [100, 200, 150, 300, 250]\n",
    "})\n",
    "\n",
    "# Somma cumulativa delle vendite\n",
    "df['Somma_cumulativa'] = df['Vendite'].expanding().sum()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  Giorno  Vendite  Somma_cumulativa\n",
    "0    Lun      100               100\n",
    "1    Mar      200               300\n",
    "2    Mer      150               450\n",
    "3    Gio      300               750\n",
    "4    Ven      250              1000\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- La somma cumulativa inizia da `100` (per il giorno \"Lun\").\n",
    "- La somma cumulativa per \"Mar\" √® `100 + 200 = 300`.\n",
    "- E cos√¨ via per gli altri giorni.\n",
    "\n",
    "### 2. **Esempio con la media cumulativa (`.mean()`)**:\n",
    "\n",
    "Supponiamo ora di voler calcolare la **media cumulativa** dei guadagni di ogni mese.\n",
    "\n",
    "```python\n",
    "# Media cumulativa delle vendite\n",
    "df['Media_cumulativa'] = df['Vendite'].expanding().mean()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  Giorno  Vendite  Somma_cumulativa  Media_cumulativa\n",
    "0    Lun      100               100               100.0\n",
    "1    Mar      200               300               150.0\n",
    "2    Mer      150               450               150.0\n",
    "3    Gio      300               750               187.5\n",
    "4    Ven      250              1000               200.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- La **media cumulativa** per il primo giorno √® semplicemente il valore del giorno stesso (`100`).\n",
    "- Per \"Mar\", la media cumulativa √® `(100 + 200) / 2 = 150`.\n",
    "- E cos√¨ via per gli altri giorni.\n",
    "\n",
    "### 3. **Esempio con `min()` e `max()`**:\n",
    "\n",
    "Il metodo `.expanding()` pu√≤ anche essere utilizzato con altre funzioni statistiche come `min()` e `max()` per ottenere il minimo e il massimo cumulativo fino alla riga corrente.\n",
    "\n",
    "```python\n",
    "# Minimo cumulativo\n",
    "df['Min_cumulativo'] = df['Vendite'].expanding().min()\n",
    "\n",
    "# Massimo cumulativo\n",
    "df['Max_cumulativo'] = df['Vendite'].expanding().max()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  Giorno  Vendite  Somma_cumulativa  Media_cumulativa  Min_cumulativo  Max_cumulativo\n",
    "0    Lun      100               100               100.0             100             100\n",
    "1    Mar      200               300               150.0             100             200\n",
    "2    Mer      150               450               150.0             100             200\n",
    "3    Gio      300               750               187.5             100             300\n",
    "4    Ven      250              1000               200.0             100             300\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- **Minimo cumulativo**: Il minimo resta `100` fino a \"Ven\", poich√© `100` √® il valore minimo per tutte le righe.\n",
    "- **Massimo cumulativo**: Il massimo aumenta man mano che vengono inclusi valori pi√π alti (ad esempio, `300` √® il massimo tra tutte le vendite).\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - `.expanding()` √® utile quando si desidera applicare trasformazioni cumulative che si costruiscono progressivamente lungo il dataset.\n",
    "    - Funziona bene per calcolare valori come la somma, la media, il massimo e il minimo, e pu√≤ essere applicato per analisi su serie temporali o qualsiasi dataset dove √® importante tracciare come cambiano i valori nel tempo o con l'aggiunta di nuove righe.\n",
    "    - √à particolarmente utile per analizzare come un aggregato si sviluppa o cambia con l'inclusione di pi√π dati, senza dover ripetere i calcoli ogni volta che nuovi dati vengono aggiunti.\n",
    "- **Limitazioni**:\n",
    "    - L'uso di `.expanding()` √® limitato a trasformazioni che hanno un senso cumulativo, come somme, medie e simili. Non √® adatto per calcoli che dipendono solo dai dati correnti o per analisi che richiedono valori statici.\n",
    "    - Se il dataset √® molto grande, l'applicazione di trasformazioni cumulative potrebbe aumentare il tempo di esecuzione, soprattutto se la funzione applicata √® complessa.\n",
    "\n",
    "In generale, `.expanding()` √® un potente strumento per applicare operazioni che devono essere eseguite su finestre che crescono nel tempo, rendendolo ideale per analisi temporali o di serie storiche.\n",
    "\n",
    "### `.expanding()` ‚Äì Applica trasformazioni espansive (es. somma cumulativa)\n",
    "\n",
    "Il metodo `.expanding()` di pandas √® utilizzato per applicare trasformazioni cumulative (o espansive) a un DataFrame o una Serie. Le operazioni cumulative calcolano valori basati su un intervallo che si espande progressivamente, prendendo in considerazione tutte le righe precedenti fino alla riga corrente.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.expanding(min_periods=1).funzione()\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "1. **`min_periods`** (default = 1):\n",
    "    - Imposta il numero minimo di periodi (righe) richiesti per calcolare il valore cumulativo. Se il numero di righe precedenti √® inferiore a `min_periods`, restituir√† `NaN` per quella riga.\n",
    "    - √à utile quando si desidera evitare calcoli cumulativi che non sono ancora \"completi\", come ad esempio la somma dei valori a partire dalla seconda riga.\n",
    "2. **Funzioni applicabili**:\n",
    "    - Le funzioni che possono essere applicate a un oggetto `.expanding()` includono funzioni statistiche e di aggregazione, come `.sum()`, `.mean()`, `.min()`, `.max()`, `.std()`, `.median()`, e altre funzioni personalizzate.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "### 1. **Esempio con la somma cumulativa (`.sum()`)**:\n",
    "\n",
    "Supponiamo di avere un DataFrame che contiene vendite giornaliere e vogliamo calcolare la somma cumulativa delle vendite fino a ogni giorno.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'Giorno': ['Lun', 'Mar', 'Mer', 'Gio', 'Ven'],\n",
    "    'Vendite': [100, 200, 150, 300, 250]\n",
    "})\n",
    "\n",
    "# Somma cumulativa delle vendite\n",
    "df['Somma_cumulativa'] = df['Vendite'].expanding().sum()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  Giorno  Vendite  Somma_cumulativa\n",
    "0    Lun      100               100\n",
    "1    Mar      200               300\n",
    "2    Mer      150               450\n",
    "3    Gio      300               750\n",
    "4    Ven      250              1000\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- La somma cumulativa inizia da `100` (per il giorno \"Lun\").\n",
    "- La somma cumulativa per \"Mar\" √® `100 + 200 = 300`.\n",
    "- E cos√¨ via per gli altri giorni.\n",
    "\n",
    "### 2. **Esempio con la media cumulativa (`.mean()`)**:\n",
    "\n",
    "Supponiamo ora di voler calcolare la **media cumulativa** dei guadagni di ogni mese.\n",
    "\n",
    "```python\n",
    "# Media cumulativa delle vendite\n",
    "df['Media_cumulativa'] = df['Vendite'].expanding().mean()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  Giorno  Vendite  Somma_cumulativa  Media_cumulativa\n",
    "0    Lun      100               100               100.0\n",
    "1    Mar      200               300               150.0\n",
    "2    Mer      150               450               150.0\n",
    "3    Gio      300               750               187.5\n",
    "4    Ven      250              1000               200.0\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- La **media cumulativa** per il primo giorno √® semplicemente il valore del giorno stesso (`100`).\n",
    "- Per \"Mar\", la media cumulativa √® `(100 + 200) / 2 = 150`.\n",
    "- E cos√¨ via per gli altri giorni.\n",
    "\n",
    "### 3. **Esempio con `min()` e `max()`**:\n",
    "\n",
    "Il metodo `.expanding()` pu√≤ anche essere utilizzato con altre funzioni statistiche come `min()` e `max()` per ottenere il minimo e il massimo cumulativo fino alla riga corrente.\n",
    "\n",
    "```python\n",
    "# Minimo cumulativo\n",
    "df['Min_cumulativo'] = df['Vendite'].expanding().min()\n",
    "\n",
    "# Massimo cumulativo\n",
    "df['Max_cumulativo'] = df['Vendite'].expanding().max()\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "  Giorno  Vendite  Somma_cumulativa  Media_cumulativa  Min_cumulativo  Max_cumulativo\n",
    "0    Lun      100               100               100.0             100             100\n",
    "1    Mar      200               300               150.0             100             200\n",
    "2    Mer      150               450               150.0             100             200\n",
    "3    Gio      300               750               187.5             100             300\n",
    "4    Ven      250              1000               200.0             100             300\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "- **Minimo cumulativo**: Il minimo resta `100` fino a \"Ven\", poich√© `100` √® il valore minimo per tutte le righe.\n",
    "- **Massimo cumulativo**: Il massimo aumenta man mano che vengono inclusi valori pi√π alti (ad esempio, `300` √® il massimo tra tutte le vendite).\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - `.expanding()` √® utile quando si desidera applicare trasformazioni cumulative che si costruiscono progressivamente lungo il dataset.\n",
    "    - Funziona bene per calcolare valori come la somma, la media, il massimo e il minimo, e pu√≤ essere applicato per analisi su serie temporali o qualsiasi dataset dove √® importante tracciare come cambiano i valori nel tempo o con l'aggiunta di nuove righe.\n",
    "    - √à particolarmente utile per analizzare come un aggregato si sviluppa o cambia con l'inclusione di pi√π dati, senza dover ripetere i calcoli ogni volta che nuovi dati vengono aggiunti.\n",
    "- **Limitazioni**:\n",
    "    - L'uso di `.expanding()` √® limitato a trasformazioni che hanno un senso cumulativo, come somme, medie e simili. Non √® adatto per calcoli che dipendono solo dai dati correnti o per analisi che richiedono valori statici.\n",
    "    - Se il dataset √® molto grande, l'applicazione di trasformazioni cumulative potrebbe aumentare il tempo di esecuzione, soprattutto se la funzione applicata √® complessa.\n",
    "\n",
    "In generale, `.expanding()` √® un potente strumento per applicare operazioni che devono essere eseguite su finestre che crescono nel tempo, rendendolo ideale per analisi temporali o di serie storiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.pipe()` ‚Äì Utilizza funzioni personalizzate sul DataFrame\n",
    "\n",
    "Il metodo `.pipe()` di pandas √® un modo molto utile per applicare funzioni personalizzate a un DataFrame o una Serie. Esso permette di concatenare diverse trasformazioni in modo fluido, rendendo il codice pi√π leggibile e facilmente estensibile, specialmente quando si desidera applicare pi√π operazioni su un DataFrame in sequenza.\n",
    "\n",
    "Il vantaggio principale di `.pipe()` √® che consente di mantenere il flusso delle operazioni pi√π chiaro e consente di utilizzare funzioni personalizzate con parametri, che possono essere facilmente incapsulate in una pipeline di trasformazione.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.pipe(func, *args, **kwargs)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "- **`func`**: La funzione che verr√† applicata al DataFrame (o Serie). Pu√≤ essere una funzione predefinita o una funzione personalizzata definita dall'utente.\n",
    "- **`args`**: Argomenti aggiuntivi che verranno passati alla funzione.\n",
    "- **`*kwargs`**: Argomenti keyword che verranno passati alla funzione.\n",
    "\n",
    "La funzione `func` deve accettare un oggetto DataFrame o Serie come primo argomento (o uno specificato dall'utente) e restituire un DataFrame o una Serie come risultato.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "### 1. **Esempio base di utilizzo con `.pipe()`**:\n",
    "\n",
    "Supponiamo di avere un DataFrame e di voler eseguire una serie di operazioni come il filtraggio dei valori e l'applicazione di una trasformazione.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione del DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [5, 4, 3, 2, 1]\n",
    "})\n",
    "\n",
    "# Funzione personalizzata per sommare una costante a tutte le colonne\n",
    "def add_constant(df, constant):\n",
    "    return df + constant\n",
    "\n",
    "# Applicazione della funzione tramite .pipe()\n",
    "df_transformed = df.pipe(add_constant, 10)\n",
    "print(df_transformed)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    A   B\n",
    "0  11  15\n",
    "1  12  14\n",
    "2  13  13\n",
    "3  14  12\n",
    "4  15  11\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, abbiamo creato una funzione `add_constant` che somma una costante a tutti i valori del DataFrame. Abbiamo utilizzato `.pipe()` per applicarla, passando il valore `10` come argomento.\n",
    "\n",
    "### 2. **Esempio di concatenazione di operazioni con `.pipe()`**:\n",
    "\n",
    "Supponiamo di voler applicare pi√π trasformazioni, come la normalizzazione dei valori e poi l'applicazione di una funzione per calcolare il quadrato di tutti i valori.\n",
    "\n",
    "```python\n",
    "# Funzione per normalizzare un DataFrame\n",
    "def normalize(df):\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "# Funzione per elevare al quadrato i valori\n",
    "def square(df):\n",
    "    return df**2\n",
    "\n",
    "# Concatenazione delle operazioni usando .pipe()\n",
    "df_transformed = (df.pipe(normalize)\n",
    "                  .pipe(square))\n",
    "print(df_transformed)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "          A         B\n",
    "0  1.000000  1.000000\n",
    "1  0.577350  0.577350\n",
    "2  0.000000  0.000000\n",
    "3  0.577350  0.577350\n",
    "4  1.000000  1.000000\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio:\n",
    "\n",
    "1. **`normalize()`**: Prima normalizza il DataFrame (standardizzazione dei valori).\n",
    "2. **`square()`**: Poi eleva al quadrato i valori risultanti.\n",
    "\n",
    "Usando `.pipe()`, possiamo concatenare le operazioni in un'unica sequenza leggibile.\n",
    "\n",
    "### 3. **Esempio di utilizzo con funzioni che accettano argomenti personalizzati**:\n",
    "\n",
    "Quando si desidera applicare una funzione con parametri personalizzati, `.pipe()` consente di passare gli argomenti in modo semplice.\n",
    "\n",
    "```python\n",
    "# Funzione che applica una moltiplicazione personalizzata\n",
    "def multiply(df, multiplier):\n",
    "    return df * multiplier\n",
    "\n",
    "# Applicazione della funzione tramite .pipe() con argomento personalizzato\n",
    "df_transformed = df.pipe(multiply, 2)\n",
    "print(df_transformed)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A   B\n",
    "0  2  10\n",
    "1  4  8\n",
    "2  6  6\n",
    "3  8  4\n",
    "4  10 2\n",
    "\n",
    "```\n",
    "\n",
    "In questo caso, la funzione `multiply` prende il DataFrame e un parametro `multiplier` per moltiplicare tutti i valori del DataFrame per `2`.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - `.pipe()` √® particolarmente utile quando si desidera creare una pipeline di trasformazioni fluida e leggibile, soprattutto se si vogliono applicare pi√π funzioni personalizzate a un DataFrame.\n",
    "    - √à ideale quando si ha una serie di trasformazioni che devono essere applicate in sequenza e si vogliono evitare lunghe catene di metodi o la ripetizione di funzioni in un blocco di codice.\n",
    "    - √à anche utile quando si lavora con funzioni che richiedono parametri aggiuntivi e non si vuole passare continuamente questi parametri tra le chiamate di funzione.\n",
    "- **Limitazioni**:\n",
    "    - `.pipe()` pu√≤ sembrare un po' pi√π complesso da comprendere per i principianti, poich√© si richiede l'uso di funzioni personalizzate e la gestione di argomenti extra.\n",
    "    - √à pi√π adatto per operazioni che devono essere concatenare piuttosto che per operazioni di base. Non sempre √® necessario utilizzare `.pipe()` se le operazioni sono semplici.\n",
    "\n",
    "In generale, `.pipe()` √® una funzionalit√† potente per applicare trasformazioni personalizzate e organizzare il flusso di lavoro in modo chiaro e modulare, migliorando la leggibilit√† e la manutenibilit√† del codice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.eval()` ‚Äì Valuta un'espressione Python come colonna del DataFrame\n",
    "\n",
    "Il metodo `.eval()` di pandas consente di eseguire espressioni Python su un DataFrame in modo efficiente. In pratica, permette di calcolare valori e creare nuove colonne o modificare quelle esistenti usando espressioni scritte in una sintassi simile a quella di Python, ma operando direttamente sulle colonne del DataFrame.\n",
    "\n",
    "Utilizzare `.eval()` pu√≤ portare a un miglioramento delle prestazioni rispetto alla scrittura di operazioni su DataFrame con operazioni di tipo standard (ad esempio, `df['A'] + df['B']`), specialmente con DataFrame di grandi dimensioni.\n",
    "\n",
    "### Sintassi:\n",
    "\n",
    "```python\n",
    "DataFrame.eval(expr, inplace=False, **kwargs)\n",
    "\n",
    "```\n",
    "\n",
    "### Parametri principali:\n",
    "\n",
    "- **`expr`**: Una stringa che rappresenta l'espressione da valutare. Pu√≤ essere un'espressione matematica, booleana o una combinazione di operazioni tra le colonne del DataFrame.\n",
    "- **`inplace`**: Booleano che, se impostato su `True`, modifica direttamente il DataFrame originale. Se `False`, restituisce un nuovo DataFrame senza modificare quello originale. Il valore predefinito √® `False`.\n",
    "- **`*kwargs`**: Parametri opzionali che possono essere passati per gestire variabili esterne, ad esempio con il parametro `bindings` per associare variabili esterne all'espressione.\n",
    "\n",
    "### Esempi:\n",
    "\n",
    "### 1. **Esempio base di `.eval()` per operazioni matematiche**:\n",
    "\n",
    "Supponiamo di avere un DataFrame con due colonne e di voler creare una nuova colonna che sia il risultato di una somma tra le due colonne.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creazione del DataFrame di esempio\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [5, 6, 7, 8]\n",
    "})\n",
    "\n",
    "# Creazione della colonna 'C' come somma delle colonne 'A' e 'B'\n",
    "df.eval('C = A + B', inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B  C\n",
    "0  1  5  6\n",
    "1  2  6  8\n",
    "2  3  7 10\n",
    "3  4  8 12\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, l'espressione `'C = A + B'` viene valutata direttamente e una nuova colonna `C` viene creata come somma delle colonne `A` e `B`.\n",
    "\n",
    "### 2. **Esempio di `.eval()` per operazioni booleane**:\n",
    "\n",
    "Puoi anche utilizzare `.eval()` per applicare condizioni booleane. Ad esempio, supponiamo di voler creare una nuova colonna che indichi se la somma di `A` e `B` √® maggiore di un certo valore.\n",
    "\n",
    "```python\n",
    "# Creazione della colonna 'Flag' che verifica se la somma di A e B √® maggiore di 10\n",
    "df.eval('Flag = (A + B) > 10', inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B  C  Flag\n",
    "0  1  5  6  False\n",
    "1  2  6  8  False\n",
    "2  3  7 10   True\n",
    "3  4  8 12   True\n",
    "\n",
    "```\n",
    "\n",
    "Qui, abbiamo utilizzato `.eval()` per creare la colonna `Flag`, che √® `True` quando la somma delle colonne `A` e `B` √® maggiore di `10`, e `False` altrimenti.\n",
    "\n",
    "### 3. **Esempio di utilizzo di variabili esterne**:\n",
    "\n",
    "Puoi anche passare variabili esterne all'interno dell'espressione. Questo √® particolarmente utile quando hai bisogno di lavorare con valori che non sono nel DataFrame, ma che vuoi utilizzare per calcoli.\n",
    "\n",
    "```python\n",
    "# Variabile esterna\n",
    "multiplier = 3\n",
    "\n",
    "# Creazione della colonna 'D' come risultato della moltiplicazione di A e del valore esterno 'multiplier'\n",
    "df.eval('D = A * @multiplier', inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B  C  Flag  D\n",
    "0  1  5  6  False  3\n",
    "1  2  6  8  False  6\n",
    "2  3  7 10   True  9\n",
    "3  4  8 12   True 12\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, abbiamo utilizzato il simbolo `@` per fare riferimento alla variabile esterna `multiplier` e moltiplicare la colonna `A` per questo valore.\n",
    "\n",
    "### 4. **Esempio di utilizzo con `inplace=False`**:\n",
    "\n",
    "Se non vuoi modificare direttamente il DataFrame originale, puoi impostare `inplace=False` per ottenere un nuovo DataFrame con le modifiche applicate.\n",
    "\n",
    "```python\n",
    "# Creazione di un nuovo DataFrame con la colonna 'E' come differenza tra 'B' e 'A'\n",
    "df_new = df.eval('E = B - A', inplace=False)\n",
    "\n",
    "print(df_new)\n",
    "\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B  C  Flag  D  E\n",
    "0  1  5  6  False  3  4\n",
    "1  2  6  8  False  6  4\n",
    "2  3  7 10   True  9  4\n",
    "3  4  8 12   True 12  4\n",
    "\n",
    "```\n",
    "\n",
    "In questo esempio, `df` non viene modificato, ma viene creato un nuovo DataFrame `df_new` con la colonna `E`.\n",
    "\n",
    "### Considerazioni finali:\n",
    "\n",
    "- **Quando usarlo**:\n",
    "    - `.eval()` √® particolarmente utile quando si desidera applicare espressioni matematiche o booleane su pi√π colonne in modo conciso e leggibile.\n",
    "    - √à ideale per operazioni su grandi DataFrame dove l'uso di `.eval()` pu√≤ migliorare le prestazioni rispetto a scrivere operazioni di calcolo tramite codice pi√π complesso.\n",
    "    - Pu√≤ essere utile quando si lavora con variabili esterne che devono essere utilizzate all'interno delle espressioni.\n",
    "- **Limitazioni**:\n",
    "    - Non supporta tutte le operazioni, in particolare quelle che coinvolgono metodi complessi o funzioni non scalari che non possono essere rappresentati facilmente in una stringa di espressione.\n",
    "    - Non tutte le funzioni personalizzate possono essere usate con `.eval()`, poich√© l'espressione √® limitata a operazioni matematiche e logiche basilari.\n",
    "\n",
    "In generale, `.eval()` √® un potente strumento che rende il calcolo di nuove colonne e operazioni tra colonne pi√π efficiente e leggibile, soprattutto su DataFrame di grandi dimensioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Aggregation and Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.groupby()`¬†‚Äì Raggruppa il DataFrame in base a una o pi√π colonne\n",
    "\n",
    "Il comando `.groupby()` √® uno dei metodi fondamentali di Pandas utilizzato per raggruppare i dati in un DataFrame in base a una o pi√π colonne. Dopo aver effettuato il raggruppamento, √® possibile eseguire operazioni aggregate, come somme, medie, conteggi, ecc., su ciascun gruppo.\n",
    "\n",
    "### Principali parametri di `.groupby()`\n",
    "\n",
    "1. **by**:\n",
    "    - Descrizione: Indica la colonna o le colonne su cui si vuole effettuare il raggruppamento.\n",
    "    - Tipo: Stringa o lista di stringhe.\n",
    "    - Esempio:\n",
    "        - Raggruppamento per una singola colonna: `df.groupby('colonna1')`\n",
    "        - Raggruppamento per pi√π colonne: `df.groupby(['colonna1', 'colonna2'])`\n",
    "2. **axis**:\n",
    "    - Descrizione: Specifica se il raggruppamento deve avvenire lungo le righe o le colonne. Di solito √® impostato su `0` (per le righe), ma pu√≤ essere cambiato su `1` per le colonne.\n",
    "    - Tipo: Intero (0 o 1).\n",
    "    - Esempio: `df.groupby('colonna', axis=0)` (questo √® il comportamento predefinito).\n",
    "3. **as_index**:\n",
    "    - Descrizione: Se impostato su `True` (predefinito), l'indice del DataFrame risultante sar√† il valore della colonna utilizzata per il raggruppamento. Se impostato su `False`, la colonna utilizzata per il raggruppamento non diventer√† l'indice del DataFrame risultante.\n",
    "    - Tipo: Booleano.\n",
    "    - Esempio:\n",
    "        - `df.groupby('colonna', as_index=True)`\n",
    "        - `df.groupby('colonna', as_index=False)`\n",
    "4. **sort**:\n",
    "    - Descrizione: Determina se i gruppi devono essere ordinati o meno. Se `True`, i gruppi vengono ordinati per le chiavi. Se `False`, i gruppi non sono ordinati.\n",
    "    - Tipo: Booleano.\n",
    "    - Esempio: `df.groupby('colonna', sort=False)`\n",
    "5. **group_keys**:\n",
    "    - Descrizione: Se impostato su `True`, le chiavi del gruppo verranno incluse come indice del risultato.\n",
    "    - Tipo: Booleano.\n",
    "    - Esempio: `df.groupby('colonna', group_keys=True)`\n",
    "6. **observed**:\n",
    "    - Descrizione: Questo parametro √® utilizzato per lavorare con variabili categoriali. Se `True`, l'output conterr√† solo le categorie osservate nei dati. Se `False` (predefinito), includer√† tutte le categorie possibili, anche quelle non presenti nei dati.\n",
    "    - Tipo: Booleano.\n",
    "    - Esempio: `df.groupby('colonna', observed=True)`\n",
    "\n",
    "### Esempi\n",
    "\n",
    "1. **Raggruppare per una colonna e calcolare la somma**:\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Valore': [10, 20, 30, 40, 50]\n",
    "    })\n",
    "    \n",
    "    grouped = df.groupby('Categoria')['Valore'].sum()\n",
    "    print(grouped)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Categoria\n",
    "    A    90\n",
    "    B    60\n",
    "    Name: Valore, dtype: int64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **Raggruppare per pi√π colonne e calcolare la media**:\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Gruppo': ['A', 'A', 'B', 'B', 'A'],\n",
    "        'Sesso': ['M', 'F', 'M', 'F', 'M'],\n",
    "        'Et√†': [23, 25, 30, 35, 40]\n",
    "    })\n",
    "    \n",
    "    grouped = df.groupby(['Gruppo', 'Sesso'])['Et√†'].mean()\n",
    "    print(grouped)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Gruppo  Sesso\n",
    "    A       F        25.0\n",
    "            M        31.5\n",
    "    B       F        35.0\n",
    "            M        30.0\n",
    "    Name: Et√†, dtype: float64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **Raggruppare senza cambiare l'indice**:\n",
    "    \n",
    "    ```python\n",
    "    grouped = df.groupby('Categoria', as_index=False)['Valore'].sum()\n",
    "    print(grouped)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "      Categoria  Valore\n",
    "    0         A      90\n",
    "    1         B      60\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.groupby()`**:\n",
    "    - Quando hai bisogno di aggregare i dati in base a una o pi√π colonne e vuoi eseguire operazioni statistiche come somma, media, conteggio, ecc.\n",
    "    - √à utile quando si analizzano dataset complessi con pi√π variabili e si vogliono ottenere insights sui vari gruppi di dati.\n",
    "    - Utile anche per raggruppamenti gerarchici, come nei dati temporali o geografici.\n",
    "- **Casi d'uso comuni**:\n",
    "    - Raggruppamento di dati di vendite per prodotto, mese o anno.\n",
    "    - Calcolo delle statistiche aggregate per ciascun gruppo (es. media del reddito per ogni fascia di et√†).\n",
    "    - Operazioni con dati di clienti in base a diverse caratteristiche (es. numero di transazioni per tipo di cliente).\n",
    "\n",
    "Usa `.groupby()` quando hai dati eterogenei e hai bisogno di aggregare, riassumere o estrarre informazioni da gruppi specifici in modo efficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.agg()`¬†‚Äì Applica funzioni di aggregazione come somma, media, min, max sui dati raggruppati\n",
    "\n",
    "Il metodo `.agg()` di Pandas √® utilizzato per applicare funzioni di aggregazione a un oggetto `GroupBy` (come quello creato con `.groupby()`). Consente di applicare pi√π funzioni di aggregazione sui dati raggruppati e restituire risultati personalizzati.\n",
    "\n",
    "### Principali parametri di `.agg()`\n",
    "\n",
    "1. **func**:\n",
    "    - Descrizione: Una funzione o una lista di funzioni da applicare ai dati raggruppati. Pu√≤ essere:\n",
    "        - Una singola funzione (ad esempio `'sum'`, `'mean'`, `'min'`, `'max'`).\n",
    "        - Una lista di funzioni da applicare simultaneamente (ad esempio, `['sum', 'mean']`).\n",
    "        - Un dizionario in cui ogni colonna ha una funzione specifica da applicare.\n",
    "    - Tipo: Stringa, lista di stringhe, dizionario o funzione.\n",
    "    - Esempio:\n",
    "        - `df.groupby('colonna').agg('sum')`\n",
    "        - `df.groupby('colonna').agg(['mean', 'min'])`\n",
    "        - `df.groupby('colonna').agg({'colonna1': 'sum', 'colonna2': 'mean'})`\n",
    "2. **axis**:\n",
    "    - Descrizione: Determina se l'aggregazione deve essere applicata lungo le righe o le colonne. Impostato su `0` per le righe (comportamento predefinito).\n",
    "    - Tipo: Intero (0 o 1).\n",
    "    - Esempio: `df.groupby('colonna').agg('sum', axis=0)` (predefinito).\n",
    "\n",
    "### Esempi\n",
    "\n",
    "1. **Applicare una funzione di aggregazione (somma)**:\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Valore': [10, 20, 30, 40, 50]\n",
    "    })\n",
    "    \n",
    "    # Raggruppa per 'Categoria' e applica la somma sui valori\n",
    "    grouped = df.groupby('Categoria').agg('sum')\n",
    "    print(grouped)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "              Valore\n",
    "    Categoria\n",
    "    A                90\n",
    "    B                60\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **Applicare pi√π funzioni di aggregazione (somma e media)**:\n",
    "    \n",
    "    ```python\n",
    "    grouped = df.groupby('Categoria').agg(['sum', 'mean'])\n",
    "    print(grouped)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "              Valore\n",
    "                sum mean\n",
    "    Categoria\n",
    "    A                90   30.0\n",
    "    B                60   30.0\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **Usare un dizionario per applicare diverse funzioni su colonne specifiche**:\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Valore': [10, 20, 30, 40, 50],\n",
    "        'Quantit√†': [1, 2, 3, 4, 5]\n",
    "    })\n",
    "    \n",
    "    # Raggruppa per 'Categoria' e applica 'sum' su 'Valore' e 'mean' su 'Quantit√†'\n",
    "    grouped = df.groupby('Categoria').agg({'Valore': 'sum', 'Quantit√†': 'mean'})\n",
    "    print(grouped)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "              Valore  Quantit√†\n",
    "    Categoria\n",
    "    A                90        3.0\n",
    "    B                60        3.0\n",
    "    \n",
    "    ```\n",
    "    \n",
    "4. **Applicare una funzione personalizzata**:\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Valore': [10, 20, 30, 40, 50]\n",
    "    })\n",
    "    \n",
    "    # Raggruppa per 'Categoria' e applica una funzione personalizzata che calcola la deviazione standard\n",
    "    grouped = df.groupby('Categoria').agg(lambda x: x.std())\n",
    "    print(grouped)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "              Valore\n",
    "    Categoria\n",
    "    A                20.0\n",
    "    B                14.142136\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.agg()`**:\n",
    "    - Quando hai bisogno di applicare pi√π funzioni di aggregazione su un `GroupBy` e ottenere risultati aggregati pi√π complessi.\n",
    "    - √à utile quando vuoi ottenere statistiche descrittive su pi√π colonne contemporaneamente, come somma, media, deviazione standard, minimo e massimo, per gruppi specifici.\n",
    "    - Pu√≤ essere usato per applicare funzioni personalizzate che non sono incluse tra le funzioni predefinite.\n",
    "- **Casi d'uso comuni**:\n",
    "    - Analisi dei dati di vendita: somma delle vendite e media degli importi per ogni categoria di prodotto.\n",
    "    - Analisi dei punteggi degli studenti: somma dei punteggi e media dei tempi di studio per ogni classe.\n",
    "    - Aggiornamento delle metriche finanziarie: minimo e massimo dei saldi dei conti bancari per ogni segmento di cliente.\n",
    "\n",
    "**Nota**: L'uso di `.agg()` √® particolarmente utile quando hai bisogno di pi√π operazioni di aggregazione su un gruppo o quando le funzioni di aggregazione predefinite non sono sufficienti per le tue esigenze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.sum()`,¬†`.mean()`,¬†`.min()`,¬†`.max()`,¬†`.count()`¬†‚Äì Calcola direttamente queste statistiche\n",
    "\n",
    "I metodi `.sum()`, `.mean()`, `.min()`, `.max()`, e `.count()` sono funzioni di aggregazione che vengono comunemente utilizzate in Pandas per calcolare statistiche dirette sui dati. Questi metodi sono generalmente utilizzati sui DataFrame o Series per ottenere informazioni aggregate in modo semplice e veloce.\n",
    "\n",
    "### 1. **`.sum()`** - Calcola la somma degli elementi\n",
    "\n",
    "- **Descrizione**: Restituisce la somma degli elementi di una colonna o riga del DataFrame o della Series.\n",
    "- **Applicazione**: Pu√≤ essere utilizzato per calcolare la somma totale dei valori numerici di una colonna (ad esempio, somma delle vendite, somma dei punteggi).\n",
    "- **Tipo di ritorno**: Un singolo valore (se applicato su una Series), o un DataFrame con la somma per ogni colonna (se applicato su un DataFrame).\n",
    "- **Esempio**:\n",
    "**Output**:\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Vendite': [10, 20, 30, 40, 50]\n",
    "    })\n",
    "    \n",
    "    somma = df['Vendite'].sum()\n",
    "    print(somma)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    ```\n",
    "    150\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### 2. **`.mean()`** - Calcola la media degli elementi\n",
    "\n",
    "- **Descrizione**: Restituisce la media (o la media aritmetica) dei valori numerici di una colonna o di una riga.\n",
    "- **Applicazione**: Utile per calcolare la media dei punteggi, delle vendite o di qualsiasi altra variabile numerica.\n",
    "- **Tipo di ritorno**: Un singolo valore (se applicato su una Series), o un DataFrame con la media per ogni colonna (se applicato su un DataFrame).\n",
    "- **Esempio**:\n",
    "**Output**:\n",
    "    \n",
    "    ```python\n",
    "    media = df['Vendite'].mean()\n",
    "    print(media)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    ```\n",
    "    30.0\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### 3. **`.min()`** - Restituisce il valore minimo\n",
    "\n",
    "- **Descrizione**: Restituisce il valore minimo della colonna o della Series.\n",
    "- **Applicazione**: Utilizzato per trovare il valore pi√π basso, come il prezzo minimo di un prodotto, o il punteggio pi√π basso tra gli studenti.\n",
    "- **Tipo di ritorno**: Il valore minimo (per una Series) o una Series con il minimo per ogni colonna (per un DataFrame).\n",
    "- **Esempio**:\n",
    "**Output**:\n",
    "    \n",
    "    ```python\n",
    "    minimo = df['Vendite'].min()\n",
    "    print(minimo)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    ```\n",
    "    10\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### 4. **`.max()`** - Restituisce il valore massimo\n",
    "\n",
    "- **Descrizione**: Restituisce il valore massimo di una colonna o Series.\n",
    "- **Applicazione**: Utile per trovare il valore pi√π alto, come il valore massimo di vendite o il punteggio pi√π alto.\n",
    "- **Tipo di ritorno**: Il valore massimo (per una Series) o una Series con il massimo per ogni colonna (per un DataFrame).\n",
    "- **Esempio**:\n",
    "**Output**:\n",
    "    \n",
    "    ```python\n",
    "    massimo = df['Vendite'].max()\n",
    "    print(massimo)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    ```\n",
    "    50\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### 5. **`.count()`** - Conta il numero di valori non nulli\n",
    "\n",
    "- **Descrizione**: Restituisce il numero di valori non nulli (non NaN) in una colonna o in una Series.\n",
    "- **Applicazione**: Utile per determinare quanti valori validi ci sono in una colonna, come il numero di risposte valide in un sondaggio.\n",
    "- **Tipo di ritorno**: Il conteggio dei valori non nulli (per una Series) o una Series con il conteggio per ogni colonna (per un DataFrame).\n",
    "- **Esempio**:\n",
    "**Output**:\n",
    "    \n",
    "    ```python\n",
    "    count = df['Vendite'].count()\n",
    "    print(count)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    ```\n",
    "    5\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "1. **Esempio su un DataFrame con pi√π colonne**:\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Vendite': [10, 20, 30, 40, 50],\n",
    "        'Profitto': [5, 10, 15, 20, 25]\n",
    "    })\n",
    "    \n",
    "    # Somma di tutte le colonne numeriche\n",
    "    somma = df.sum()\n",
    "    print(somma)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Categoria     ABA\n",
    "    Vendite        150\n",
    "    Profitto       75\n",
    "    dtype: object\n",
    "    \n",
    "    ```\n",
    "    \n",
    "2. **Esempio con .groupby() e statistiche aggregate**:\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Vendite': [10, 20, 30, 40, 50],\n",
    "        'Profitto': [5, 10, 15, 20, 25]\n",
    "    })\n",
    "    \n",
    "    # Raggruppa per 'Categoria' e calcola somma e media\n",
    "    result = df.groupby('Categoria').agg({\n",
    "        'Vendite': 'sum',\n",
    "        'Profitto': 'mean'\n",
    "    })\n",
    "    print(result)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "              Vendite  Profitto\n",
    "    Categoria\n",
    "    A                90      15.0\n",
    "    B                60      15.0\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.sum()`, `.mean()`, `.min()`, `.max()`, `.count()`**:\n",
    "    - **.sum()** √® utile per ottenere il totale di una variabile, ad esempio il totale delle vendite o dei profitti.\n",
    "    - **.mean()** √® ideale quando hai bisogno di ottenere la media di una variabile numerica, come la media dei punteggi, dei saldi, o dei redditi.\n",
    "    - **.min() e .max()** sono utili per trovare i valori estremi, come il minimo e il massimo dei prezzi, dei punteggi o delle vendite.\n",
    "    - **.count()** √® fondamentale per contare il numero di valori validi (non nulli) in una colonna o Serie, ad esempio per verificare il numero di transazioni o di risposte in un sondaggio.\n",
    "\n",
    "Questi metodi sono semplici e molto veloci, quindi sono adatti per un'analisi iniziale dei dati. Quando hai bisogno di statistiche descrittive rapide su un DataFrame o una Serie, questi metodi sono gli strumenti perfetti da usare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.pivot_table()`¬†‚Äì Crea una tabella pivot con righe, colonne e valori specificati\n",
    "\n",
    "Il metodo `.pivot_table()` di Pandas viene utilizzato per creare tabelle pivot, che sono una rappresentazione tabellare dei dati dove √® possibile aggregare (riassumere) informazioni in base a righe, colonne e valori specifici. √à molto utile per esplorare e analizzare grandi quantit√† di dati in modo sintetico.\n",
    "\n",
    "### Principali parametri di `.pivot_table()`\n",
    "\n",
    "1. **data**:\n",
    "    - Descrizione: Il DataFrame su cui eseguire la pivot.\n",
    "    - Tipo: DataFrame.\n",
    "    - Esempio: `df` (un DataFrame contenente i dati).\n",
    "2. **values**:\n",
    "    - Descrizione: Le colonne per le quali calcolare le aggregazioni (ad esempio, somma, media).\n",
    "    - Tipo: Stringa o lista di stringhe (nomi delle colonne).\n",
    "    - Esempio: `'Vendite'`, `['Vendite', 'Profitto']`.\n",
    "3. **index**:\n",
    "    - Descrizione: Le colonne da usare come indice per le righe della tabella pivot.\n",
    "    - Tipo: Stringa o lista di stringhe.\n",
    "    - Esempio: `'Categoria'`, `['Categoria', 'Anno']`.\n",
    "4. **columns**:\n",
    "    - Descrizione: Le colonne da usare come intestazioni delle colonne della tabella pivot.\n",
    "    - Tipo: Stringa o lista di stringhe.\n",
    "    - Esempio: `'Mese'`.\n",
    "5. **aggfunc**:\n",
    "    - Descrizione: La funzione di aggregazione da utilizzare per calcolare i valori nella tabella pivot (ad esempio, somma, media, conteggio).\n",
    "    - Tipo: Funzione (ad esempio, `'sum'`, `'mean'`, `'count'`, o una funzione personalizzata).\n",
    "    - Default: `'mean'`.\n",
    "    - Esempio: `np.sum`, `'mean'`, `'count'`.\n",
    "6. **fill_value**:\n",
    "    - Descrizione: Un valore con cui riempire i NaN (valori mancanti) nella tabella pivot.\n",
    "    - Tipo: Qualsiasi (es. `0`, `'NA'`, ecc.).\n",
    "    - Esempio: `0`, `'N/A'`.\n",
    "7. **margins**:\n",
    "    - Descrizione: Se `True`, aggiunge una colonna e una riga di margine con i totali (somme o medie).\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `False`.\n",
    "    - Esempio: `margins=True`.\n",
    "8. **margins_name**:\n",
    "    - Descrizione: Nome per le righe/colonne di margine, utilizzato quando `margins=True`.\n",
    "    - Tipo: Stringa.\n",
    "    - Esempio: `'Totale'`.\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "1. **Creare una tabella pivot di base con somma**:\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Creiamo un DataFrame di esempio\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Mese': ['Gennaio', 'Gennaio', 'Febbraio', 'Febbraio', 'Marzo'],\n",
    "        'Vendite': [10, 20, 30, 40, 50],\n",
    "        'Profitto': [5, 10, 15, 20, 25]\n",
    "    })\n",
    "    \n",
    "    # Creare una tabella pivot con le 'Categoria' come righe, 'Mese' come colonne e 'Vendite' come valori\n",
    "    pivot = df.pivot_table(values='Vendite', index='Categoria', columns='Mese', aggfunc='sum', fill_value=0)\n",
    "    print(pivot)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Mese      Febbraio  Gennaio  Marzo\n",
    "    Categoria\n",
    "    A               30       10     50\n",
    "    B               40       20      0\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo esempio, la tabella pivot mostra la somma delle vendite per ogni categoria e mese. Se non ci sono dati per una combinazione, il valore viene sostituito con `0` grazie all'uso di `fill_value=0`.\n",
    "    \n",
    "2. **Aggiungere margini (totali)**:\n",
    "    \n",
    "    ```python\n",
    "    pivot = df.pivot_table(values='Vendite', index='Categoria', columns='Mese', aggfunc='sum', margins=True, margins_name='Totale', fill_value=0)\n",
    "    print(pivot)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Mese      Febbraio  Gennaio  Marzo  Totale\n",
    "    Categoria\n",
    "    A               30       10     50      90\n",
    "    B               40       20      0      60\n",
    "    Totale          70       30     50     150\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    Qui, `margins=True` ha aggiunto una colonna e una riga che contengono i totali delle vendite per mese e per categoria.\n",
    "    \n",
    "3. **Usare pi√π colonne di aggregazione (media e somma)**:\n",
    "    \n",
    "    ```python\n",
    "    pivot = df.pivot_table(values=['Vendite', 'Profitto'], index='Categoria', columns='Mese', aggfunc={'Vendite': 'sum', 'Profitto': 'mean'}, margins=True, margins_name='Totale', fill_value=0)\n",
    "    print(pivot)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "            Profitto                Vendite\n",
    "    Mese       Febbraio Gennaio Marzo Febbraio Gennaio Marzo Totale\n",
    "    Categoria\n",
    "    A                15       5    25      30       10     50     90\n",
    "    B                20      10     0      40       20      0     60\n",
    "    Totale           35      15    25      70       30     50    150\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, abbiamo specificato diverse funzioni di aggregazione per ogni colonna: la somma per `Vendite` e la media per `Profitto`.\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.pivot_table()`**:\n",
    "    - **Analisi delle vendite**: Pu√≤ essere utilizzato per aggregare vendite per categoria, mese o qualsiasi altra variabile.\n",
    "    - **Analisi dei dati di performance**: Utilizzato per ottenere sintesi statistiche come somma, media o conteggio su gruppi di dati.\n",
    "    - **Riassunti complessi**: Quando desideri ottenere riepiloghi complessi, con la possibilit√† di usare diverse funzioni di aggregazione (somma, media, minimo, massimo, ecc.) su colonne diverse.\n",
    "- **Vantaggi**:\n",
    "    - √à molto potente quando si lavora con grandi quantit√† di dati e si desidera un riepilogo aggregato per gruppi.\n",
    "    - I margini sono utili per vedere i totali globali dei dati.\n",
    "    - La possibilit√† di usare pi√π funzioni di aggregazione √® estremamente versatile per ottenere diversi tipi di statistiche.\n",
    "- **Casi d'uso comuni**:\n",
    "    - Analisi delle vendite per categoria e mese.\n",
    "    - Calcolare statistiche dei dati finanziari (come somme e medie) per diversi gruppi di clienti.\n",
    "    - Creare report di sintesi sui dati di performance (ad esempio, il punteggio medio degli studenti per classe e materia).\n",
    "\n",
    "Usare `.pivot_table()` √® particolarmente utile quando devi riassumere i dati in modo chiaro e comprensibile, e quando desideri analizzare i dati attraverso diverse dimensioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.transform()`¬†‚Äì Applica funzioni a colonne raggruppate usando¬†`groupby()`\n",
    "\n",
    "Il metodo `.transform()` di Pandas √® utilizzato per applicare funzioni di trasformazione a colonne di un DataFrame che sono state raggruppate tramite il metodo `.groupby()`. A differenza di `.agg()`, che restituisce un risultato aggregato, `.transform()` mantiene la stessa forma del DataFrame originale, quindi l'output avr√† lo stesso numero di righe del DataFrame iniziale. Questo √® utile quando si vogliono applicare calcoli come la normalizzazione o altre trasformazioni su ogni gruppo, ma mantenendo i dati originali.\n",
    "\n",
    "### Principali parametri di `.transform()`\n",
    "\n",
    "1. **func**:\n",
    "    - Descrizione: La funzione da applicare agli elementi di ciascun gruppo.\n",
    "    - Tipo: Funzione (ad esempio, una funzione predefinita come `'sum'`, `'mean'`, oppure una funzione personalizzata).\n",
    "    - Esempio: `np.mean`, `np.std`, una funzione definita dall'utente come `lambda x: x / x.sum()`.\n",
    "2. **axis**:\n",
    "    - Descrizione: L'asse lungo cui applicare la funzione. Se si sta usando un `groupby`, di solito si usa `axis=0` (lungo le righe).\n",
    "    - Tipo: Intero (di solito `0` per righe).\n",
    "    - Esempio: `axis=0`.\n",
    "3. **raw**:\n",
    "    - Descrizione: Se `True`, la funzione sar√† applicata sugli array di Numpy invece che su un `DataFrame` o `Series`. Questo pu√≤ migliorare le prestazioni, ma limita le funzionalit√†.\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `False`.\n",
    "    - Esempio: `raw=True`.\n",
    "4. **level**:\n",
    "    - Descrizione: Questo parametro √® utilizzato quando si hanno indici multi-livello (MultiIndex). Indica quale livello usare per raggruppare.\n",
    "    - Tipo: Intero o livello di indice.\n",
    "    - Esempio: `level=0`.\n",
    "5. **numeric_only**:\n",
    "    - Descrizione: Se `True`, applica la funzione solo alle colonne numeriche.\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `False`.\n",
    "    - Esempio: `numeric_only=True`.\n",
    "\n",
    "### Esempi pratici\n",
    "\n",
    "1. **Applicare una funzione di trasformazione semplice**:\n",
    "In questo esempio, vogliamo applicare la funzione `mean` su un gruppo, ma mantenere la stessa struttura del DataFrame.\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # DataFrame di esempio\n",
    "    df = pd.DataFrame({\n",
    "        'Gruppo': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "        'Valore': [10, 20, 30, 40, 50, 60]\n",
    "    })\n",
    "    \n",
    "    # Raggruppare per 'Gruppo' e applicare la trasformazione della media\n",
    "    df['Media_per_gruppo'] = df.groupby('Gruppo')['Valore'].transform('mean')\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "      Gruppo  Valore  Media_per_gruppo\n",
    "    0      A      10               20.0\n",
    "    1      A      20               20.0\n",
    "    2      A      30               20.0\n",
    "    3      B      40               50.0\n",
    "    4      B      50               50.0\n",
    "    5      B      60               50.0\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    Qui, abbiamo raggruppato i dati per la colonna `'Gruppo'` e applicato la funzione `mean` alla colonna `'Valore'`. Ogni riga ha il valore medio del proprio gruppo.\n",
    "    \n",
    "2. **Applicare una funzione personalizzata**:\n",
    "In questo esempio, useremo una funzione personalizzata che normalizza i valori rispetto alla somma del gruppo.\n",
    "    \n",
    "    ```python\n",
    "    # Funzione di normalizzazione\n",
    "    def normalize(x):\n",
    "        return x / x.sum()\n",
    "    \n",
    "    # Applicare la funzione di normalizzazione a 'Valore' per ogni gruppo\n",
    "    df['Valore_normalizzato'] = df.groupby('Gruppo')['Valore'].transform(normalize)\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "      Gruppo  Valore  Valore_normalizzato\n",
    "    0      A      10                 0.333333\n",
    "    1      A      20                 0.666667\n",
    "    2      A      30                 1.000000\n",
    "    3      B      40                 0.333333\n",
    "    4      B      50                 0.416667\n",
    "    5      B      60                 0.500000\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo esempio, la funzione personalizzata `normalize()` calcola la frazione di ciascun valore rispetto alla somma dei valori del gruppo.\n",
    "    \n",
    "3. **Applicare pi√π funzioni usando `transform`**:\n",
    "√à possibile anche applicare pi√π funzioni utilizzando `transform()` passando una lista di funzioni.\n",
    "    \n",
    "    ```python\n",
    "    # Applicare pi√π funzioni di trasformazione\n",
    "    df[['Somma', 'Media']] = df.groupby('Gruppo')['Valore'].transform([np.sum, np.mean])\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "      Gruppo  Valore  Somma  Media\n",
    "    0      A      10     60   20.0\n",
    "    1      A      20     60   20.0\n",
    "    2      A      30     60   20.0\n",
    "    3      B      40    150   50.0\n",
    "    4      B      50    150   50.0\n",
    "    5      B      60    150   50.0\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, abbiamo calcolato la somma e la media dei valori per ciascun gruppo e abbiamo applicato entrambe le trasformazioni.\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.transform()`**:\n",
    "    - **Per calcoli che mantengono la forma originale dei dati**: Quando si vogliono applicare trasformazioni ai dati raggruppati ma si desidera mantenere la stessa forma del DataFrame (senza ridurre il numero di righe come avviene con `.agg()`).\n",
    "    - **Per normalizzazione o standardizzazione**: √à utile quando si vuole normalizzare i valori rispetto al gruppo di appartenenza.\n",
    "    - **Per applicare funzioni personalizzate**: Consente di applicare trasformazioni complesse che non sono coperte dalle funzioni di aggregazione predefinite.\n",
    "- **Vantaggi**:\n",
    "    - Mantenimento della struttura originale dei dati: La funzione di trasformazione restituisce un DataFrame con lo stesso numero di righe dell'originale.\n",
    "    - Applicazione di funzioni personalizzate: √à possibile applicare trasformazioni pi√π avanzate, come normalizzazioni o altre operazioni specifiche.\n",
    "- **Casi d'uso comuni**:\n",
    "    - Applicare un calcolo a livello di gruppo, come il calcolo della media o somma, ma senza ridurre il DataFrame.\n",
    "    - Trasformazioni per analisi dei dati temporali o di serie temporali, ad esempio calcolando il tasso di crescita o la variazione percentuale per ogni gruppo.\n",
    "    - Normalizzazione dei dati per ogni gruppo (ad esempio, scala dei valori in un gruppo rispetto alla somma o alla media del gruppo).\n",
    "\n",
    "In generale, `.transform()` √® utile quando si desidera una trasformazione che non modifica il numero di righe del DataFrame e si desidera applicare calcoli pi√π complessi sui gruppi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.size()`¬†‚Äì Restituisce la dimensione di ogni gruppo\n",
    "\n",
    "Il metodo `.size()` di Pandas viene utilizzato per ottenere la dimensione di ogni gruppo in un oggetto `groupby`. Restituisce una Serie con l'indice che rappresenta i gruppi e i valori che rappresentano il numero di elementi in ciascun gruppo. Questo √® utile quando si vuole sapere quanti record appartengono a ciascun gruppo, ma senza dover applicare alcuna funzione di aggregazione.\n",
    "\n",
    "### Principali parametri di `.size()`\n",
    "\n",
    "1. **level**:\n",
    "    - Descrizione: Quando si ha un indice multi-livello (MultiIndex), il parametro `level` permette di specificare su quale livello effettuare il raggruppamento. Se non specificato, la funzione restituir√† la dimensione di tutti i gruppi.\n",
    "    - Tipo: Intero o livello di indice.\n",
    "    - Esempio: `level=0` (se si ha un indice multi-livello).\n",
    "2. **sort**:\n",
    "    - Descrizione: Se impostato su `True`, i gruppi risultanti verranno ordinati in ordine crescente. Se impostato su `False`, i gruppi saranno restituiti nell'ordine in cui appaiono nel DataFrame originale.\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `True`.\n",
    "    - Esempio: `sort=False`.\n",
    "\n",
    "### Esempio pratico di `.size()`\n",
    "\n",
    "1. **Raggruppare e ottenere la dimensione di ogni gruppo**:\n",
    "Supponiamo di avere un DataFrame in cui ogni gruppo rappresenta un tipo di prodotto, e vogliamo sapere quanti record ci sono per ciascun tipo di prodotto.\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # DataFrame di esempio\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'A', 'B', 'B', 'C', 'A', 'C'],\n",
    "        'Prodotto': ['X', 'Y', 'Z', 'W', 'Q', 'X', 'W']\n",
    "    })\n",
    "    \n",
    "    # Raggruppare per 'Categoria' e ottenere la dimensione di ogni gruppo\n",
    "    gruppo_dimensione = df.groupby('Categoria').size()\n",
    "    \n",
    "    print(gruppo_dimensione)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Categoria\n",
    "    A    3\n",
    "    B    2\n",
    "    C    2\n",
    "    dtype: int64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo esempio, abbiamo raggruppato i dati per la colonna `'Categoria'` e ottenuto il numero di elementi in ciascun gruppo. La Serie risultante mostra che ci sono 3 elementi nel gruppo `'A'`, 2 nel gruppo `'B'` e 2 nel gruppo `'C'`.\n",
    "    \n",
    "2. **Usare `level` per ottenere la dimensione su un indice multi-livello**:\n",
    "Se il DataFrame ha un indice multi-livello, √® possibile usare il parametro `level` per ottenere la dimensione su un livello specifico.\n",
    "    \n",
    "    ```python\n",
    "    # DataFrame con MultiIndex\n",
    "    df_multi = pd.DataFrame({\n",
    "        'Categoria': ['A', 'A', 'B', 'B', 'C', 'A', 'C'],\n",
    "        'Prodotto': ['X', 'Y', 'Z', 'W', 'Q', 'X', 'W'],\n",
    "        'Prezzo': [10, 20, 30, 40, 50, 60, 70]\n",
    "    }).set_index(['Categoria', 'Prodotto'])\n",
    "    \n",
    "    # Ottenere la dimensione dei gruppi per 'Categoria'\n",
    "    gruppo_dimensione = df_multi.groupby('Categoria').size()\n",
    "    \n",
    "    print(gruppo_dimensione)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Categoria\n",
    "    A    3\n",
    "    B    2\n",
    "    C    2\n",
    "    dtype: int64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.size()`**:\n",
    "    - **Per conoscere la dimensione dei gruppi**: √à utile quando si desidera sapere quante righe appartengono a ciascun gruppo senza applicare funzioni di aggregazione (come `sum()`, `mean()`, ecc.).\n",
    "    - **Contare il numero di record in un gruppo**: In contesti dove il conteggio del numero di occorrenze per ogni gruppo √® importante (ad esempio, per analizzare la distribuzione dei dati o per filtrare gruppi che soddisfano determinati criteri).\n",
    "- **Vantaggi**:\n",
    "    - Fornisce un rapido riepilogo del numero di record in ogni gruppo.\n",
    "    - Pu√≤ essere combinato facilmente con altre funzioni di raggruppamento per esplorare ulteriormente i dati.\n",
    "- **Casi d'uso comuni**:\n",
    "    - **Contare il numero di transazioni per ciascun cliente**.\n",
    "    - **Verificare la distribuzione dei dati su diverse categorie o classi**.\n",
    "    - **Contare la frequenza di ciascun valore in un DataFrame categoriale**.\n",
    "\n",
    "In generale, `.size()` √® uno strumento utile per ottenere rapidamente una panoramica delle dimensioni dei gruppi, senza applicare trasformazioni o aggregazioni sui dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.cumcount()`¬†‚Äì Conta le occorrenze cumulative di valori univoci\n",
    "\n",
    "Il metodo `.cumcount()` di Pandas √® utilizzato per contare le occorrenze cumulative di valori unici all'interno di un DataFrame, generalmente dopo aver applicato un'operazione di raggruppamento tramite `.groupby()`. Restituisce una Serie con i conteggi cumulativi di ogni valore all'interno di ogni gruppo, a partire da zero.\n",
    "\n",
    "### Principali Parametri di `.cumcount()`\n",
    "\n",
    "- **`ascending`**:\n",
    "    - Descrizione: Questo parametro indica se il conteggio deve essere eseguito in ordine crescente o decrescente all'interno di ciascun gruppo. Se `True`, il conteggio inizier√† dall'inizio del gruppo. Se `False`, inizier√† dalla fine del gruppo.\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `True`.\n",
    "    - Esempio: `ascending=False`.\n",
    "- **`dropna`**:\n",
    "    - Descrizione: Se impostato su `True`, i valori `NaN` (valori nulli) verranno esclusi dal conteggio. Se `False`, i `NaN` verranno conteggiati come parte della sequenza.\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `True`.\n",
    "    - Esempio: `dropna=False`.\n",
    "\n",
    "### Esempio pratico di `.cumcount()`\n",
    "\n",
    "1. **Contare le occorrenze cumulative all'interno di un gruppo**:\n",
    "Immagina di avere un DataFrame con informazioni su categorie di prodotti e vuoi sapere quante volte ogni prodotto appare in ciascuna categoria, ma in modo cumulativo.\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # DataFrame di esempio\n",
    "    df = pd.DataFrame({\n",
    "        'Categoria': ['A', 'A', 'B', 'B', 'A', 'A', 'B'],\n",
    "        'Prodotto': ['X', 'Y', 'X', 'Z', 'X', 'Y', 'Z']\n",
    "    })\n",
    "    \n",
    "    # Raggruppare per 'Categoria' e ottenere il conteggio cumulativo\n",
    "    df['Occorrenza_cumulativa'] = df.groupby('Categoria').cumcount()\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "      Categoria Prodotto  Occorrenza_cumulativa\n",
    "    0         A        X                     0\n",
    "    1         A        Y                     1\n",
    "    2         B        X                     0\n",
    "    3         B        Z                     1\n",
    "    4         A        X                     2\n",
    "    5         A        Y                     3\n",
    "    6         B        Z                     2\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo esempio, la colonna `'Occorrenza_cumulativa'` mostra il numero di volte che ogni prodotto √® apparso all'interno della rispettiva categoria fino a quel punto. Ad esempio, il prodotto `'X'` nella categoria `'A'` √® apparso tre volte, quindi l'ultima occorrenza ha il valore 2.\n",
    "    \n",
    "2. **Uso del parametro `ascending` per il conteggio in ordine inverso**:\n",
    "Se vuoi che il conteggio inizi dalla fine del gruppo, puoi usare `ascending=False`:\n",
    "    \n",
    "    ```python\n",
    "    # Conteggio cumulativo decrescente\n",
    "    df['Occorrenza_cumulativa_decrescente'] = df.groupby('Categoria').cumcount(ascending=False)\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "      Categoria Prodotto  Occorrenza_cumulativa  Occorrenza_cumulativa_decrescente\n",
    "    0         A        X                     0                               2\n",
    "    1         A        Y                     1                               1\n",
    "    2         B        X                     0                               1\n",
    "    3         B        Z                     1                               0\n",
    "    4         A        X                     2                               0\n",
    "    5         A        Y                     3                               3\n",
    "    6         B        Z                     2                               2\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, il conteggio inizia dalla fine del gruppo e cresce all'indietro.\n",
    "    \n",
    "3. **Contare le occorrenze cumulative con `dropna=False`**:\n",
    "Se nel tuo DataFrame ci sono valori `NaN` e vuoi che vengano inclusi nel conteggio cumulativo, puoi impostare `dropna=False`:\n",
    "    \n",
    "    ```python\n",
    "    # DataFrame con NaN\n",
    "    df_na = pd.DataFrame({\n",
    "        'Categoria': ['A', 'A', 'B', 'B', 'A', 'A', 'B', None],\n",
    "        'Prodotto': ['X', 'Y', 'X', 'Z', 'X', 'Y', 'Z', 'X']\n",
    "    })\n",
    "    \n",
    "    # Conteggio cumulativo inclusivo di NaN\n",
    "    df_na['Occorrenza_cumulativa'] = df_na.groupby('Categoria').cumcount(dropna=False)\n",
    "    \n",
    "    print(df_na)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "      Categoria Prodotto  Occorrenza_cumulativa\n",
    "    0         A        X                     0\n",
    "    1         A        Y                     1\n",
    "    2         B        X                     0\n",
    "    3         B        Z                     1\n",
    "    4         A        X                     2\n",
    "    5         A        Y                     3\n",
    "    6         B        Z                     2\n",
    "    7      NaN        X                   NaN\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    Qui, la riga con `NaN` nella colonna `'Categoria'` ha `NaN` come valore di `'Occorrenza_cumulativa'`.\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.cumcount()`**:\n",
    "    - **Per calcolare le occorrenze cumulative all'interno di un gruppo**: √à utile quando vuoi tracciare quante volte un elemento appare all'interno di un gruppo, sequenzialmente.\n",
    "    - **Analisi di serie temporali o sequenziali**: Se hai dati temporali o sequenziali (ad esempio, ordini di prodotti, azioni di clienti), il conteggio cumulativo pu√≤ essere un utile strumento per capire come i dati evolvono nel tempo.\n",
    "- **Vantaggi**:\n",
    "    - `.cumcount()` ti consente di tracciare l'andamento e l'ordine delle occorrenze, utile per l'analisi sequenziale.\n",
    "    - Pu√≤ essere usato in combinazione con `.groupby()` per ottenere conteggi personalizzati all'interno di gruppi specifici.\n",
    "- **Casi d'uso comuni**:\n",
    "    - **Monitoraggio della frequenza delle transazioni in una categoria di prodotti**.\n",
    "    - **Conteggio cumulativo delle vendite o ordini per ciascun cliente o regione**.\n",
    "    - **Rilevamento della sequenza di acquisto di un prodotto o di una categoria specifica**.\n",
    "\n",
    "`.cumcount()` √® particolarmente utile quando √® necessario tracciare l'ordine o la frequenza di occorrenze in un gruppo, offrendo una visione pi√π approfondita dei dati, soprattutto quando combinato con altre operazioni di aggregazione o analisi sequenziale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.nsmallest(n, columns)`¬†‚Äì Trova i¬†`n`¬†valori pi√π piccoli in una colonna\n",
    "\n",
    "Il metodo `.nsmallest(n, columns)` di Pandas permette di trovare i **n valori pi√π piccoli** in una o pi√π colonne di un DataFrame, restituendo le righe corrispondenti a quei valori. √à un metodo utile per estrarre rapidamente i valori minori di una colonna, senza dover ordinare l'intero DataFrame.\n",
    "\n",
    "### Principali Parametri di `.nsmallest()`\n",
    "\n",
    "- **`n`**:\n",
    "    - Descrizione: Indica il numero di valori pi√π piccoli da restituire.\n",
    "    - Tipo: Intero.\n",
    "    - Esempio: `n=5` per ottenere i 5 valori pi√π piccoli.\n",
    "- **`columns`**:\n",
    "    - Descrizione: La colonna (o le colonne) su cui basare il criterio di ordinamento. √à possibile fornire una singola colonna o una lista di colonne.\n",
    "    - Tipo: Stringa (per una singola colonna) o lista di stringhe (per pi√π colonne).\n",
    "    - Esempio: `columns='et√†'` oppure `columns=['et√†', 'salario']`.\n",
    "- **`keep`** (opzionale):\n",
    "    - Descrizione: Indica se mantenere il primo, l'ultimo o tutte le occorrenze di un valore uguale. I valori possibili sono:\n",
    "        - `'first'`: Mantieni la prima occorrenza.\n",
    "        - `'last'`: Mantieni l'ultima occorrenza.\n",
    "        - `False`: Non mantenere alcuna occorrenza duplicata.\n",
    "    - Tipo: Stringa o Booleano.\n",
    "    - Default: `'first'`.\n",
    "    - Esempio: `keep='last'`.\n",
    "\n",
    "### Esempi di utilizzo di `.nsmallest()`\n",
    "\n",
    "1. **Trova i 3 valori pi√π piccoli in una colonna**:\n",
    "Immagina di avere un DataFrame che contiene informazioni sui salari e desideri trovare i 3 salari pi√π bassi.\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # DataFrame di esempio\n",
    "    df = pd.DataFrame({\n",
    "        'Nome': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Salario': [3000, 1500, 2500, 1800, 2200]\n",
    "    })\n",
    "    \n",
    "    # Trova i 3 salari pi√π bassi\n",
    "    df_salario_basso = df.nsmallest(3, 'Salario')\n",
    "    \n",
    "    print(df_salario_basso)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "        Nome  Salario\n",
    "    1    Bob     1500\n",
    "    3  David     1800\n",
    "    4    Eva     2200\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo esempio, vengono restituiti i 3 salari pi√π bassi nel DataFrame, insieme alle righe corrispondenti.\n",
    "    \n",
    "2. **Trova i 2 valori pi√π piccoli in base a pi√π colonne**:\n",
    "Se vuoi trovare le righe con i salari pi√π bassi e, in caso di pari salario, ordinare per nome, puoi usare una lista di colonne.\n",
    "    \n",
    "    ```python\n",
    "    # Trova i 2 salari pi√π bassi, ordinati anche per nome\n",
    "    df_salario_basso_nome = df.nsmallest(2, ['Salario', 'Nome'])\n",
    "    \n",
    "    print(df_salario_basso_nome)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "        Nome  Salario\n",
    "    1    Bob     1500\n",
    "    3  David     1800\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    Qui, il metodo seleziona i 2 salari pi√π bassi, e in caso di pari salario (non presente in questo esempio), avrebbe ordinato anche per il nome.\n",
    "    \n",
    "3. **Gestire i duplicati con il parametro `keep`**:\n",
    "Se ci sono valori duplicati e vuoi mantenere solo l'ultima occorrenza, puoi usare il parametro `keep`.\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Nome': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Salario': [3000, 1500, 1500, 1800, 1500]\n",
    "    })\n",
    "    \n",
    "    # Trova i 3 salari pi√π bassi, mantenendo l'ultima occorrenza in caso di duplicati\n",
    "    df_salario_basso = df.nsmallest(3, 'Salario', keep='last')\n",
    "    \n",
    "    print(df_salario_basso)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "        Nome  Salario\n",
    "    1    Bob     1500\n",
    "    4    Eva     1500\n",
    "    3  David     1800\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, mantenendo l'ultima occorrenza dei salari uguali, Eva appare per ultima tra i salari di 1500.\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.nsmallest()`**:\n",
    "    - **Se vuoi estrarre rapidamente i valori pi√π piccoli di una colonna** senza dover ordinare tutto il DataFrame.\n",
    "    - **Quando desideri ottenere una selezione limitata** di righe con i valori pi√π bassi in base a una o pi√π colonne, utile per analizzare le \"performance pi√π basse\", i \"salari pi√π bassi\", o i \"punteggi pi√π bassi\".\n",
    "    - **Quando i dati contengono duplicati** e vuoi definire quale occorrenza mantenere usando il parametro `keep`.\n",
    "- **Vantaggi**:\n",
    "    - Efficienza nel trovare i valori pi√π piccoli senza dover ordinare tutto il DataFrame.\n",
    "    - √à possibile lavorare con dati che presentano duplicati o ordinare su pi√π colonne per ottenere il risultato desiderato.\n",
    "- **Casi d'uso comuni**:\n",
    "    - Selezionare i 5 prodotti con il prezzo pi√π basso.\n",
    "    - Trovare le 10 persone con i punteggi pi√π bassi in un test.\n",
    "    - Identificare le 3 vendite con il ricavo pi√π basso.\n",
    "\n",
    "`.nsmallest()` √® uno strumento potente per estrarre i valori minimi in modo efficiente, particolarmente utile per operazioni veloci su grandi dataset dove un ordinamento completo potrebbe essere troppo costoso in termini di tempo di esecuzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.nlargest(n, columns)`¬†‚Äì Trova i¬†`n`¬†valori pi√π grandi in una colonna\n",
    "\n",
    "Il metodo `.nlargest(n, columns)` di Pandas √® utilizzato per trovare i **n valori pi√π grandi** in una colonna o in un insieme di colonne di un DataFrame. √à l'opposto di `.nsmallest()`, ed √® utile per estrarre rapidamente i valori pi√π alti senza dover ordinare l'intero DataFrame.\n",
    "\n",
    "### Principali Parametri di `.nlargest()`\n",
    "\n",
    "- **`n`**:\n",
    "    - Descrizione: Indica il numero di valori pi√π grandi da restituire.\n",
    "    - Tipo: Intero.\n",
    "    - Esempio: `n=5` per ottenere i 5 valori pi√π grandi.\n",
    "- **`columns`**:\n",
    "    - Descrizione: La colonna (o le colonne) su cui basare il criterio di ordinamento. Pu√≤ essere una singola colonna o una lista di colonne.\n",
    "    - Tipo: Stringa (per una singola colonna) o lista di stringhe (per pi√π colonne).\n",
    "    - Esempio: `columns='salario'` oppure `columns=['salario', 'et√†']`.\n",
    "- **`keep`** (opzionale):\n",
    "    - Descrizione: Indica come gestire i duplicati. I valori possibili sono:\n",
    "        - `'first'`: Mantieni la prima occorrenza.\n",
    "        - `'last'`: Mantieni l'ultima occorrenza.\n",
    "        - `False`: Non mantenere alcuna occorrenza duplicata.\n",
    "    - Tipo: Stringa o Booleano.\n",
    "    - Default: `'first'`.\n",
    "    - Esempio: `keep='last'`.\n",
    "\n",
    "### Esempi di utilizzo di `.nlargest()`\n",
    "\n",
    "1. **Trova i 3 valori pi√π grandi in una colonna**:\n",
    "Immagina di avere un DataFrame con informazioni sui salari e desideri trovare i 3 salari pi√π alti.\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # DataFrame di esempio\n",
    "    df = pd.DataFrame({\n",
    "        'Nome': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Salario': [3000, 1500, 2500, 1800, 2200]\n",
    "    })\n",
    "    \n",
    "    # Trova i 3 salari pi√π alti\n",
    "    df_salario_alto = df.nlargest(3, 'Salario')\n",
    "    \n",
    "    print(df_salario_alto)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "        Nome  Salario\n",
    "    0  Alice     3000\n",
    "    2  Charlie     2500\n",
    "    4    Eva     2200\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    Qui, vengono restituiti i 3 salari pi√π alti nel DataFrame, insieme alle righe corrispondenti.\n",
    "    \n",
    "2. **Trova i 2 valori pi√π grandi in base a pi√π colonne**:\n",
    "Se vuoi trovare le righe con i salari pi√π alti e, in caso di pari salario, ordinare per nome, puoi usare una lista di colonne.\n",
    "    \n",
    "    ```python\n",
    "    # Trova i 2 salari pi√π alti, ordinati anche per nome\n",
    "    df_salario_alto_nome = df.nlargest(2, ['Salario', 'Nome'])\n",
    "    \n",
    "    print(df_salario_alto_nome)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "        Nome  Salario\n",
    "    0  Alice     3000\n",
    "    2  Charlie     2500\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, il metodo seleziona i 2 salari pi√π alti e, in caso di pari salario, li ordina anche per nome.\n",
    "    \n",
    "3. **Gestire i duplicati con il parametro `keep`**:\n",
    "Se ci sono valori duplicati e vuoi mantenere solo l'ultima occorrenza, puoi usare il parametro `keep`.\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Nome': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Salario': [3000, 1500, 1500, 1800, 1500]\n",
    "    })\n",
    "    \n",
    "    # Trova i 3 salari pi√π alti, mantenendo l'ultima occorrenza in caso di duplicati\n",
    "    df_salario_alto = df.nlargest(3, 'Salario', keep='last')\n",
    "    \n",
    "    print(df_salario_alto)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "        Nome  Salario\n",
    "    0  Alice     3000\n",
    "    2  Charlie     1500\n",
    "    4    Eva     1500\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, viene mantenuta l'ultima occorrenza del salario di 1500.\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.nlargest()`**:\n",
    "    - **Se vuoi estrarre rapidamente i valori pi√π alti di una colonna** senza dover ordinare tutto il DataFrame.\n",
    "    - **Quando desideri ottenere una selezione limitata** di righe con i valori pi√π alti in base a una o pi√π colonne.\n",
    "    - **Quando i dati contengono duplicati** e vuoi definire quale occorrenza mantenere usando il parametro `keep`.\n",
    "- **Vantaggi**:\n",
    "    - Efficienza nel trovare i valori pi√π alti senza dover ordinare tutto il DataFrame.\n",
    "    - √à possibile lavorare con dati che presentano duplicati o ordinare su pi√π colonne per ottenere il risultato desiderato.\n",
    "- **Casi d'uso comuni**:\n",
    "    - Selezionare i 5 prodotti con il prezzo pi√π alto.\n",
    "    - Trovare le 10 persone con i punteggi pi√π alti in un test.\n",
    "    - Identificare le 3 vendite con il ricavo pi√π alto.\n",
    "\n",
    "`.nlargest()` √® molto utile per estrarre rapidamente i valori massimi, in particolare quando si lavora con dataset molto grandi dove ordinare l'intero DataFrame potrebbe risultare costoso. Risulta ideale per analizzare le performance migliori o identificare i record di interesse in modo veloce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.mad()`¬†‚Äì Deviazione assoluta media per dati raggruppati\n",
    "\n",
    "Il metodo `.mad()` di Pandas calcola la **deviazione assoluta media** (Mean Absolute Deviation, MAD) di una serie di dati o di un DataFrame. La MAD misura quanto i dati si discostano mediamente dal valore centrale (tipicamente la mediana). √à una misura di dispersione che non √® influenzata da valori estremi (outlier) come la varianza o la deviazione standard.\n",
    "\n",
    "Quando si applica su un DataFrame raggruppato tramite `.groupby()`, `.mad()` calcola la deviazione assoluta media per ciascun gruppo.\n",
    "\n",
    "### Principali Parametri di `.mad()`\n",
    "\n",
    "- **`axis`** (opzionale):\n",
    "    - Descrizione: Specifica l'asse su cui applicare la funzione. Se non specificato, viene calcolato per ogni colonna.\n",
    "    - Tipo: Intero (0 per righe, 1 per colonne), o `None` (per calcolare su tutte le dimensioni).\n",
    "    - Default: `None`.\n",
    "    - Esempio: `axis=0` per calcolare lungo le righe, `axis=1` per calcolare lungo le colonne.\n",
    "- **`skipna`** (opzionale):\n",
    "    - Descrizione: Se `True`, esclude i valori `NaN` dal calcolo. Se `False`, restituisce `NaN` se ci sono valori `NaN` nei dati.\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `True`.\n",
    "    - Esempio: `skipna=False` se non si desidera escludere `NaN`.\n",
    "\n",
    "### Formula per la Deviazione Assoluta Media (MAD)\n",
    "\n",
    "La MAD viene calcolata con la seguente formula:\n",
    "\n",
    "MAD=1n‚àëi=1n‚à£xi‚àíMediana(x)‚à£\\text{MAD} = \\frac{1}{n} \\sum_{i=1}^{n} |x_i - \\text{Mediana}(x)|\n",
    "\n",
    "dove:\n",
    "\n",
    "- xix_i √® un valore dei dati,\n",
    "- Mediana(x)\\text{Mediana}(x) √® la mediana del set di dati,\n",
    "- nn √® il numero di dati.\n",
    "\n",
    "### Esempi di utilizzo di `.mad()`\n",
    "\n",
    "1. **Calcolare la MAD su una colonna di un DataFrame**:\n",
    "Immagina di avere un DataFrame con informazioni sul salario e sull'et√† e vuoi calcolare la MAD per la colonna del salario.\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # DataFrame di esempio\n",
    "    df = pd.DataFrame({\n",
    "        'Nome': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Salario': [3000, 1500, 2500, 1800, 2200]\n",
    "    })\n",
    "    \n",
    "    # Calcola la MAD sul salario\n",
    "    mad_salario = df['Salario'].mad()\n",
    "    \n",
    "    print(mad_salario)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    366.6666666666667\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    La MAD indica che, in media, i salari sono distanti dalla mediana di circa 367 unit√† monetarie.\n",
    "    \n",
    "2. **Calcolare la MAD su gruppi di dati raggruppati**:\n",
    "Se il DataFrame contiene una colonna per il genere e vuoi calcolare la MAD sul salario per ciascun genere, puoi utilizzare `.groupby()` combinato con `.mad()`.\n",
    "    \n",
    "    ```python\n",
    "    # DataFrame di esempio con genere\n",
    "    df = pd.DataFrame({\n",
    "        'Nome': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Salario': [3000, 1500, 2500, 1800, 2200],\n",
    "        'Genere': ['F', 'M', 'M', 'M', 'F']\n",
    "    })\n",
    "    \n",
    "    # Raggruppa per 'Genere' e calcola la MAD sul salario\n",
    "    mad_salario_genere = df.groupby('Genere')['Salario'].mad()\n",
    "    \n",
    "    print(mad_salario_genere)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    Genere\n",
    "    F    500.000000\n",
    "    M    300.000000\n",
    "    Name: Salario, dtype: float64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, per il genere femminile la MAD √® 500, mentre per il genere maschile √® 300. Questo significa che le donne hanno una maggiore dispersione salariale rispetto agli uomini.\n",
    "    \n",
    "3. **Gestire i valori NaN con `skipna`**:\n",
    "Se ci sono valori `NaN` nel tuo DataFrame, puoi usare `skipna=False` per includere i `NaN` nel calcolo (restituendo `NaN` se ci sono valori mancanti).\n",
    "    \n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Nome': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Salario': [3000, None, 2500, 1800, 2200]\n",
    "    })\n",
    "    \n",
    "    # Calcola la MAD sul salario con skipna=False\n",
    "    mad_salario = df['Salario'].mad(skipna=False)\n",
    "    \n",
    "    print(mad_salario)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    nan\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, poich√© c'√® un valore `NaN`, la MAD restituisce `NaN` per l'intera colonna.\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.mad()`**:\n",
    "    - **Misura della dispersione robusta**: La MAD √® particolarmente utile quando si desidera una misura di dispersione che non sia influenzata da valori estremi o outlier.\n",
    "    - **Quando non si vuole usare la varianza o la deviazione standard**: Se i dati contengono outlier o non sono distribuiti normalmente, la MAD pu√≤ essere una scelta migliore.\n",
    "    - **Per analisi su gruppi**: Utilizzando `.groupby()`, puoi calcolare la MAD per gruppi specifici, ad esempio per categoria, genere, regione, etc.\n",
    "- **Vantaggi**:\n",
    "    - √à una misura semplice e robusta della dispersione.\n",
    "    - Non √® sensibile agli outlier, quindi √® pi√π affidabile per dataset che contengono valori estremi.\n",
    "- **Casi d'uso comuni**:\n",
    "    - Calcolare la dispersione di un set di dati senza che i valori estremi influenzino troppo il risultato.\n",
    "    - Comparare la variabilit√† tra diversi gruppi o categorie (ad esempio, differenze salariali tra uomini e donne).\n",
    "\n",
    "`.mad()` √® una funzione utile per calcolare una misura robusta della dispersione dei dati, ideale quando i dati contengono outlier o non sono distribuiti normalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.rolling(window).apply()`¬†‚Äì Applica una funzione su una finestra mobile\n",
    "\n",
    "Il metodo `.rolling(window).apply()` in Pandas viene utilizzato per applicare una funzione su una finestra mobile (sliding window) di dati all'interno di un DataFrame o di una Serie. Le finestre mobili sono utili per eseguire operazioni che coinvolgono un sottoinsieme di dati continui, come calcolare medie mobili, somme cumulative, deviazioni standard e altre statistiche su intervalli di dati.\n",
    "\n",
    "### Principali Parametri di `.rolling(window).apply()`\n",
    "\n",
    "1. **`window`**:\n",
    "    - Descrizione: La dimensione della finestra mobile. Rappresenta il numero di osservazioni da includere in ogni \"finestra\".\n",
    "    - Tipo: Intero o oggetto `timedelta` (per finestre basate sul tempo, ad esempio giorni).\n",
    "    - Esempio: `window=3` per una finestra che considera 3 righe di dati alla volta.\n",
    "2. **`min_periods`** (opzionale):\n",
    "    - Descrizione: Il numero minimo di valori non `NaN` che devono essere presenti nella finestra per calcolare il risultato. Se il numero di valori validi √® inferiore, il risultato sar√† `NaN`.\n",
    "    - Tipo: Intero o `None`.\n",
    "    - Default: `None`.\n",
    "    - Esempio: `min_periods=2` se vuoi calcolare il risultato solo se almeno 2 valori nella finestra sono validi.\n",
    "3. **`axis`** (opzionale):\n",
    "    - Descrizione: L'asse su cui applicare la finestra.\n",
    "    - Tipo: Intero o `None`.\n",
    "    - Default: `None`.\n",
    "    - Esempio: `axis=0` per applicare la finestra sulle righe, `axis=1` per applicare la finestra sulle colonne.\n",
    "4. **`raw`** (opzionale):\n",
    "    - Descrizione: Se `True`, la funzione sar√† applicata su array Numpy raw. Se `False` (default), la funzione verr√† applicata sui dati come Pandas Series.\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `False`.\n",
    "    - Esempio: `raw=True` se si vuole passare i dati come array Numpy.\n",
    "5. **`center`** (opzionale):\n",
    "    - Descrizione: Se `True`, la finestra sar√† centrata (la finestra includer√† valori precedenti e successivi al punto corrente). Se `False`, la finestra si sposter√† in avanti (i valori saranno solo quelli precedenti al punto corrente).\n",
    "    - Tipo: Booleano.\n",
    "    - Default: `False`.\n",
    "    - Esempio: `center=True` per avere la finestra centrata.\n",
    "\n",
    "### Funzionamento di `.rolling(window).apply()`\n",
    "\n",
    "Il metodo `.rolling(window).apply()` crea una finestra mobile di dimensione specificata dal parametro `window`. Poi, applica una funzione su ogni finestra di dati. La funzione pu√≤ essere qualsiasi funzione che accetti un array o una Serie come input, come la somma, la media, il calcolo della deviazione standard, ecc.\n",
    "\n",
    "### Esempi di utilizzo di `.rolling(window).apply()`\n",
    "\n",
    "1. **Calcolare la media mobile con `.apply()`**:\n",
    "Supponiamo di avere una Serie con valori numerici e di voler calcolare la media mobile con una finestra di 3 periodi.\n",
    "    \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Serie di esempio\n",
    "    data = pd.Series([10, 20, 30, 40, 50, 60, 70])\n",
    "    \n",
    "    # Calcolare la media mobile con una finestra di 3\n",
    "    rolling_mean = data.rolling(window=3).apply(lambda x: x.mean())\n",
    "    \n",
    "    print(rolling_mean)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    0     NaN\n",
    "    1     NaN\n",
    "    2    20.0\n",
    "    3    30.0\n",
    "    4    40.0\n",
    "    5    50.0\n",
    "    6    60.0\n",
    "    dtype: float64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    La media mobile viene calcolata a partire dal terzo valore, poich√© le prime due finestre hanno meno di 3 valori.\n",
    "    \n",
    "2. **Calcolare la somma mobile con `.apply()`**:\n",
    "Utilizzando `.apply()`, puoi applicare qualsiasi funzione di aggregazione come la somma:\n",
    "    \n",
    "    ```python\n",
    "    # Calcolare la somma mobile con una finestra di 4\n",
    "    rolling_sum = data.rolling(window=4).apply(lambda x: x.sum())\n",
    "    \n",
    "    print(rolling_sum)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    0     NaN\n",
    "    1     NaN\n",
    "    2     NaN\n",
    "    3    100.0\n",
    "    4    140.0\n",
    "    5    180.0\n",
    "    6    220.0\n",
    "    dtype: float64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "3. **Calcolare la deviazione standard mobile con `.apply()`**:\n",
    "Se vuoi calcolare la deviazione standard mobile su una finestra di dati, puoi farlo con `.apply()`:\n",
    "    \n",
    "    ```python\n",
    "    # Calcolare la deviazione standard mobile con una finestra di 3\n",
    "    rolling_std = data.rolling(window=3).apply(lambda x: x.std())\n",
    "    \n",
    "    print(rolling_std)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    0     NaN\n",
    "    1     NaN\n",
    "    2     10.0\n",
    "    3     10.0\n",
    "    4     10.0\n",
    "    5     10.0\n",
    "    6     10.0\n",
    "    dtype: float64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "4. **Finestra mobile centrata**:\n",
    "Se vuoi che la finestra sia centrata attorno al valore corrente, puoi usare `center=True`:\n",
    "    \n",
    "    ```python\n",
    "    # Media mobile centrata con una finestra di 3\n",
    "    centered_rolling_mean = data.rolling(window=3, center=True).apply(lambda x: x.mean())\n",
    "    \n",
    "    print(centered_rolling_mean)\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    **Output**:\n",
    "    \n",
    "    ```\n",
    "    0     NaN\n",
    "    1    15.0\n",
    "    2    20.0\n",
    "    3    30.0\n",
    "    4    40.0\n",
    "    5    50.0\n",
    "    6     NaN\n",
    "    dtype: float64\n",
    "    \n",
    "    ```\n",
    "    \n",
    "    In questo caso, la finestra mobile √® centrata attorno a ciascun valore.\n",
    "    \n",
    "\n",
    "### Considerazioni Finali\n",
    "\n",
    "- **Quando usare `.rolling(window).apply()`**:\n",
    "    - **Calcolare statistiche mobili**: Se hai bisogno di calcolare statistiche che si riferiscono a finestre di dati contigue, come medie mobili, somme mobili, o deviazioni standard mobili.\n",
    "    - **Finestra mobile personalizzata**: Quando hai bisogno di applicare funzioni personalizzate, non solo statistiche predefinite, come la somma o la media.\n",
    "    - **Analisi temporale**: √à particolarmente utile in serie temporali per calcolare statistiche che evolvono nel tempo su finestre mobili (ad esempio, media mobile su dati giornalieri).\n",
    "- **Vantaggi**:\n",
    "    - Ti permette di applicare funzioni molto personalizzate sui dati, al di l√† delle statistiche standard.\n",
    "    - √à ideale per analisi su serie temporali, trend e altri tipi di dati sequenziali.\n",
    "- **Limitazioni**:\n",
    "    - Potrebbe essere meno efficiente di operazioni predefinite come `.mean()` o `.sum()`, soprattutto per grandi set di dati.\n",
    "    - Se la finestra √® troppo grande, potrebbe aumentare notevolmente i tempi di calcolo.\n",
    "\n",
    "In sintesi, `.rolling(window).apply()` √® molto utile quando desideri applicare funzioni personalizzate su finestre di dati, come la media mobile o la somma mobile, e si adatta perfettamente a serie temporali e altre analisi sequenziali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Merging and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Exploring Temporal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Handling Multi-Level Indices (MultiIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Pandas Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Method chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping [RACCOLTA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "<p align=\"center\">\n",
    "  Enzo Schitini\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  Data Scientist & Data Analyst ‚Ä¢ SQL ‚Ä¢ Expert Bubble.io ‚Ä¢ UX & UI @ Scituffy creator\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
